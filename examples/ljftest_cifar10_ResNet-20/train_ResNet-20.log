WARNING: Logging before InitGoogleLogging() is written to STDERR
I1206 10:32:51.314559  2751 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I1206 10:32:51.314666  2751 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I1206 10:32:51.314671  2751 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I1206 10:32:51.314676  2751 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I1206 10:32:51.314678  2751 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I1206 10:32:51.314682  2751 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I1206 10:32:51.314741  2751 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I1206 10:32:51.314898  2751 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I1206 10:32:51.316694  2751 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I1206 10:32:51.316733  2751 caffe.cpp:269] Using GPUs 0
I1206 10:32:51.340888  2751 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I1206 10:32:51.745591  2751 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I1206 10:32:51.745632  2751 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I1206 10:32:51.765482  2751 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_20.prototxt"
test_net: "./test_ResNet_20.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_20"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 1
type: "Nesterov"
I1206 10:32:51.765744  2751 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_20.prototxt
I1206 10:32:51.766706  2751 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_20.prototxt
I1206 10:32:51.766726  2751 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1206 10:32:51.767663  2751 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 10
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
I1206 10:32:51.768133  2751 layer_factory.hpp:77] Creating layer Data1
I1206 10:32:51.768365  2751 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I1206 10:32:51.768409  2751 net.cpp:128] Creating Layer Data1
I1206 10:32:51.768420  2751 net.cpp:522] Data1 -> data
I1206 10:32:51.768453  2751 net.cpp:522] Data1 -> label
I1206 10:32:51.770035  2751 data_layer.cpp:45] output data size: 128,3,32,32
I1206 10:32:51.778540  2751 net.cpp:172] Setting up Data1
I1206 10:32:51.778592  2751 net.cpp:186] Top shape: 128 3 32 32 (393216)
I1206 10:32:51.778599  2751 net.cpp:186] Top shape: 128 (128)
I1206 10:32:51.778609  2751 net.cpp:194] Memory required for data: 1573376
I1206 10:32:51.778622  2751 layer_factory.hpp:77] Creating layer conv1
I1206 10:32:51.778652  2751 net.cpp:128] Creating Layer conv1
I1206 10:32:51.778661  2751 net.cpp:558] conv1 <- data
I1206 10:32:51.778687  2751 net.cpp:522] conv1 -> conv1
I1206 10:32:52.535346  2751 net.cpp:172] Setting up conv1
I1206 10:32:52.535398  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.535403  2751 net.cpp:194] Memory required for data: 9961984
I1206 10:32:52.535441  2751 layer_factory.hpp:77] Creating layer conv1/bn
I1206 10:32:52.535459  2751 net.cpp:128] Creating Layer conv1/bn
I1206 10:32:52.535465  2751 net.cpp:558] conv1/bn <- conv1
I1206 10:32:52.535475  2751 net.cpp:509] conv1/bn -> conv1 (in-place)
I1206 10:32:52.535773  2751 net.cpp:172] Setting up conv1/bn
I1206 10:32:52.535787  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.535792  2751 net.cpp:194] Memory required for data: 18350592
I1206 10:32:52.535806  2751 layer_factory.hpp:77] Creating layer conv1/scale
I1206 10:32:52.535815  2751 net.cpp:128] Creating Layer conv1/scale
I1206 10:32:52.535820  2751 net.cpp:558] conv1/scale <- conv1
I1206 10:32:52.535825  2751 net.cpp:509] conv1/scale -> conv1 (in-place)
I1206 10:32:52.535871  2751 layer_factory.hpp:77] Creating layer conv1/scale
I1206 10:32:52.536012  2751 net.cpp:172] Setting up conv1/scale
I1206 10:32:52.536027  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.536031  2751 net.cpp:194] Memory required for data: 26739200
I1206 10:32:52.536041  2751 layer_factory.hpp:77] Creating layer conv1/ReLU
I1206 10:32:52.536049  2751 net.cpp:128] Creating Layer conv1/ReLU
I1206 10:32:52.536054  2751 net.cpp:558] conv1/ReLU <- conv1
I1206 10:32:52.536059  2751 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I1206 10:32:52.536311  2751 net.cpp:172] Setting up conv1/ReLU
I1206 10:32:52.536329  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.536334  2751 net.cpp:194] Memory required for data: 35127808
I1206 10:32:52.536337  2751 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I1206 10:32:52.536347  2751 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I1206 10:32:52.536352  2751 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I1206 10:32:52.536360  2751 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I1206 10:32:52.536371  2751 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I1206 10:32:52.536417  2751 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I1206 10:32:52.536429  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.536435  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.536439  2751 net.cpp:194] Memory required for data: 51905024
I1206 10:32:52.536443  2751 layer_factory.hpp:77] Creating layer conv2_1_0
I1206 10:32:52.536458  2751 net.cpp:128] Creating Layer conv2_1_0
I1206 10:32:52.536463  2751 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I1206 10:32:52.536470  2751 net.cpp:522] conv2_1_0 -> conv2_1_0
I1206 10:32:52.538969  2751 net.cpp:172] Setting up conv2_1_0
I1206 10:32:52.538995  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.538998  2751 net.cpp:194] Memory required for data: 60293632
I1206 10:32:52.539011  2751 layer_factory.hpp:77] Creating layer conv2_1_bn0
I1206 10:32:52.539021  2751 net.cpp:128] Creating Layer conv2_1_bn0
I1206 10:32:52.539029  2751 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I1206 10:32:52.539038  2751 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I1206 10:32:52.539259  2751 net.cpp:172] Setting up conv2_1_bn0
I1206 10:32:52.539270  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.539274  2751 net.cpp:194] Memory required for data: 68682240
I1206 10:32:52.539284  2751 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1206 10:32:52.539294  2751 net.cpp:128] Creating Layer conv2_1_scale0
I1206 10:32:52.539299  2751 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I1206 10:32:52.539304  2751 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I1206 10:32:52.539340  2751 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1206 10:32:52.539463  2751 net.cpp:172] Setting up conv2_1_scale0
I1206 10:32:52.539475  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.539479  2751 net.cpp:194] Memory required for data: 77070848
I1206 10:32:52.539487  2751 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I1206 10:32:52.539494  2751 net.cpp:128] Creating Layer conv2_1_ReLU0
I1206 10:32:52.539499  2751 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I1206 10:32:52.539503  2751 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I1206 10:32:52.539754  2751 net.cpp:172] Setting up conv2_1_ReLU0
I1206 10:32:52.539772  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.539813  2751 net.cpp:194] Memory required for data: 85459456
I1206 10:32:52.539844  2751 layer_factory.hpp:77] Creating layer conv2_1_1
I1206 10:32:52.539857  2751 net.cpp:128] Creating Layer conv2_1_1
I1206 10:32:52.539862  2751 net.cpp:558] conv2_1_1 <- conv2_1_0
I1206 10:32:52.539872  2751 net.cpp:522] conv2_1_1 -> conv2_1_1
I1206 10:32:52.541167  2751 net.cpp:172] Setting up conv2_1_1
I1206 10:32:52.541193  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.541198  2751 net.cpp:194] Memory required for data: 93848064
I1206 10:32:52.541206  2751 layer_factory.hpp:77] Creating layer conv2_1bn1
I1206 10:32:52.541218  2751 net.cpp:128] Creating Layer conv2_1bn1
I1206 10:32:52.541224  2751 net.cpp:558] conv2_1bn1 <- conv2_1_1
I1206 10:32:52.541232  2751 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I1206 10:32:52.541457  2751 net.cpp:172] Setting up conv2_1bn1
I1206 10:32:52.541469  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.541473  2751 net.cpp:194] Memory required for data: 102236672
I1206 10:32:52.541486  2751 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1206 10:32:52.541492  2751 net.cpp:128] Creating Layer conv2_1_scale1
I1206 10:32:52.541496  2751 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I1206 10:32:52.541505  2751 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I1206 10:32:52.541541  2751 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1206 10:32:52.541663  2751 net.cpp:172] Setting up conv2_1_scale1
I1206 10:32:52.541672  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.541676  2751 net.cpp:194] Memory required for data: 110625280
I1206 10:32:52.541684  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I1206 10:32:52.541692  2751 net.cpp:128] Creating Layer conv2_Eltwise_1
I1206 10:32:52.541697  2751 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I1206 10:32:52.541702  2751 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I1206 10:32:52.541707  2751 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I1206 10:32:52.541738  2751 net.cpp:172] Setting up conv2_Eltwise_1
I1206 10:32:52.541744  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.541748  2751 net.cpp:194] Memory required for data: 119013888
I1206 10:32:52.541751  2751 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I1206 10:32:52.541760  2751 net.cpp:128] Creating Layer conv2_1ReLU_1
I1206 10:32:52.541764  2751 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I1206 10:32:52.541770  2751 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I1206 10:32:52.542181  2751 net.cpp:172] Setting up conv2_1ReLU_1
I1206 10:32:52.542197  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.542201  2751 net.cpp:194] Memory required for data: 127402496
I1206 10:32:52.542207  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.542217  2751 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.542222  2751 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I1206 10:32:52.542229  2751 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1206 10:32:52.542241  2751 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1206 10:32:52.542290  2751 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.542299  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.542305  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.542309  2751 net.cpp:194] Memory required for data: 144179712
I1206 10:32:52.542313  2751 layer_factory.hpp:77] Creating layer conv2_2_0
I1206 10:32:52.542326  2751 net.cpp:128] Creating Layer conv2_2_0
I1206 10:32:52.542331  2751 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1206 10:32:52.542340  2751 net.cpp:522] conv2_2_0 -> conv2_2_0
I1206 10:32:52.543548  2751 net.cpp:172] Setting up conv2_2_0
I1206 10:32:52.543567  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.543571  2751 net.cpp:194] Memory required for data: 152568320
I1206 10:32:52.543594  2751 layer_factory.hpp:77] Creating layer conv2_2_bn0
I1206 10:32:52.543604  2751 net.cpp:128] Creating Layer conv2_2_bn0
I1206 10:32:52.543608  2751 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I1206 10:32:52.543619  2751 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I1206 10:32:52.543846  2751 net.cpp:172] Setting up conv2_2_bn0
I1206 10:32:52.543853  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.543857  2751 net.cpp:194] Memory required for data: 160956928
I1206 10:32:52.543866  2751 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1206 10:32:52.543874  2751 net.cpp:128] Creating Layer conv2_2_scale0
I1206 10:32:52.543877  2751 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I1206 10:32:52.543885  2751 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I1206 10:32:52.543921  2751 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1206 10:32:52.544045  2751 net.cpp:172] Setting up conv2_2_scale0
I1206 10:32:52.544052  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.544056  2751 net.cpp:194] Memory required for data: 169345536
I1206 10:32:52.544064  2751 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I1206 10:32:52.544070  2751 net.cpp:128] Creating Layer conv2_2_ReLU0
I1206 10:32:52.544075  2751 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I1206 10:32:52.544081  2751 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I1206 10:32:52.544332  2751 net.cpp:172] Setting up conv2_2_ReLU0
I1206 10:32:52.544343  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.544348  2751 net.cpp:194] Memory required for data: 177734144
I1206 10:32:52.544353  2751 layer_factory.hpp:77] Creating layer conv2_2_1
I1206 10:32:52.544364  2751 net.cpp:128] Creating Layer conv2_2_1
I1206 10:32:52.544369  2751 net.cpp:558] conv2_2_1 <- conv2_2_0
I1206 10:32:52.544379  2751 net.cpp:522] conv2_2_1 -> conv2_2_1
I1206 10:32:52.545589  2751 net.cpp:172] Setting up conv2_2_1
I1206 10:32:52.545617  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.545622  2751 net.cpp:194] Memory required for data: 186122752
I1206 10:32:52.545636  2751 layer_factory.hpp:77] Creating layer conv2_2bn1
I1206 10:32:52.545647  2751 net.cpp:128] Creating Layer conv2_2bn1
I1206 10:32:52.545652  2751 net.cpp:558] conv2_2bn1 <- conv2_2_1
I1206 10:32:52.545658  2751 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I1206 10:32:52.545892  2751 net.cpp:172] Setting up conv2_2bn1
I1206 10:32:52.545902  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.545905  2751 net.cpp:194] Memory required for data: 194511360
I1206 10:32:52.545917  2751 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1206 10:32:52.545928  2751 net.cpp:128] Creating Layer conv2_2_scale1
I1206 10:32:52.545935  2751 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I1206 10:32:52.545941  2751 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I1206 10:32:52.545980  2751 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1206 10:32:52.546110  2751 net.cpp:172] Setting up conv2_2_scale1
I1206 10:32:52.546120  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.546124  2751 net.cpp:194] Memory required for data: 202899968
I1206 10:32:52.546133  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I1206 10:32:52.546139  2751 net.cpp:128] Creating Layer conv2_Eltwise_2
I1206 10:32:52.546144  2751 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1206 10:32:52.546149  2751 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I1206 10:32:52.546157  2751 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I1206 10:32:52.546181  2751 net.cpp:172] Setting up conv2_Eltwise_2
I1206 10:32:52.546190  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.546195  2751 net.cpp:194] Memory required for data: 211288576
I1206 10:32:52.546200  2751 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I1206 10:32:52.546205  2751 net.cpp:128] Creating Layer conv2_2ReLU_1
I1206 10:32:52.546209  2751 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I1206 10:32:52.546233  2751 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I1206 10:32:52.546460  2751 net.cpp:172] Setting up conv2_2ReLU_1
I1206 10:32:52.546478  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.546483  2751 net.cpp:194] Memory required for data: 219677184
I1206 10:32:52.546486  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.546494  2751 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.546499  2751 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I1206 10:32:52.546504  2751 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1206 10:32:52.546514  2751 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1206 10:32:52.546561  2751 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.546567  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.546573  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.546576  2751 net.cpp:194] Memory required for data: 236454400
I1206 10:32:52.546581  2751 layer_factory.hpp:77] Creating layer conv2_3_0
I1206 10:32:52.546593  2751 net.cpp:128] Creating Layer conv2_3_0
I1206 10:32:52.546598  2751 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1206 10:32:52.546607  2751 net.cpp:522] conv2_3_0 -> conv2_3_0
I1206 10:32:52.547849  2751 net.cpp:172] Setting up conv2_3_0
I1206 10:32:52.547866  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.547870  2751 net.cpp:194] Memory required for data: 244843008
I1206 10:32:52.547880  2751 layer_factory.hpp:77] Creating layer conv2_3_bn0
I1206 10:32:52.547894  2751 net.cpp:128] Creating Layer conv2_3_bn0
I1206 10:32:52.547900  2751 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I1206 10:32:52.547909  2751 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I1206 10:32:52.548140  2751 net.cpp:172] Setting up conv2_3_bn0
I1206 10:32:52.548147  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.548151  2751 net.cpp:194] Memory required for data: 253231616
I1206 10:32:52.548161  2751 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1206 10:32:52.548168  2751 net.cpp:128] Creating Layer conv2_3_scale0
I1206 10:32:52.548173  2751 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I1206 10:32:52.548178  2751 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I1206 10:32:52.548214  2751 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1206 10:32:52.548454  2751 net.cpp:172] Setting up conv2_3_scale0
I1206 10:32:52.548468  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.548473  2751 net.cpp:194] Memory required for data: 261620224
I1206 10:32:52.548481  2751 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I1206 10:32:52.548490  2751 net.cpp:128] Creating Layer conv2_3_ReLU0
I1206 10:32:52.548494  2751 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I1206 10:32:52.548499  2751 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I1206 10:32:52.548914  2751 net.cpp:172] Setting up conv2_3_ReLU0
I1206 10:32:52.548934  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.548939  2751 net.cpp:194] Memory required for data: 270008832
I1206 10:32:52.548944  2751 layer_factory.hpp:77] Creating layer conv2_3_1
I1206 10:32:52.548960  2751 net.cpp:128] Creating Layer conv2_3_1
I1206 10:32:52.548969  2751 net.cpp:558] conv2_3_1 <- conv2_3_0
I1206 10:32:52.549015  2751 net.cpp:522] conv2_3_1 -> conv2_3_1
I1206 10:32:52.550324  2751 net.cpp:172] Setting up conv2_3_1
I1206 10:32:52.550350  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.550355  2751 net.cpp:194] Memory required for data: 278397440
I1206 10:32:52.550369  2751 layer_factory.hpp:77] Creating layer conv2_3bn1
I1206 10:32:52.550379  2751 net.cpp:128] Creating Layer conv2_3bn1
I1206 10:32:52.550385  2751 net.cpp:558] conv2_3bn1 <- conv2_3_1
I1206 10:32:52.550392  2751 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I1206 10:32:52.550632  2751 net.cpp:172] Setting up conv2_3bn1
I1206 10:32:52.550657  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.550662  2751 net.cpp:194] Memory required for data: 286786048
I1206 10:32:52.550671  2751 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1206 10:32:52.550683  2751 net.cpp:128] Creating Layer conv2_3_scale1
I1206 10:32:52.550691  2751 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I1206 10:32:52.550698  2751 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I1206 10:32:52.550740  2751 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1206 10:32:52.550873  2751 net.cpp:172] Setting up conv2_3_scale1
I1206 10:32:52.550884  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.550887  2751 net.cpp:194] Memory required for data: 295174656
I1206 10:32:52.550895  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I1206 10:32:52.550904  2751 net.cpp:128] Creating Layer conv2_Eltwise_3
I1206 10:32:52.550909  2751 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1206 10:32:52.550915  2751 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I1206 10:32:52.550920  2751 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I1206 10:32:52.550946  2751 net.cpp:172] Setting up conv2_Eltwise_3
I1206 10:32:52.550956  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.550961  2751 net.cpp:194] Memory required for data: 303563264
I1206 10:32:52.550964  2751 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I1206 10:32:52.550971  2751 net.cpp:128] Creating Layer conv2_3ReLU_1
I1206 10:32:52.550974  2751 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I1206 10:32:52.550981  2751 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I1206 10:32:52.551213  2751 net.cpp:172] Setting up conv2_3ReLU_1
I1206 10:32:52.551225  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.551229  2751 net.cpp:194] Memory required for data: 311951872
I1206 10:32:52.551234  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.551241  2751 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.551246  2751 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I1206 10:32:52.551254  2751 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1206 10:32:52.551265  2751 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1206 10:32:52.551312  2751 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.551321  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.551327  2751 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I1206 10:32:52.551331  2751 net.cpp:194] Memory required for data: 328729088
I1206 10:32:52.551335  2751 layer_factory.hpp:77] Creating layer conv3_1_0
I1206 10:32:52.551347  2751 net.cpp:128] Creating Layer conv3_1_0
I1206 10:32:52.551353  2751 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1206 10:32:52.551363  2751 net.cpp:522] conv3_1_0 -> conv3_1_0
I1206 10:32:52.554087  2751 net.cpp:172] Setting up conv3_1_0
I1206 10:32:52.554116  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.554121  2751 net.cpp:194] Memory required for data: 332923392
I1206 10:32:52.554136  2751 layer_factory.hpp:77] Creating layer conv3_1_bn0
I1206 10:32:52.554152  2751 net.cpp:128] Creating Layer conv3_1_bn0
I1206 10:32:52.554157  2751 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I1206 10:32:52.554169  2751 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I1206 10:32:52.554412  2751 net.cpp:172] Setting up conv3_1_bn0
I1206 10:32:52.554422  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.554426  2751 net.cpp:194] Memory required for data: 337117696
I1206 10:32:52.554436  2751 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1206 10:32:52.554446  2751 net.cpp:128] Creating Layer conv3_1_scale0
I1206 10:32:52.554451  2751 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I1206 10:32:52.554457  2751 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I1206 10:32:52.554495  2751 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1206 10:32:52.554651  2751 net.cpp:172] Setting up conv3_1_scale0
I1206 10:32:52.554661  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.554666  2751 net.cpp:194] Memory required for data: 341312000
I1206 10:32:52.554673  2751 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I1206 10:32:52.554680  2751 net.cpp:128] Creating Layer conv3_1_ReLU0
I1206 10:32:52.554684  2751 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I1206 10:32:52.554692  2751 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I1206 10:32:52.554929  2751 net.cpp:172] Setting up conv3_1_ReLU0
I1206 10:32:52.554942  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.554946  2751 net.cpp:194] Memory required for data: 345506304
I1206 10:32:52.554952  2751 layer_factory.hpp:77] Creating layer conv3_1_1
I1206 10:32:52.554965  2751 net.cpp:128] Creating Layer conv3_1_1
I1206 10:32:52.554971  2751 net.cpp:558] conv3_1_1 <- conv3_1_0
I1206 10:32:52.554981  2751 net.cpp:522] conv3_1_1 -> conv3_1_1
I1206 10:32:52.556358  2751 net.cpp:172] Setting up conv3_1_1
I1206 10:32:52.556385  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.556391  2751 net.cpp:194] Memory required for data: 349700608
I1206 10:32:52.556401  2751 layer_factory.hpp:77] Creating layer conv3_1bn1
I1206 10:32:52.556408  2751 net.cpp:128] Creating Layer conv3_1bn1
I1206 10:32:52.556413  2751 net.cpp:558] conv3_1bn1 <- conv3_1_1
I1206 10:32:52.556427  2751 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I1206 10:32:52.556660  2751 net.cpp:172] Setting up conv3_1bn1
I1206 10:32:52.556669  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.556674  2751 net.cpp:194] Memory required for data: 353894912
I1206 10:32:52.556684  2751 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1206 10:32:52.556690  2751 net.cpp:128] Creating Layer conv3_1_scale1
I1206 10:32:52.556695  2751 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I1206 10:32:52.556700  2751 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I1206 10:32:52.556766  2751 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1206 10:32:52.556951  2751 net.cpp:172] Setting up conv3_1_scale1
I1206 10:32:52.556962  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.556967  2751 net.cpp:194] Memory required for data: 358089216
I1206 10:32:52.556975  2751 layer_factory.hpp:77] Creating layer conv3_1_down
I1206 10:32:52.556993  2751 net.cpp:128] Creating Layer conv3_1_down
I1206 10:32:52.556998  2751 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1206 10:32:52.557004  2751 net.cpp:522] conv3_1_down -> conv3_1_down
I1206 10:32:52.558248  2751 net.cpp:172] Setting up conv3_1_down
I1206 10:32:52.558264  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.558269  2751 net.cpp:194] Memory required for data: 362283520
I1206 10:32:52.558290  2751 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I1206 10:32:52.558300  2751 net.cpp:128] Creating Layer conv3_1_bn_down
I1206 10:32:52.558306  2751 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I1206 10:32:52.558312  2751 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I1206 10:32:52.558547  2751 net.cpp:172] Setting up conv3_1_bn_down
I1206 10:32:52.558553  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.558557  2751 net.cpp:194] Memory required for data: 366477824
I1206 10:32:52.558567  2751 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1206 10:32:52.558573  2751 net.cpp:128] Creating Layer conv3_1_scale_down
I1206 10:32:52.558578  2751 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I1206 10:32:52.558584  2751 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I1206 10:32:52.558622  2751 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1206 10:32:52.558755  2751 net.cpp:172] Setting up conv3_1_scale_down
I1206 10:32:52.558765  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.558769  2751 net.cpp:194] Memory required for data: 370672128
I1206 10:32:52.558776  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I1206 10:32:52.558800  2751 net.cpp:128] Creating Layer conv3_Eltwise_1
I1206 10:32:52.558805  2751 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I1206 10:32:52.558810  2751 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I1206 10:32:52.558816  2751 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I1206 10:32:52.558840  2751 net.cpp:172] Setting up conv3_Eltwise_1
I1206 10:32:52.558847  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.558851  2751 net.cpp:194] Memory required for data: 374866432
I1206 10:32:52.558856  2751 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I1206 10:32:52.558861  2751 net.cpp:128] Creating Layer conv3_1ReLU_1
I1206 10:32:52.558866  2751 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I1206 10:32:52.558872  2751 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I1206 10:32:52.559100  2751 net.cpp:172] Setting up conv3_1ReLU_1
I1206 10:32:52.559109  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.559113  2751 net.cpp:194] Memory required for data: 379060736
I1206 10:32:52.559118  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.559124  2751 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.559128  2751 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I1206 10:32:52.559137  2751 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1206 10:32:52.559145  2751 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1206 10:32:52.559196  2751 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.559204  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.559211  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.559213  2751 net.cpp:194] Memory required for data: 387449344
I1206 10:32:52.559217  2751 layer_factory.hpp:77] Creating layer conv3_2_0
I1206 10:32:52.559229  2751 net.cpp:128] Creating Layer conv3_2_0
I1206 10:32:52.559234  2751 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1206 10:32:52.559244  2751 net.cpp:522] conv3_2_0 -> conv3_2_0
I1206 10:32:52.560612  2751 net.cpp:172] Setting up conv3_2_0
I1206 10:32:52.560634  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.560638  2751 net.cpp:194] Memory required for data: 391643648
I1206 10:32:52.560648  2751 layer_factory.hpp:77] Creating layer conv3_2_bn0
I1206 10:32:52.560657  2751 net.cpp:128] Creating Layer conv3_2_bn0
I1206 10:32:52.560662  2751 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I1206 10:32:52.560672  2751 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I1206 10:32:52.560912  2751 net.cpp:172] Setting up conv3_2_bn0
I1206 10:32:52.560923  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.560927  2751 net.cpp:194] Memory required for data: 395837952
I1206 10:32:52.560936  2751 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1206 10:32:52.560943  2751 net.cpp:128] Creating Layer conv3_2_scale0
I1206 10:32:52.560948  2751 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I1206 10:32:52.560956  2751 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I1206 10:32:52.560993  2751 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1206 10:32:52.561134  2751 net.cpp:172] Setting up conv3_2_scale0
I1206 10:32:52.561147  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.561151  2751 net.cpp:194] Memory required for data: 400032256
I1206 10:32:52.561159  2751 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I1206 10:32:52.561166  2751 net.cpp:128] Creating Layer conv3_2_ReLU0
I1206 10:32:52.561169  2751 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I1206 10:32:52.561175  2751 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I1206 10:32:52.561595  2751 net.cpp:172] Setting up conv3_2_ReLU0
I1206 10:32:52.561616  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.561621  2751 net.cpp:194] Memory required for data: 404226560
I1206 10:32:52.561625  2751 layer_factory.hpp:77] Creating layer conv3_2_1
I1206 10:32:52.561655  2751 net.cpp:128] Creating Layer conv3_2_1
I1206 10:32:52.561661  2751 net.cpp:558] conv3_2_1 <- conv3_2_0
I1206 10:32:52.561669  2751 net.cpp:522] conv3_2_1 -> conv3_2_1
I1206 10:32:52.563045  2751 net.cpp:172] Setting up conv3_2_1
I1206 10:32:52.563069  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.563073  2751 net.cpp:194] Memory required for data: 408420864
I1206 10:32:52.563086  2751 layer_factory.hpp:77] Creating layer conv3_2bn1
I1206 10:32:52.563098  2751 net.cpp:128] Creating Layer conv3_2bn1
I1206 10:32:52.563104  2751 net.cpp:558] conv3_2bn1 <- conv3_2_1
I1206 10:32:52.563113  2751 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I1206 10:32:52.563351  2751 net.cpp:172] Setting up conv3_2bn1
I1206 10:32:52.563362  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.563366  2751 net.cpp:194] Memory required for data: 412615168
I1206 10:32:52.563376  2751 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1206 10:32:52.563382  2751 net.cpp:128] Creating Layer conv3_2_scale1
I1206 10:32:52.563386  2751 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I1206 10:32:52.563395  2751 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I1206 10:32:52.563432  2751 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1206 10:32:52.563568  2751 net.cpp:172] Setting up conv3_2_scale1
I1206 10:32:52.563580  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.563583  2751 net.cpp:194] Memory required for data: 416809472
I1206 10:32:52.563591  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I1206 10:32:52.563598  2751 net.cpp:128] Creating Layer conv3_Eltwise_2
I1206 10:32:52.563602  2751 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1206 10:32:52.563607  2751 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I1206 10:32:52.563616  2751 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I1206 10:32:52.563637  2751 net.cpp:172] Setting up conv3_Eltwise_2
I1206 10:32:52.563644  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.563648  2751 net.cpp:194] Memory required for data: 421003776
I1206 10:32:52.563652  2751 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I1206 10:32:52.563658  2751 net.cpp:128] Creating Layer conv3_2ReLU_1
I1206 10:32:52.563665  2751 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I1206 10:32:52.563670  2751 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I1206 10:32:52.563946  2751 net.cpp:172] Setting up conv3_2ReLU_1
I1206 10:32:52.563962  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.563967  2751 net.cpp:194] Memory required for data: 425198080
I1206 10:32:52.563972  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.563982  2751 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.563987  2751 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I1206 10:32:52.563993  2751 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1206 10:32:52.564002  2751 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1206 10:32:52.564054  2751 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.564060  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.564066  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.564070  2751 net.cpp:194] Memory required for data: 433586688
I1206 10:32:52.564074  2751 layer_factory.hpp:77] Creating layer conv3_3_0
I1206 10:32:52.564085  2751 net.cpp:128] Creating Layer conv3_3_0
I1206 10:32:52.564090  2751 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1206 10:32:52.564100  2751 net.cpp:522] conv3_3_0 -> conv3_3_0
I1206 10:32:52.565552  2751 net.cpp:172] Setting up conv3_3_0
I1206 10:32:52.565573  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.565578  2751 net.cpp:194] Memory required for data: 437780992
I1206 10:32:52.565588  2751 layer_factory.hpp:77] Creating layer conv3_3_bn0
I1206 10:32:52.565621  2751 net.cpp:128] Creating Layer conv3_3_bn0
I1206 10:32:52.565629  2751 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I1206 10:32:52.565639  2751 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I1206 10:32:52.565884  2751 net.cpp:172] Setting up conv3_3_bn0
I1206 10:32:52.565896  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.565899  2751 net.cpp:194] Memory required for data: 441975296
I1206 10:32:52.565909  2751 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1206 10:32:52.565917  2751 net.cpp:128] Creating Layer conv3_3_scale0
I1206 10:32:52.565920  2751 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I1206 10:32:52.565928  2751 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I1206 10:32:52.565966  2751 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1206 10:32:52.566151  2751 net.cpp:172] Setting up conv3_3_scale0
I1206 10:32:52.566164  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.566169  2751 net.cpp:194] Memory required for data: 446169600
I1206 10:32:52.566176  2751 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I1206 10:32:52.566182  2751 net.cpp:128] Creating Layer conv3_3_ReLU0
I1206 10:32:52.566187  2751 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I1206 10:32:52.566193  2751 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I1206 10:32:52.566432  2751 net.cpp:172] Setting up conv3_3_ReLU0
I1206 10:32:52.566445  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.566450  2751 net.cpp:194] Memory required for data: 450363904
I1206 10:32:52.566454  2751 layer_factory.hpp:77] Creating layer conv3_3_1
I1206 10:32:52.566468  2751 net.cpp:128] Creating Layer conv3_3_1
I1206 10:32:52.566473  2751 net.cpp:558] conv3_3_1 <- conv3_3_0
I1206 10:32:52.566481  2751 net.cpp:522] conv3_3_1 -> conv3_3_1
I1206 10:32:52.567896  2751 net.cpp:172] Setting up conv3_3_1
I1206 10:32:52.567919  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.567924  2751 net.cpp:194] Memory required for data: 454558208
I1206 10:32:52.567935  2751 layer_factory.hpp:77] Creating layer conv3_3bn1
I1206 10:32:52.567956  2751 net.cpp:128] Creating Layer conv3_3bn1
I1206 10:32:52.567962  2751 net.cpp:558] conv3_3bn1 <- conv3_3_1
I1206 10:32:52.567970  2751 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I1206 10:32:52.568209  2751 net.cpp:172] Setting up conv3_3bn1
I1206 10:32:52.568222  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.568236  2751 net.cpp:194] Memory required for data: 458752512
I1206 10:32:52.568246  2751 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1206 10:32:52.568253  2751 net.cpp:128] Creating Layer conv3_3_scale1
I1206 10:32:52.568259  2751 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I1206 10:32:52.568265  2751 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I1206 10:32:52.568305  2751 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1206 10:32:52.568444  2751 net.cpp:172] Setting up conv3_3_scale1
I1206 10:32:52.568457  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.568461  2751 net.cpp:194] Memory required for data: 462946816
I1206 10:32:52.568470  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I1206 10:32:52.568476  2751 net.cpp:128] Creating Layer conv3_Eltwise_3
I1206 10:32:52.568481  2751 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1206 10:32:52.568486  2751 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I1206 10:32:52.568492  2751 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I1206 10:32:52.568516  2751 net.cpp:172] Setting up conv3_Eltwise_3
I1206 10:32:52.568522  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.568526  2751 net.cpp:194] Memory required for data: 467141120
I1206 10:32:52.568531  2751 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I1206 10:32:52.568536  2751 net.cpp:128] Creating Layer conv3_3ReLU_1
I1206 10:32:52.568540  2751 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I1206 10:32:52.568548  2751 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I1206 10:32:52.568986  2751 net.cpp:172] Setting up conv3_3ReLU_1
I1206 10:32:52.569007  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.569012  2751 net.cpp:194] Memory required for data: 471335424
I1206 10:32:52.569017  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.569025  2751 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.569031  2751 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I1206 10:32:52.569041  2751 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1206 10:32:52.569049  2751 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1206 10:32:52.569100  2751 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.569110  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.569116  2751 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I1206 10:32:52.569120  2751 net.cpp:194] Memory required for data: 479724032
I1206 10:32:52.569124  2751 layer_factory.hpp:77] Creating layer conv4_1_0
I1206 10:32:52.569139  2751 net.cpp:128] Creating Layer conv4_1_0
I1206 10:32:52.569144  2751 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1206 10:32:52.569152  2751 net.cpp:522] conv4_1_0 -> conv4_1_0
I1206 10:32:52.572134  2751 net.cpp:172] Setting up conv4_1_0
I1206 10:32:52.572161  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.572165  2751 net.cpp:194] Memory required for data: 481821184
I1206 10:32:52.572177  2751 layer_factory.hpp:77] Creating layer conv4_1_bn0
I1206 10:32:52.572190  2751 net.cpp:128] Creating Layer conv4_1_bn0
I1206 10:32:52.572197  2751 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I1206 10:32:52.572206  2751 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I1206 10:32:52.572479  2751 net.cpp:172] Setting up conv4_1_bn0
I1206 10:32:52.572491  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.572496  2751 net.cpp:194] Memory required for data: 483918336
I1206 10:32:52.572506  2751 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1206 10:32:52.572513  2751 net.cpp:128] Creating Layer conv4_1_scale0
I1206 10:32:52.572517  2751 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I1206 10:32:52.572526  2751 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I1206 10:32:52.572566  2751 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1206 10:32:52.572711  2751 net.cpp:172] Setting up conv4_1_scale0
I1206 10:32:52.572721  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.572724  2751 net.cpp:194] Memory required for data: 486015488
I1206 10:32:52.572732  2751 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I1206 10:32:52.572739  2751 net.cpp:128] Creating Layer conv4_1_ReLU0
I1206 10:32:52.572743  2751 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I1206 10:32:52.572749  2751 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I1206 10:32:52.572988  2751 net.cpp:172] Setting up conv4_1_ReLU0
I1206 10:32:52.573001  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.573006  2751 net.cpp:194] Memory required for data: 488112640
I1206 10:32:52.573010  2751 layer_factory.hpp:77] Creating layer conv4_1_1
I1206 10:32:52.573024  2751 net.cpp:128] Creating Layer conv4_1_1
I1206 10:32:52.573032  2751 net.cpp:558] conv4_1_1 <- conv4_1_0
I1206 10:32:52.573042  2751 net.cpp:522] conv4_1_1 -> conv4_1_1
I1206 10:32:52.575034  2751 net.cpp:172] Setting up conv4_1_1
I1206 10:32:52.575057  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.575060  2751 net.cpp:194] Memory required for data: 490209792
I1206 10:32:52.575074  2751 layer_factory.hpp:77] Creating layer conv4_1bn1
I1206 10:32:52.575089  2751 net.cpp:128] Creating Layer conv4_1bn1
I1206 10:32:52.575103  2751 net.cpp:558] conv4_1bn1 <- conv4_1_1
I1206 10:32:52.575111  2751 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I1206 10:32:52.575369  2751 net.cpp:172] Setting up conv4_1bn1
I1206 10:32:52.575379  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.575402  2751 net.cpp:194] Memory required for data: 492306944
I1206 10:32:52.575412  2751 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1206 10:32:52.575423  2751 net.cpp:128] Creating Layer conv4_1_scale1
I1206 10:32:52.575426  2751 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I1206 10:32:52.575433  2751 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I1206 10:32:52.575475  2751 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1206 10:32:52.575623  2751 net.cpp:172] Setting up conv4_1_scale1
I1206 10:32:52.575635  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.575640  2751 net.cpp:194] Memory required for data: 494404096
I1206 10:32:52.575649  2751 layer_factory.hpp:77] Creating layer conv4_1_down
I1206 10:32:52.575662  2751 net.cpp:128] Creating Layer conv4_1_down
I1206 10:32:52.575667  2751 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1206 10:32:52.575678  2751 net.cpp:522] conv4_1_down -> conv4_1_down
I1206 10:32:52.577138  2751 net.cpp:172] Setting up conv4_1_down
I1206 10:32:52.577165  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.577170  2751 net.cpp:194] Memory required for data: 496501248
I1206 10:32:52.577180  2751 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I1206 10:32:52.577189  2751 net.cpp:128] Creating Layer conv4_1_bn_down
I1206 10:32:52.577198  2751 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I1206 10:32:52.577208  2751 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I1206 10:32:52.577498  2751 net.cpp:172] Setting up conv4_1_bn_down
I1206 10:32:52.577512  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.577517  2751 net.cpp:194] Memory required for data: 498598400
I1206 10:32:52.577527  2751 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1206 10:32:52.577535  2751 net.cpp:128] Creating Layer conv4_1_scale_down
I1206 10:32:52.577540  2751 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I1206 10:32:52.577545  2751 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I1206 10:32:52.577589  2751 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1206 10:32:52.577739  2751 net.cpp:172] Setting up conv4_1_scale_down
I1206 10:32:52.577745  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.577749  2751 net.cpp:194] Memory required for data: 500695552
I1206 10:32:52.577757  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I1206 10:32:52.577767  2751 net.cpp:128] Creating Layer conv4_Eltwise_1
I1206 10:32:52.577772  2751 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I1206 10:32:52.577777  2751 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I1206 10:32:52.577783  2751 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I1206 10:32:52.577808  2751 net.cpp:172] Setting up conv4_Eltwise_1
I1206 10:32:52.577816  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.577819  2751 net.cpp:194] Memory required for data: 502792704
I1206 10:32:52.577823  2751 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I1206 10:32:52.577829  2751 net.cpp:128] Creating Layer conv4_1ReLU_1
I1206 10:32:52.577833  2751 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I1206 10:32:52.577841  2751 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I1206 10:32:52.578073  2751 net.cpp:172] Setting up conv4_1ReLU_1
I1206 10:32:52.578089  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.578094  2751 net.cpp:194] Memory required for data: 504889856
I1206 10:32:52.578099  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.578105  2751 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.578110  2751 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I1206 10:32:52.578119  2751 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1206 10:32:52.578128  2751 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1206 10:32:52.578183  2751 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.578234  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.578245  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.578249  2751 net.cpp:194] Memory required for data: 509084160
I1206 10:32:52.578253  2751 layer_factory.hpp:77] Creating layer conv4_2_0
I1206 10:32:52.578266  2751 net.cpp:128] Creating Layer conv4_2_0
I1206 10:32:52.578271  2751 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1206 10:32:52.578280  2751 net.cpp:522] conv4_2_0 -> conv4_2_0
I1206 10:32:52.580260  2751 net.cpp:172] Setting up conv4_2_0
I1206 10:32:52.580286  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.580291  2751 net.cpp:194] Memory required for data: 511181312
I1206 10:32:52.580301  2751 layer_factory.hpp:77] Creating layer conv4_2_bn0
I1206 10:32:52.580315  2751 net.cpp:128] Creating Layer conv4_2_bn0
I1206 10:32:52.580322  2751 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I1206 10:32:52.580329  2751 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I1206 10:32:52.580582  2751 net.cpp:172] Setting up conv4_2_bn0
I1206 10:32:52.580592  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.580596  2751 net.cpp:194] Memory required for data: 513278464
I1206 10:32:52.580606  2751 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1206 10:32:52.580613  2751 net.cpp:128] Creating Layer conv4_2_scale0
I1206 10:32:52.580617  2751 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I1206 10:32:52.580623  2751 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I1206 10:32:52.580664  2751 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1206 10:32:52.580812  2751 net.cpp:172] Setting up conv4_2_scale0
I1206 10:32:52.580821  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.580826  2751 net.cpp:194] Memory required for data: 515375616
I1206 10:32:52.580833  2751 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I1206 10:32:52.580842  2751 net.cpp:128] Creating Layer conv4_2_ReLU0
I1206 10:32:52.580849  2751 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I1206 10:32:52.580855  2751 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I1206 10:32:52.581281  2751 net.cpp:172] Setting up conv4_2_ReLU0
I1206 10:32:52.581301  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.581305  2751 net.cpp:194] Memory required for data: 517472768
I1206 10:32:52.581311  2751 layer_factory.hpp:77] Creating layer conv4_2_1
I1206 10:32:52.581328  2751 net.cpp:128] Creating Layer conv4_2_1
I1206 10:32:52.581336  2751 net.cpp:558] conv4_2_1 <- conv4_2_0
I1206 10:32:52.581346  2751 net.cpp:522] conv4_2_1 -> conv4_2_1
I1206 10:32:52.583353  2751 net.cpp:172] Setting up conv4_2_1
I1206 10:32:52.583379  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.583384  2751 net.cpp:194] Memory required for data: 519569920
I1206 10:32:52.583398  2751 layer_factory.hpp:77] Creating layer conv4_2bn1
I1206 10:32:52.583410  2751 net.cpp:128] Creating Layer conv4_2bn1
I1206 10:32:52.583415  2751 net.cpp:558] conv4_2bn1 <- conv4_2_1
I1206 10:32:52.583423  2751 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I1206 10:32:52.583685  2751 net.cpp:172] Setting up conv4_2bn1
I1206 10:32:52.583698  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.583701  2751 net.cpp:194] Memory required for data: 521667072
I1206 10:32:52.583725  2751 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1206 10:32:52.583732  2751 net.cpp:128] Creating Layer conv4_2_scale1
I1206 10:32:52.583737  2751 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I1206 10:32:52.583744  2751 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I1206 10:32:52.583786  2751 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1206 10:32:52.583928  2751 net.cpp:172] Setting up conv4_2_scale1
I1206 10:32:52.583938  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.583942  2751 net.cpp:194] Memory required for data: 523764224
I1206 10:32:52.583950  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I1206 10:32:52.583959  2751 net.cpp:128] Creating Layer conv4_Eltwise_2
I1206 10:32:52.583964  2751 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1206 10:32:52.583989  2751 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I1206 10:32:52.583999  2751 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I1206 10:32:52.584022  2751 net.cpp:172] Setting up conv4_Eltwise_2
I1206 10:32:52.584029  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.584033  2751 net.cpp:194] Memory required for data: 525861376
I1206 10:32:52.584038  2751 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I1206 10:32:52.584043  2751 net.cpp:128] Creating Layer conv4_2ReLU_1
I1206 10:32:52.584048  2751 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I1206 10:32:52.584054  2751 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I1206 10:32:52.584306  2751 net.cpp:172] Setting up conv4_2ReLU_1
I1206 10:32:52.584322  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.584326  2751 net.cpp:194] Memory required for data: 527958528
I1206 10:32:52.584331  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.584338  2751 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.584343  2751 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I1206 10:32:52.584352  2751 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1206 10:32:52.584360  2751 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1206 10:32:52.584412  2751 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.584419  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.584425  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.584429  2751 net.cpp:194] Memory required for data: 532152832
I1206 10:32:52.584434  2751 layer_factory.hpp:77] Creating layer conv4_3_0
I1206 10:32:52.584445  2751 net.cpp:128] Creating Layer conv4_3_0
I1206 10:32:52.584450  2751 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1206 10:32:52.584458  2751 net.cpp:522] conv4_3_0 -> conv4_3_0
I1206 10:32:52.586287  2751 net.cpp:172] Setting up conv4_3_0
I1206 10:32:52.586304  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.586308  2751 net.cpp:194] Memory required for data: 534249984
I1206 10:32:52.586318  2751 layer_factory.hpp:77] Creating layer conv4_3_bn0
I1206 10:32:52.586328  2751 net.cpp:128] Creating Layer conv4_3_bn0
I1206 10:32:52.586333  2751 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I1206 10:32:52.586340  2751 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I1206 10:32:52.586592  2751 net.cpp:172] Setting up conv4_3_bn0
I1206 10:32:52.586599  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.586603  2751 net.cpp:194] Memory required for data: 536347136
I1206 10:32:52.586612  2751 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1206 10:32:52.586619  2751 net.cpp:128] Creating Layer conv4_3_scale0
I1206 10:32:52.586623  2751 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I1206 10:32:52.586628  2751 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I1206 10:32:52.586673  2751 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1206 10:32:52.586817  2751 net.cpp:172] Setting up conv4_3_scale0
I1206 10:32:52.586823  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.586827  2751 net.cpp:194] Memory required for data: 538444288
I1206 10:32:52.586834  2751 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I1206 10:32:52.586843  2751 net.cpp:128] Creating Layer conv4_3_ReLU0
I1206 10:32:52.586848  2751 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I1206 10:32:52.586853  2751 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I1206 10:32:52.587090  2751 net.cpp:172] Setting up conv4_3_ReLU0
I1206 10:32:52.587100  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.587105  2751 net.cpp:194] Memory required for data: 540541440
I1206 10:32:52.587110  2751 layer_factory.hpp:77] Creating layer conv4_3_1
I1206 10:32:52.587122  2751 net.cpp:128] Creating Layer conv4_3_1
I1206 10:32:52.587127  2751 net.cpp:558] conv4_3_1 <- conv4_3_0
I1206 10:32:52.587153  2751 net.cpp:522] conv4_3_1 -> conv4_3_1
I1206 10:32:52.589195  2751 net.cpp:172] Setting up conv4_3_1
I1206 10:32:52.589223  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.589228  2751 net.cpp:194] Memory required for data: 542638592
I1206 10:32:52.589242  2751 layer_factory.hpp:77] Creating layer conv4_3bn1
I1206 10:32:52.589252  2751 net.cpp:128] Creating Layer conv4_3bn1
I1206 10:32:52.589258  2751 net.cpp:558] conv4_3bn1 <- conv4_3_1
I1206 10:32:52.589267  2751 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I1206 10:32:52.589534  2751 net.cpp:172] Setting up conv4_3bn1
I1206 10:32:52.589543  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.589548  2751 net.cpp:194] Memory required for data: 544735744
I1206 10:32:52.589557  2751 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1206 10:32:52.589565  2751 net.cpp:128] Creating Layer conv4_3_scale1
I1206 10:32:52.589570  2751 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I1206 10:32:52.589576  2751 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I1206 10:32:52.589617  2751 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1206 10:32:52.589767  2751 net.cpp:172] Setting up conv4_3_scale1
I1206 10:32:52.589777  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.589782  2751 net.cpp:194] Memory required for data: 546832896
I1206 10:32:52.589789  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I1206 10:32:52.589798  2751 net.cpp:128] Creating Layer conv4_Eltwise_3
I1206 10:32:52.589803  2751 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1206 10:32:52.589808  2751 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I1206 10:32:52.589817  2751 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I1206 10:32:52.589838  2751 net.cpp:172] Setting up conv4_Eltwise_3
I1206 10:32:52.589844  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.589848  2751 net.cpp:194] Memory required for data: 548930048
I1206 10:32:52.589853  2751 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I1206 10:32:52.589859  2751 net.cpp:128] Creating Layer conv4_3ReLU_1
I1206 10:32:52.589864  2751 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I1206 10:32:52.589871  2751 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I1206 10:32:52.590108  2751 net.cpp:172] Setting up conv4_3ReLU_1
I1206 10:32:52.590123  2751 net.cpp:186] Top shape: 128 64 8 8 (524288)
I1206 10:32:52.590127  2751 net.cpp:194] Memory required for data: 551027200
I1206 10:32:52.590132  2751 layer_factory.hpp:77] Creating layer Pooling1
I1206 10:32:52.590140  2751 net.cpp:128] Creating Layer Pooling1
I1206 10:32:52.590145  2751 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I1206 10:32:52.590153  2751 net.cpp:522] Pooling1 -> Pooling1
I1206 10:32:52.590653  2751 net.cpp:172] Setting up Pooling1
I1206 10:32:52.590670  2751 net.cpp:186] Top shape: 128 64 1 1 (8192)
I1206 10:32:52.590674  2751 net.cpp:194] Memory required for data: 551059968
I1206 10:32:52.590678  2751 layer_factory.hpp:77] Creating layer fc1
I1206 10:32:52.590693  2751 net.cpp:128] Creating Layer fc1
I1206 10:32:52.590699  2751 net.cpp:558] fc1 <- Pooling1
I1206 10:32:52.590708  2751 net.cpp:522] fc1 -> fc1
I1206 10:32:52.592013  2751 net.cpp:172] Setting up fc1
I1206 10:32:52.592036  2751 net.cpp:186] Top shape: 128 10 1 1 (1280)
I1206 10:32:52.592039  2751 net.cpp:194] Memory required for data: 551065088
I1206 10:32:52.592049  2751 layer_factory.hpp:77] Creating layer Softmax1
I1206 10:32:52.592061  2751 net.cpp:128] Creating Layer Softmax1
I1206 10:32:52.592065  2751 net.cpp:558] Softmax1 <- fc1
I1206 10:32:52.592072  2751 net.cpp:558] Softmax1 <- label
I1206 10:32:52.592080  2751 net.cpp:522] Softmax1 -> Softmax1
I1206 10:32:52.592100  2751 layer_factory.hpp:77] Creating layer Softmax1
I1206 10:32:52.592478  2751 net.cpp:172] Setting up Softmax1
I1206 10:32:52.592496  2751 net.cpp:186] Top shape: (1)
I1206 10:32:52.592500  2751 net.cpp:189]     with loss weight 1
I1206 10:32:52.592563  2751 net.cpp:194] Memory required for data: 551065092
I1206 10:32:52.592583  2751 net.cpp:301] Softmax1 needs backward computation.
I1206 10:32:52.592589  2751 net.cpp:301] fc1 needs backward computation.
I1206 10:32:52.592593  2751 net.cpp:301] Pooling1 needs backward computation.
I1206 10:32:52.592598  2751 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I1206 10:32:52.592602  2751 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I1206 10:32:52.592607  2751 net.cpp:301] conv4_3_scale1 needs backward computation.
I1206 10:32:52.592612  2751 net.cpp:301] conv4_3bn1 needs backward computation.
I1206 10:32:52.592615  2751 net.cpp:301] conv4_3_1 needs backward computation.
I1206 10:32:52.592619  2751 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I1206 10:32:52.592623  2751 net.cpp:301] conv4_3_scale0 needs backward computation.
I1206 10:32:52.592629  2751 net.cpp:301] conv4_3_bn0 needs backward computation.
I1206 10:32:52.592633  2751 net.cpp:301] conv4_3_0 needs backward computation.
I1206 10:32:52.592638  2751 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.592643  2751 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I1206 10:32:52.592646  2751 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I1206 10:32:52.592651  2751 net.cpp:301] conv4_2_scale1 needs backward computation.
I1206 10:32:52.592655  2751 net.cpp:301] conv4_2bn1 needs backward computation.
I1206 10:32:52.592659  2751 net.cpp:301] conv4_2_1 needs backward computation.
I1206 10:32:52.592669  2751 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I1206 10:32:52.592672  2751 net.cpp:301] conv4_2_scale0 needs backward computation.
I1206 10:32:52.592676  2751 net.cpp:301] conv4_2_bn0 needs backward computation.
I1206 10:32:52.592680  2751 net.cpp:301] conv4_2_0 needs backward computation.
I1206 10:32:52.592685  2751 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.592690  2751 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I1206 10:32:52.592694  2751 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I1206 10:32:52.592698  2751 net.cpp:301] conv4_1_scale_down needs backward computation.
I1206 10:32:52.592703  2751 net.cpp:301] conv4_1_bn_down needs backward computation.
I1206 10:32:52.592707  2751 net.cpp:301] conv4_1_down needs backward computation.
I1206 10:32:52.592711  2751 net.cpp:301] conv4_1_scale1 needs backward computation.
I1206 10:32:52.592715  2751 net.cpp:301] conv4_1bn1 needs backward computation.
I1206 10:32:52.592720  2751 net.cpp:301] conv4_1_1 needs backward computation.
I1206 10:32:52.592725  2751 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I1206 10:32:52.592728  2751 net.cpp:301] conv4_1_scale0 needs backward computation.
I1206 10:32:52.592733  2751 net.cpp:301] conv4_1_bn0 needs backward computation.
I1206 10:32:52.592737  2751 net.cpp:301] conv4_1_0 needs backward computation.
I1206 10:32:52.592741  2751 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I1206 10:32:52.592746  2751 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I1206 10:32:52.592751  2751 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I1206 10:32:52.592756  2751 net.cpp:301] conv3_3_scale1 needs backward computation.
I1206 10:32:52.592761  2751 net.cpp:301] conv3_3bn1 needs backward computation.
I1206 10:32:52.592764  2751 net.cpp:301] conv3_3_1 needs backward computation.
I1206 10:32:52.592769  2751 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I1206 10:32:52.592773  2751 net.cpp:301] conv3_3_scale0 needs backward computation.
I1206 10:32:52.592777  2751 net.cpp:301] conv3_3_bn0 needs backward computation.
I1206 10:32:52.592782  2751 net.cpp:301] conv3_3_0 needs backward computation.
I1206 10:32:52.592787  2751 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.592792  2751 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I1206 10:32:52.592797  2751 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I1206 10:32:52.592803  2751 net.cpp:301] conv3_2_scale1 needs backward computation.
I1206 10:32:52.592813  2751 net.cpp:301] conv3_2bn1 needs backward computation.
I1206 10:32:52.592818  2751 net.cpp:301] conv3_2_1 needs backward computation.
I1206 10:32:52.592823  2751 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I1206 10:32:52.592826  2751 net.cpp:301] conv3_2_scale0 needs backward computation.
I1206 10:32:52.592830  2751 net.cpp:301] conv3_2_bn0 needs backward computation.
I1206 10:32:52.592834  2751 net.cpp:301] conv3_2_0 needs backward computation.
I1206 10:32:52.592839  2751 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.592846  2751 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I1206 10:32:52.592851  2751 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I1206 10:32:52.592855  2751 net.cpp:301] conv3_1_scale_down needs backward computation.
I1206 10:32:52.592860  2751 net.cpp:301] conv3_1_bn_down needs backward computation.
I1206 10:32:52.592864  2751 net.cpp:301] conv3_1_down needs backward computation.
I1206 10:32:52.592869  2751 net.cpp:301] conv3_1_scale1 needs backward computation.
I1206 10:32:52.592873  2751 net.cpp:301] conv3_1bn1 needs backward computation.
I1206 10:32:52.592877  2751 net.cpp:301] conv3_1_1 needs backward computation.
I1206 10:32:52.592882  2751 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I1206 10:32:52.592886  2751 net.cpp:301] conv3_1_scale0 needs backward computation.
I1206 10:32:52.592890  2751 net.cpp:301] conv3_1_bn0 needs backward computation.
I1206 10:32:52.592895  2751 net.cpp:301] conv3_1_0 needs backward computation.
I1206 10:32:52.592900  2751 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I1206 10:32:52.592905  2751 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I1206 10:32:52.592908  2751 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I1206 10:32:52.592913  2751 net.cpp:301] conv2_3_scale1 needs backward computation.
I1206 10:32:52.592918  2751 net.cpp:301] conv2_3bn1 needs backward computation.
I1206 10:32:52.592922  2751 net.cpp:301] conv2_3_1 needs backward computation.
I1206 10:32:52.592926  2751 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I1206 10:32:52.592931  2751 net.cpp:301] conv2_3_scale0 needs backward computation.
I1206 10:32:52.592934  2751 net.cpp:301] conv2_3_bn0 needs backward computation.
I1206 10:32:52.592939  2751 net.cpp:301] conv2_3_0 needs backward computation.
I1206 10:32:52.592944  2751 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.592949  2751 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I1206 10:32:52.592954  2751 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I1206 10:32:52.592959  2751 net.cpp:301] conv2_2_scale1 needs backward computation.
I1206 10:32:52.592969  2751 net.cpp:301] conv2_2bn1 needs backward computation.
I1206 10:32:52.592974  2751 net.cpp:301] conv2_2_1 needs backward computation.
I1206 10:32:52.592978  2751 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I1206 10:32:52.592983  2751 net.cpp:301] conv2_2_scale0 needs backward computation.
I1206 10:32:52.592988  2751 net.cpp:301] conv2_2_bn0 needs backward computation.
I1206 10:32:52.592993  2751 net.cpp:301] conv2_2_0 needs backward computation.
I1206 10:32:52.592998  2751 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.593003  2751 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I1206 10:32:52.593006  2751 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I1206 10:32:52.593013  2751 net.cpp:301] conv2_1_scale1 needs backward computation.
I1206 10:32:52.593016  2751 net.cpp:301] conv2_1bn1 needs backward computation.
I1206 10:32:52.593021  2751 net.cpp:301] conv2_1_1 needs backward computation.
I1206 10:32:52.593026  2751 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I1206 10:32:52.593030  2751 net.cpp:301] conv2_1_scale0 needs backward computation.
I1206 10:32:52.593034  2751 net.cpp:301] conv2_1_bn0 needs backward computation.
I1206 10:32:52.593039  2751 net.cpp:301] conv2_1_0 needs backward computation.
I1206 10:32:52.593050  2751 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I1206 10:32:52.593055  2751 net.cpp:301] conv1/ReLU needs backward computation.
I1206 10:32:52.593060  2751 net.cpp:301] conv1/scale needs backward computation.
I1206 10:32:52.593065  2751 net.cpp:301] conv1/bn needs backward computation.
I1206 10:32:52.593068  2751 net.cpp:301] conv1 needs backward computation.
I1206 10:32:52.593075  2751 net.cpp:303] Data1 does not need backward computation.
I1206 10:32:52.593077  2751 net.cpp:348] This network produces output Softmax1
I1206 10:32:52.593134  2751 net.cpp:363] Network initialization done.
I1206 10:32:52.594328  2751 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_20.prototxt
I1206 10:32:52.594344  2751 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1206 10:32:52.594353  2751 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_20.prototxt
I1206 10:32:52.595114  2751 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 10
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
layer {
  name: "prob"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "prob"
}
I1206 10:32:52.595487  2751 layer_factory.hpp:77] Creating layer Data1
I1206 10:32:52.595566  2751 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I1206 10:32:52.595584  2751 net.cpp:128] Creating Layer Data1
I1206 10:32:52.595592  2751 net.cpp:522] Data1 -> data
I1206 10:32:52.595602  2751 net.cpp:522] Data1 -> label
I1206 10:32:52.595751  2751 data_layer.cpp:45] output data size: 10,3,32,32
I1206 10:32:52.596698  2751 net.cpp:172] Setting up Data1
I1206 10:32:52.596714  2751 net.cpp:186] Top shape: 10 3 32 32 (30720)
I1206 10:32:52.596721  2751 net.cpp:186] Top shape: 10 (10)
I1206 10:32:52.596724  2751 net.cpp:194] Memory required for data: 122920
I1206 10:32:52.596729  2751 layer_factory.hpp:77] Creating layer label_Data1_1_split
I1206 10:32:52.596738  2751 net.cpp:128] Creating Layer label_Data1_1_split
I1206 10:32:52.596742  2751 net.cpp:558] label_Data1_1_split <- label
I1206 10:32:52.596751  2751 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I1206 10:32:52.596760  2751 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I1206 10:32:52.596818  2751 net.cpp:172] Setting up label_Data1_1_split
I1206 10:32:52.596825  2751 net.cpp:186] Top shape: 10 (10)
I1206 10:32:52.596830  2751 net.cpp:186] Top shape: 10 (10)
I1206 10:32:52.596834  2751 net.cpp:194] Memory required for data: 123000
I1206 10:32:52.596838  2751 layer_factory.hpp:77] Creating layer conv1
I1206 10:32:52.596850  2751 net.cpp:128] Creating Layer conv1
I1206 10:32:52.596855  2751 net.cpp:558] conv1 <- data
I1206 10:32:52.596887  2751 net.cpp:522] conv1 -> conv1
I1206 10:32:52.598683  2751 net.cpp:172] Setting up conv1
I1206 10:32:52.598716  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.598721  2751 net.cpp:194] Memory required for data: 778360
I1206 10:32:52.598737  2751 layer_factory.hpp:77] Creating layer conv1/bn
I1206 10:32:52.598745  2751 net.cpp:128] Creating Layer conv1/bn
I1206 10:32:52.598750  2751 net.cpp:558] conv1/bn <- conv1
I1206 10:32:52.598759  2751 net.cpp:509] conv1/bn -> conv1 (in-place)
I1206 10:32:52.599026  2751 net.cpp:172] Setting up conv1/bn
I1206 10:32:52.599035  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.599038  2751 net.cpp:194] Memory required for data: 1433720
I1206 10:32:52.599050  2751 layer_factory.hpp:77] Creating layer conv1/scale
I1206 10:32:52.599057  2751 net.cpp:128] Creating Layer conv1/scale
I1206 10:32:52.599061  2751 net.cpp:558] conv1/scale <- conv1
I1206 10:32:52.599069  2751 net.cpp:509] conv1/scale -> conv1 (in-place)
I1206 10:32:52.599115  2751 layer_factory.hpp:77] Creating layer conv1/scale
I1206 10:32:52.599481  2751 net.cpp:172] Setting up conv1/scale
I1206 10:32:52.599495  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.599499  2751 net.cpp:194] Memory required for data: 2089080
I1206 10:32:52.599508  2751 layer_factory.hpp:77] Creating layer conv1/ReLU
I1206 10:32:52.599514  2751 net.cpp:128] Creating Layer conv1/ReLU
I1206 10:32:52.599519  2751 net.cpp:558] conv1/ReLU <- conv1
I1206 10:32:52.599525  2751 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I1206 10:32:52.600117  2751 net.cpp:172] Setting up conv1/ReLU
I1206 10:32:52.600129  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.600133  2751 net.cpp:194] Memory required for data: 2744440
I1206 10:32:52.600138  2751 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I1206 10:32:52.600145  2751 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I1206 10:32:52.600149  2751 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I1206 10:32:52.600158  2751 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I1206 10:32:52.600167  2751 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I1206 10:32:52.600219  2751 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I1206 10:32:52.600240  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.600247  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.600251  2751 net.cpp:194] Memory required for data: 4055160
I1206 10:32:52.600255  2751 layer_factory.hpp:77] Creating layer conv2_1_0
I1206 10:32:52.600270  2751 net.cpp:128] Creating Layer conv2_1_0
I1206 10:32:52.600275  2751 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I1206 10:32:52.600281  2751 net.cpp:522] conv2_1_0 -> conv2_1_0
I1206 10:32:52.602218  2751 net.cpp:172] Setting up conv2_1_0
I1206 10:32:52.602241  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.602247  2751 net.cpp:194] Memory required for data: 4710520
I1206 10:32:52.602262  2751 layer_factory.hpp:77] Creating layer conv2_1_bn0
I1206 10:32:52.602277  2751 net.cpp:128] Creating Layer conv2_1_bn0
I1206 10:32:52.602283  2751 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I1206 10:32:52.602290  2751 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I1206 10:32:52.602573  2751 net.cpp:172] Setting up conv2_1_bn0
I1206 10:32:52.602583  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.602587  2751 net.cpp:194] Memory required for data: 5365880
I1206 10:32:52.602598  2751 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1206 10:32:52.602605  2751 net.cpp:128] Creating Layer conv2_1_scale0
I1206 10:32:52.602609  2751 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I1206 10:32:52.602614  2751 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I1206 10:32:52.602705  2751 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1206 10:32:52.602905  2751 net.cpp:172] Setting up conv2_1_scale0
I1206 10:32:52.602916  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.602927  2751 net.cpp:194] Memory required for data: 6021240
I1206 10:32:52.602944  2751 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I1206 10:32:52.602967  2751 net.cpp:128] Creating Layer conv2_1_ReLU0
I1206 10:32:52.602977  2751 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I1206 10:32:52.603005  2751 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I1206 10:32:52.603559  2751 net.cpp:172] Setting up conv2_1_ReLU0
I1206 10:32:52.603581  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.603586  2751 net.cpp:194] Memory required for data: 6676600
I1206 10:32:52.603591  2751 layer_factory.hpp:77] Creating layer conv2_1_1
I1206 10:32:52.603606  2751 net.cpp:128] Creating Layer conv2_1_1
I1206 10:32:52.603615  2751 net.cpp:558] conv2_1_1 <- conv2_1_0
I1206 10:32:52.603624  2751 net.cpp:522] conv2_1_1 -> conv2_1_1
I1206 10:32:52.605003  2751 net.cpp:172] Setting up conv2_1_1
I1206 10:32:52.605032  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.605036  2751 net.cpp:194] Memory required for data: 7331960
I1206 10:32:52.605046  2751 layer_factory.hpp:77] Creating layer conv2_1bn1
I1206 10:32:52.605060  2751 net.cpp:128] Creating Layer conv2_1bn1
I1206 10:32:52.605065  2751 net.cpp:558] conv2_1bn1 <- conv2_1_1
I1206 10:32:52.605074  2751 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I1206 10:32:52.605346  2751 net.cpp:172] Setting up conv2_1bn1
I1206 10:32:52.605356  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.605360  2751 net.cpp:194] Memory required for data: 7987320
I1206 10:32:52.605373  2751 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1206 10:32:52.605384  2751 net.cpp:128] Creating Layer conv2_1_scale1
I1206 10:32:52.605391  2751 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I1206 10:32:52.605396  2751 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I1206 10:32:52.605446  2751 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1206 10:32:52.605624  2751 net.cpp:172] Setting up conv2_1_scale1
I1206 10:32:52.605635  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.605639  2751 net.cpp:194] Memory required for data: 8642680
I1206 10:32:52.605648  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I1206 10:32:52.605656  2751 net.cpp:128] Creating Layer conv2_Eltwise_1
I1206 10:32:52.605665  2751 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I1206 10:32:52.605670  2751 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I1206 10:32:52.605676  2751 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I1206 10:32:52.605707  2751 net.cpp:172] Setting up conv2_Eltwise_1
I1206 10:32:52.605716  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.605720  2751 net.cpp:194] Memory required for data: 9298040
I1206 10:32:52.605724  2751 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I1206 10:32:52.605731  2751 net.cpp:128] Creating Layer conv2_1ReLU_1
I1206 10:32:52.605736  2751 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I1206 10:32:52.605742  2751 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I1206 10:32:52.605981  2751 net.cpp:172] Setting up conv2_1ReLU_1
I1206 10:32:52.605994  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.606001  2751 net.cpp:194] Memory required for data: 9953400
I1206 10:32:52.606005  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.606015  2751 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.606022  2751 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I1206 10:32:52.606029  2751 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1206 10:32:52.606040  2751 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1206 10:32:52.606092  2751 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1206 10:32:52.606102  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.606108  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.606112  2751 net.cpp:194] Memory required for data: 11264120
I1206 10:32:52.606117  2751 layer_factory.hpp:77] Creating layer conv2_2_0
I1206 10:32:52.606128  2751 net.cpp:128] Creating Layer conv2_2_0
I1206 10:32:52.606148  2751 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1206 10:32:52.606158  2751 net.cpp:522] conv2_2_0 -> conv2_2_0
I1206 10:32:52.607455  2751 net.cpp:172] Setting up conv2_2_0
I1206 10:32:52.607481  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.607486  2751 net.cpp:194] Memory required for data: 11919480
I1206 10:32:52.607496  2751 layer_factory.hpp:77] Creating layer conv2_2_bn0
I1206 10:32:52.607507  2751 net.cpp:128] Creating Layer conv2_2_bn0
I1206 10:32:52.607514  2751 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I1206 10:32:52.607522  2751 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I1206 10:32:52.607789  2751 net.cpp:172] Setting up conv2_2_bn0
I1206 10:32:52.607800  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.607803  2751 net.cpp:194] Memory required for data: 12574840
I1206 10:32:52.607812  2751 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1206 10:32:52.607821  2751 net.cpp:128] Creating Layer conv2_2_scale0
I1206 10:32:52.607825  2751 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I1206 10:32:52.607831  2751 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I1206 10:32:52.607880  2751 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1206 10:32:52.608027  2751 net.cpp:172] Setting up conv2_2_scale0
I1206 10:32:52.608037  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.608042  2751 net.cpp:194] Memory required for data: 13230200
I1206 10:32:52.608048  2751 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I1206 10:32:52.608057  2751 net.cpp:128] Creating Layer conv2_2_ReLU0
I1206 10:32:52.608064  2751 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I1206 10:32:52.608072  2751 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I1206 10:32:52.608332  2751 net.cpp:172] Setting up conv2_2_ReLU0
I1206 10:32:52.608348  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.608352  2751 net.cpp:194] Memory required for data: 13885560
I1206 10:32:52.608359  2751 layer_factory.hpp:77] Creating layer conv2_2_1
I1206 10:32:52.608372  2751 net.cpp:128] Creating Layer conv2_2_1
I1206 10:32:52.608379  2751 net.cpp:558] conv2_2_1 <- conv2_2_0
I1206 10:32:52.608389  2751 net.cpp:522] conv2_2_1 -> conv2_2_1
I1206 10:32:52.609747  2751 net.cpp:172] Setting up conv2_2_1
I1206 10:32:52.609773  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.609777  2751 net.cpp:194] Memory required for data: 14540920
I1206 10:32:52.609787  2751 layer_factory.hpp:77] Creating layer conv2_2bn1
I1206 10:32:52.609803  2751 net.cpp:128] Creating Layer conv2_2bn1
I1206 10:32:52.609812  2751 net.cpp:558] conv2_2bn1 <- conv2_2_1
I1206 10:32:52.609820  2751 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I1206 10:32:52.610090  2751 net.cpp:172] Setting up conv2_2bn1
I1206 10:32:52.610100  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.610103  2751 net.cpp:194] Memory required for data: 15196280
I1206 10:32:52.610117  2751 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1206 10:32:52.610126  2751 net.cpp:128] Creating Layer conv2_2_scale1
I1206 10:32:52.610131  2751 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I1206 10:32:52.610137  2751 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I1206 10:32:52.610188  2751 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1206 10:32:52.610342  2751 net.cpp:172] Setting up conv2_2_scale1
I1206 10:32:52.610352  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.610357  2751 net.cpp:194] Memory required for data: 15851640
I1206 10:32:52.610363  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I1206 10:32:52.610370  2751 net.cpp:128] Creating Layer conv2_Eltwise_2
I1206 10:32:52.610375  2751 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1206 10:32:52.610380  2751 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I1206 10:32:52.610391  2751 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I1206 10:32:52.610421  2751 net.cpp:172] Setting up conv2_Eltwise_2
I1206 10:32:52.610430  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.610450  2751 net.cpp:194] Memory required for data: 16507000
I1206 10:32:52.610455  2751 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I1206 10:32:52.610461  2751 net.cpp:128] Creating Layer conv2_2ReLU_1
I1206 10:32:52.610466  2751 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I1206 10:32:52.610471  2751 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I1206 10:32:52.610911  2751 net.cpp:172] Setting up conv2_2ReLU_1
I1206 10:32:52.610931  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.610936  2751 net.cpp:194] Memory required for data: 17162360
I1206 10:32:52.610941  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.610950  2751 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.610958  2751 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I1206 10:32:52.610968  2751 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1206 10:32:52.610977  2751 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1206 10:32:52.611034  2751 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1206 10:32:52.611044  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.611050  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.611057  2751 net.cpp:194] Memory required for data: 18473080
I1206 10:32:52.611063  2751 layer_factory.hpp:77] Creating layer conv2_3_0
I1206 10:32:52.611074  2751 net.cpp:128] Creating Layer conv2_3_0
I1206 10:32:52.611081  2751 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1206 10:32:52.611090  2751 net.cpp:522] conv2_3_0 -> conv2_3_0
I1206 10:32:52.612413  2751 net.cpp:172] Setting up conv2_3_0
I1206 10:32:52.612437  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.612442  2751 net.cpp:194] Memory required for data: 19128440
I1206 10:32:52.612453  2751 layer_factory.hpp:77] Creating layer conv2_3_bn0
I1206 10:32:52.612462  2751 net.cpp:128] Creating Layer conv2_3_bn0
I1206 10:32:52.612469  2751 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I1206 10:32:52.612479  2751 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I1206 10:32:52.612751  2751 net.cpp:172] Setting up conv2_3_bn0
I1206 10:32:52.612761  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.612766  2751 net.cpp:194] Memory required for data: 19783800
I1206 10:32:52.612776  2751 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1206 10:32:52.612783  2751 net.cpp:128] Creating Layer conv2_3_scale0
I1206 10:32:52.612790  2751 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I1206 10:32:52.612798  2751 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I1206 10:32:52.612848  2751 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1206 10:32:52.613001  2751 net.cpp:172] Setting up conv2_3_scale0
I1206 10:32:52.613013  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.613019  2751 net.cpp:194] Memory required for data: 20439160
I1206 10:32:52.613027  2751 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I1206 10:32:52.613036  2751 net.cpp:128] Creating Layer conv2_3_ReLU0
I1206 10:32:52.613040  2751 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I1206 10:32:52.613045  2751 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I1206 10:32:52.613291  2751 net.cpp:172] Setting up conv2_3_ReLU0
I1206 10:32:52.613303  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.613307  2751 net.cpp:194] Memory required for data: 21094520
I1206 10:32:52.613312  2751 layer_factory.hpp:77] Creating layer conv2_3_1
I1206 10:32:52.613325  2751 net.cpp:128] Creating Layer conv2_3_1
I1206 10:32:52.613333  2751 net.cpp:558] conv2_3_1 <- conv2_3_0
I1206 10:32:52.613342  2751 net.cpp:522] conv2_3_1 -> conv2_3_1
I1206 10:32:52.614667  2751 net.cpp:172] Setting up conv2_3_1
I1206 10:32:52.614693  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.614698  2751 net.cpp:194] Memory required for data: 21749880
I1206 10:32:52.614707  2751 layer_factory.hpp:77] Creating layer conv2_3bn1
I1206 10:32:52.614742  2751 net.cpp:128] Creating Layer conv2_3bn1
I1206 10:32:52.614750  2751 net.cpp:558] conv2_3bn1 <- conv2_3_1
I1206 10:32:52.614758  2751 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I1206 10:32:52.615036  2751 net.cpp:172] Setting up conv2_3bn1
I1206 10:32:52.615046  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615051  2751 net.cpp:194] Memory required for data: 22405240
I1206 10:32:52.615061  2751 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1206 10:32:52.615069  2751 net.cpp:128] Creating Layer conv2_3_scale1
I1206 10:32:52.615074  2751 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I1206 10:32:52.615083  2751 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I1206 10:32:52.615133  2751 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1206 10:32:52.615283  2751 net.cpp:172] Setting up conv2_3_scale1
I1206 10:32:52.615291  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615296  2751 net.cpp:194] Memory required for data: 23060600
I1206 10:32:52.615303  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I1206 10:32:52.615310  2751 net.cpp:128] Creating Layer conv2_Eltwise_3
I1206 10:32:52.615317  2751 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1206 10:32:52.615324  2751 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I1206 10:32:52.615332  2751 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I1206 10:32:52.615361  2751 net.cpp:172] Setting up conv2_Eltwise_3
I1206 10:32:52.615372  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615380  2751 net.cpp:194] Memory required for data: 23715960
I1206 10:32:52.615384  2751 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I1206 10:32:52.615391  2751 net.cpp:128] Creating Layer conv2_3ReLU_1
I1206 10:32:52.615396  2751 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I1206 10:32:52.615401  2751 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I1206 10:32:52.615648  2751 net.cpp:172] Setting up conv2_3ReLU_1
I1206 10:32:52.615662  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615671  2751 net.cpp:194] Memory required for data: 24371320
I1206 10:32:52.615675  2751 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.615682  2751 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.615687  2751 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I1206 10:32:52.615694  2751 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1206 10:32:52.615707  2751 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1206 10:32:52.615762  2751 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1206 10:32:52.615772  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615777  2751 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1206 10:32:52.615782  2751 net.cpp:194] Memory required for data: 25682040
I1206 10:32:52.615785  2751 layer_factory.hpp:77] Creating layer conv3_1_0
I1206 10:32:52.615800  2751 net.cpp:128] Creating Layer conv3_1_0
I1206 10:32:52.615805  2751 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1206 10:32:52.615813  2751 net.cpp:522] conv3_1_0 -> conv3_1_0
I1206 10:32:52.617211  2751 net.cpp:172] Setting up conv3_1_0
I1206 10:32:52.617238  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.617244  2751 net.cpp:194] Memory required for data: 26009720
I1206 10:32:52.617252  2751 layer_factory.hpp:77] Creating layer conv3_1_bn0
I1206 10:32:52.617264  2751 net.cpp:128] Creating Layer conv3_1_bn0
I1206 10:32:52.617269  2751 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I1206 10:32:52.617278  2751 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I1206 10:32:52.617538  2751 net.cpp:172] Setting up conv3_1_bn0
I1206 10:32:52.617549  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.617554  2751 net.cpp:194] Memory required for data: 26337400
I1206 10:32:52.617563  2751 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1206 10:32:52.617588  2751 net.cpp:128] Creating Layer conv3_1_scale0
I1206 10:32:52.617592  2751 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I1206 10:32:52.617599  2751 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I1206 10:32:52.617684  2751 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1206 10:32:52.617843  2751 net.cpp:172] Setting up conv3_1_scale0
I1206 10:32:52.617854  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.617859  2751 net.cpp:194] Memory required for data: 26665080
I1206 10:32:52.617867  2751 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I1206 10:32:52.617877  2751 net.cpp:128] Creating Layer conv3_1_ReLU0
I1206 10:32:52.617882  2751 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I1206 10:32:52.617887  2751 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I1206 10:32:52.618165  2751 net.cpp:172] Setting up conv3_1_ReLU0
I1206 10:32:52.618180  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.618185  2751 net.cpp:194] Memory required for data: 26992760
I1206 10:32:52.618189  2751 layer_factory.hpp:77] Creating layer conv3_1_1
I1206 10:32:52.618203  2751 net.cpp:128] Creating Layer conv3_1_1
I1206 10:32:52.618208  2751 net.cpp:558] conv3_1_1 <- conv3_1_0
I1206 10:32:52.618216  2751 net.cpp:522] conv3_1_1 -> conv3_1_1
I1206 10:32:52.619765  2751 net.cpp:172] Setting up conv3_1_1
I1206 10:32:52.619808  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.619813  2751 net.cpp:194] Memory required for data: 27320440
I1206 10:32:52.619827  2751 layer_factory.hpp:77] Creating layer conv3_1bn1
I1206 10:32:52.619837  2751 net.cpp:128] Creating Layer conv3_1bn1
I1206 10:32:52.619843  2751 net.cpp:558] conv3_1bn1 <- conv3_1_1
I1206 10:32:52.619855  2751 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I1206 10:32:52.620121  2751 net.cpp:172] Setting up conv3_1bn1
I1206 10:32:52.620132  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.620137  2751 net.cpp:194] Memory required for data: 27648120
I1206 10:32:52.620146  2751 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1206 10:32:52.620153  2751 net.cpp:128] Creating Layer conv3_1_scale1
I1206 10:32:52.620157  2751 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I1206 10:32:52.620167  2751 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I1206 10:32:52.620218  2751 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1206 10:32:52.620378  2751 net.cpp:172] Setting up conv3_1_scale1
I1206 10:32:52.620388  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.620393  2751 net.cpp:194] Memory required for data: 27975800
I1206 10:32:52.620400  2751 layer_factory.hpp:77] Creating layer conv3_1_down
I1206 10:32:52.620412  2751 net.cpp:128] Creating Layer conv3_1_down
I1206 10:32:52.620417  2751 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1206 10:32:52.620427  2751 net.cpp:522] conv3_1_down -> conv3_1_down
I1206 10:32:52.621731  2751 net.cpp:172] Setting up conv3_1_down
I1206 10:32:52.621757  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.621762  2751 net.cpp:194] Memory required for data: 28303480
I1206 10:32:52.621781  2751 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I1206 10:32:52.621794  2751 net.cpp:128] Creating Layer conv3_1_bn_down
I1206 10:32:52.621803  2751 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I1206 10:32:52.621812  2751 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I1206 10:32:52.622076  2751 net.cpp:172] Setting up conv3_1_bn_down
I1206 10:32:52.622086  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.622089  2751 net.cpp:194] Memory required for data: 28631160
I1206 10:32:52.622099  2751 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1206 10:32:52.622108  2751 net.cpp:128] Creating Layer conv3_1_scale_down
I1206 10:32:52.622112  2751 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I1206 10:32:52.622122  2751 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I1206 10:32:52.622171  2751 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1206 10:32:52.622339  2751 net.cpp:172] Setting up conv3_1_scale_down
I1206 10:32:52.622350  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.622354  2751 net.cpp:194] Memory required for data: 28958840
I1206 10:32:52.622362  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I1206 10:32:52.622371  2751 net.cpp:128] Creating Layer conv3_Eltwise_1
I1206 10:32:52.622380  2751 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I1206 10:32:52.622385  2751 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I1206 10:32:52.622390  2751 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I1206 10:32:52.622416  2751 net.cpp:172] Setting up conv3_Eltwise_1
I1206 10:32:52.622424  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.622428  2751 net.cpp:194] Memory required for data: 29286520
I1206 10:32:52.622432  2751 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I1206 10:32:52.622438  2751 net.cpp:128] Creating Layer conv3_1ReLU_1
I1206 10:32:52.622442  2751 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I1206 10:32:52.622448  2751 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I1206 10:32:52.623045  2751 net.cpp:172] Setting up conv3_1ReLU_1
I1206 10:32:52.623066  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.623072  2751 net.cpp:194] Memory required for data: 29614200
I1206 10:32:52.623077  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.623085  2751 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.623092  2751 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I1206 10:32:52.623101  2751 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1206 10:32:52.623113  2751 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1206 10:32:52.623173  2751 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1206 10:32:52.623183  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.623189  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.623193  2751 net.cpp:194] Memory required for data: 30269560
I1206 10:32:52.623198  2751 layer_factory.hpp:77] Creating layer conv3_2_0
I1206 10:32:52.623209  2751 net.cpp:128] Creating Layer conv3_2_0
I1206 10:32:52.623216  2751 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1206 10:32:52.623255  2751 net.cpp:522] conv3_2_0 -> conv3_2_0
I1206 10:32:52.624760  2751 net.cpp:172] Setting up conv3_2_0
I1206 10:32:52.624786  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.624791  2751 net.cpp:194] Memory required for data: 30597240
I1206 10:32:52.624801  2751 layer_factory.hpp:77] Creating layer conv3_2_bn0
I1206 10:32:52.624814  2751 net.cpp:128] Creating Layer conv3_2_bn0
I1206 10:32:52.624820  2751 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I1206 10:32:52.624827  2751 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I1206 10:32:52.625124  2751 net.cpp:172] Setting up conv3_2_bn0
I1206 10:32:52.625139  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.625145  2751 net.cpp:194] Memory required for data: 30924920
I1206 10:32:52.625157  2751 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1206 10:32:52.625166  2751 net.cpp:128] Creating Layer conv3_2_scale0
I1206 10:32:52.625171  2751 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I1206 10:32:52.625177  2751 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I1206 10:32:52.625231  2751 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1206 10:32:52.625385  2751 net.cpp:172] Setting up conv3_2_scale0
I1206 10:32:52.625396  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.625401  2751 net.cpp:194] Memory required for data: 31252600
I1206 10:32:52.625408  2751 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I1206 10:32:52.625416  2751 net.cpp:128] Creating Layer conv3_2_ReLU0
I1206 10:32:52.625422  2751 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I1206 10:32:52.625428  2751 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I1206 10:32:52.625665  2751 net.cpp:172] Setting up conv3_2_ReLU0
I1206 10:32:52.625694  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.625699  2751 net.cpp:194] Memory required for data: 31580280
I1206 10:32:52.625703  2751 layer_factory.hpp:77] Creating layer conv3_2_1
I1206 10:32:52.625718  2751 net.cpp:128] Creating Layer conv3_2_1
I1206 10:32:52.625723  2751 net.cpp:558] conv3_2_1 <- conv3_2_0
I1206 10:32:52.625731  2751 net.cpp:522] conv3_2_1 -> conv3_2_1
I1206 10:32:52.627177  2751 net.cpp:172] Setting up conv3_2_1
I1206 10:32:52.627202  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.627207  2751 net.cpp:194] Memory required for data: 31907960
I1206 10:32:52.627216  2751 layer_factory.hpp:77] Creating layer conv3_2bn1
I1206 10:32:52.627228  2751 net.cpp:128] Creating Layer conv3_2bn1
I1206 10:32:52.627233  2751 net.cpp:558] conv3_2bn1 <- conv3_2_1
I1206 10:32:52.627246  2751 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I1206 10:32:52.627513  2751 net.cpp:172] Setting up conv3_2bn1
I1206 10:32:52.627523  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.627528  2751 net.cpp:194] Memory required for data: 32235640
I1206 10:32:52.627537  2751 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1206 10:32:52.627545  2751 net.cpp:128] Creating Layer conv3_2_scale1
I1206 10:32:52.627550  2751 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I1206 10:32:52.627557  2751 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I1206 10:32:52.627606  2751 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1206 10:32:52.627764  2751 net.cpp:172] Setting up conv3_2_scale1
I1206 10:32:52.627774  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.627779  2751 net.cpp:194] Memory required for data: 32563320
I1206 10:32:52.627786  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I1206 10:32:52.627795  2751 net.cpp:128] Creating Layer conv3_Eltwise_2
I1206 10:32:52.627800  2751 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1206 10:32:52.627805  2751 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I1206 10:32:52.627811  2751 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I1206 10:32:52.627836  2751 net.cpp:172] Setting up conv3_Eltwise_2
I1206 10:32:52.627843  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.627847  2751 net.cpp:194] Memory required for data: 32891000
I1206 10:32:52.627851  2751 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I1206 10:32:52.627857  2751 net.cpp:128] Creating Layer conv3_2ReLU_1
I1206 10:32:52.627862  2751 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I1206 10:32:52.627867  2751 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I1206 10:32:52.628105  2751 net.cpp:172] Setting up conv3_2ReLU_1
I1206 10:32:52.628119  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.628123  2751 net.cpp:194] Memory required for data: 33218680
I1206 10:32:52.628129  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.628135  2751 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.628139  2751 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I1206 10:32:52.628149  2751 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1206 10:32:52.628156  2751 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1206 10:32:52.628213  2751 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1206 10:32:52.628237  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.628245  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.628249  2751 net.cpp:194] Memory required for data: 33874040
I1206 10:32:52.628253  2751 layer_factory.hpp:77] Creating layer conv3_3_0
I1206 10:32:52.628265  2751 net.cpp:128] Creating Layer conv3_3_0
I1206 10:32:52.628270  2751 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1206 10:32:52.628278  2751 net.cpp:522] conv3_3_0 -> conv3_3_0
I1206 10:32:52.629717  2751 net.cpp:172] Setting up conv3_3_0
I1206 10:32:52.629757  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.629762  2751 net.cpp:194] Memory required for data: 34201720
I1206 10:32:52.629771  2751 layer_factory.hpp:77] Creating layer conv3_3_bn0
I1206 10:32:52.629783  2751 net.cpp:128] Creating Layer conv3_3_bn0
I1206 10:32:52.629788  2751 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I1206 10:32:52.629801  2751 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I1206 10:32:52.630076  2751 net.cpp:172] Setting up conv3_3_bn0
I1206 10:32:52.630087  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.630091  2751 net.cpp:194] Memory required for data: 34529400
I1206 10:32:52.630101  2751 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1206 10:32:52.630107  2751 net.cpp:128] Creating Layer conv3_3_scale0
I1206 10:32:52.630112  2751 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I1206 10:32:52.630117  2751 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I1206 10:32:52.630168  2751 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1206 10:32:52.630328  2751 net.cpp:172] Setting up conv3_3_scale0
I1206 10:32:52.630339  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.630343  2751 net.cpp:194] Memory required for data: 34857080
I1206 10:32:52.630352  2751 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I1206 10:32:52.630360  2751 net.cpp:128] Creating Layer conv3_3_ReLU0
I1206 10:32:52.630364  2751 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I1206 10:32:52.630370  2751 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I1206 10:32:52.630808  2751 net.cpp:172] Setting up conv3_3_ReLU0
I1206 10:32:52.630829  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.630834  2751 net.cpp:194] Memory required for data: 35184760
I1206 10:32:52.630839  2751 layer_factory.hpp:77] Creating layer conv3_3_1
I1206 10:32:52.630858  2751 net.cpp:128] Creating Layer conv3_3_1
I1206 10:32:52.630864  2751 net.cpp:558] conv3_3_1 <- conv3_3_0
I1206 10:32:52.630872  2751 net.cpp:522] conv3_3_1 -> conv3_3_1
I1206 10:32:52.632330  2751 net.cpp:172] Setting up conv3_3_1
I1206 10:32:52.632359  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.632364  2751 net.cpp:194] Memory required for data: 35512440
I1206 10:32:52.632374  2751 layer_factory.hpp:77] Creating layer conv3_3bn1
I1206 10:32:52.632382  2751 net.cpp:128] Creating Layer conv3_3bn1
I1206 10:32:52.632387  2751 net.cpp:558] conv3_3bn1 <- conv3_3_1
I1206 10:32:52.632400  2751 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I1206 10:32:52.632671  2751 net.cpp:172] Setting up conv3_3bn1
I1206 10:32:52.632681  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.632686  2751 net.cpp:194] Memory required for data: 35840120
I1206 10:32:52.632695  2751 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1206 10:32:52.632704  2751 net.cpp:128] Creating Layer conv3_3_scale1
I1206 10:32:52.632709  2751 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I1206 10:32:52.632714  2751 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I1206 10:32:52.632763  2751 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1206 10:32:52.632917  2751 net.cpp:172] Setting up conv3_3_scale1
I1206 10:32:52.632930  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.632935  2751 net.cpp:194] Memory required for data: 36167800
I1206 10:32:52.632942  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I1206 10:32:52.632949  2751 net.cpp:128] Creating Layer conv3_Eltwise_3
I1206 10:32:52.632953  2751 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1206 10:32:52.632959  2751 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I1206 10:32:52.632966  2751 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I1206 10:32:52.632992  2751 net.cpp:172] Setting up conv3_Eltwise_3
I1206 10:32:52.632998  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.633002  2751 net.cpp:194] Memory required for data: 36495480
I1206 10:32:52.633006  2751 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I1206 10:32:52.633013  2751 net.cpp:128] Creating Layer conv3_3ReLU_1
I1206 10:32:52.633031  2751 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I1206 10:32:52.633040  2751 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I1206 10:32:52.633289  2751 net.cpp:172] Setting up conv3_3ReLU_1
I1206 10:32:52.633306  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.633311  2751 net.cpp:194] Memory required for data: 36823160
I1206 10:32:52.633316  2751 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.633323  2751 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.633328  2751 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I1206 10:32:52.633337  2751 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1206 10:32:52.633345  2751 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1206 10:32:52.633401  2751 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1206 10:32:52.633411  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.633419  2751 net.cpp:186] Top shape: 10 32 16 16 (81920)
I1206 10:32:52.633421  2751 net.cpp:194] Memory required for data: 37478520
I1206 10:32:52.633426  2751 layer_factory.hpp:77] Creating layer conv4_1_0
I1206 10:32:52.633438  2751 net.cpp:128] Creating Layer conv4_1_0
I1206 10:32:52.633443  2751 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1206 10:32:52.633453  2751 net.cpp:522] conv4_1_0 -> conv4_1_0
I1206 10:32:52.635066  2751 net.cpp:172] Setting up conv4_1_0
I1206 10:32:52.635092  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.635097  2751 net.cpp:194] Memory required for data: 37642360
I1206 10:32:52.635107  2751 layer_factory.hpp:77] Creating layer conv4_1_bn0
I1206 10:32:52.635118  2751 net.cpp:128] Creating Layer conv4_1_bn0
I1206 10:32:52.635123  2751 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I1206 10:32:52.635130  2751 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I1206 10:32:52.635412  2751 net.cpp:172] Setting up conv4_1_bn0
I1206 10:32:52.635423  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.635427  2751 net.cpp:194] Memory required for data: 37806200
I1206 10:32:52.635437  2751 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1206 10:32:52.635445  2751 net.cpp:128] Creating Layer conv4_1_scale0
I1206 10:32:52.635450  2751 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I1206 10:32:52.635457  2751 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I1206 10:32:52.635506  2751 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1206 10:32:52.635668  2751 net.cpp:172] Setting up conv4_1_scale0
I1206 10:32:52.635677  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.635682  2751 net.cpp:194] Memory required for data: 37970040
I1206 10:32:52.635689  2751 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I1206 10:32:52.635699  2751 net.cpp:128] Creating Layer conv4_1_ReLU0
I1206 10:32:52.635704  2751 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I1206 10:32:52.635710  2751 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I1206 10:32:52.635953  2751 net.cpp:172] Setting up conv4_1_ReLU0
I1206 10:32:52.635969  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.635974  2751 net.cpp:194] Memory required for data: 38133880
I1206 10:32:52.635978  2751 layer_factory.hpp:77] Creating layer conv4_1_1
I1206 10:32:52.635990  2751 net.cpp:128] Creating Layer conv4_1_1
I1206 10:32:52.635996  2751 net.cpp:558] conv4_1_1 <- conv4_1_0
I1206 10:32:52.636005  2751 net.cpp:522] conv4_1_1 -> conv4_1_1
I1206 10:32:52.637923  2751 net.cpp:172] Setting up conv4_1_1
I1206 10:32:52.637948  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.637953  2751 net.cpp:194] Memory required for data: 38297720
I1206 10:32:52.637962  2751 layer_factory.hpp:77] Creating layer conv4_1bn1
I1206 10:32:52.637974  2751 net.cpp:128] Creating Layer conv4_1bn1
I1206 10:32:52.637980  2751 net.cpp:558] conv4_1bn1 <- conv4_1_1
I1206 10:32:52.637991  2751 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I1206 10:32:52.638267  2751 net.cpp:172] Setting up conv4_1bn1
I1206 10:32:52.638293  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.638298  2751 net.cpp:194] Memory required for data: 38461560
I1206 10:32:52.638306  2751 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1206 10:32:52.638314  2751 net.cpp:128] Creating Layer conv4_1_scale1
I1206 10:32:52.638319  2751 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I1206 10:32:52.638324  2751 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I1206 10:32:52.638378  2751 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1206 10:32:52.638538  2751 net.cpp:172] Setting up conv4_1_scale1
I1206 10:32:52.638551  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.638556  2751 net.cpp:194] Memory required for data: 38625400
I1206 10:32:52.638563  2751 layer_factory.hpp:77] Creating layer conv4_1_down
I1206 10:32:52.638576  2751 net.cpp:128] Creating Layer conv4_1_down
I1206 10:32:52.638581  2751 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1206 10:32:52.638588  2751 net.cpp:522] conv4_1_down -> conv4_1_down
I1206 10:32:52.639936  2751 net.cpp:172] Setting up conv4_1_down
I1206 10:32:52.639961  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.639966  2751 net.cpp:194] Memory required for data: 38789240
I1206 10:32:52.639976  2751 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I1206 10:32:52.639984  2751 net.cpp:128] Creating Layer conv4_1_bn_down
I1206 10:32:52.639989  2751 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I1206 10:32:52.639998  2751 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I1206 10:32:52.640291  2751 net.cpp:172] Setting up conv4_1_bn_down
I1206 10:32:52.640302  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.640306  2751 net.cpp:194] Memory required for data: 38953080
I1206 10:32:52.640316  2751 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1206 10:32:52.640326  2751 net.cpp:128] Creating Layer conv4_1_scale_down
I1206 10:32:52.640331  2751 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I1206 10:32:52.640336  2751 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I1206 10:32:52.640389  2751 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1206 10:32:52.640549  2751 net.cpp:172] Setting up conv4_1_scale_down
I1206 10:32:52.640558  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.640563  2751 net.cpp:194] Memory required for data: 39116920
I1206 10:32:52.640570  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I1206 10:32:52.640585  2751 net.cpp:128] Creating Layer conv4_Eltwise_1
I1206 10:32:52.640590  2751 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I1206 10:32:52.640595  2751 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I1206 10:32:52.640601  2751 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I1206 10:32:52.640630  2751 net.cpp:172] Setting up conv4_Eltwise_1
I1206 10:32:52.640640  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.640645  2751 net.cpp:194] Memory required for data: 39280760
I1206 10:32:52.640650  2751 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I1206 10:32:52.640655  2751 net.cpp:128] Creating Layer conv4_1ReLU_1
I1206 10:32:52.640660  2751 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I1206 10:32:52.640667  2751 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I1206 10:32:52.641106  2751 net.cpp:172] Setting up conv4_1ReLU_1
I1206 10:32:52.641127  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.641132  2751 net.cpp:194] Memory required for data: 39444600
I1206 10:32:52.641136  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.641146  2751 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.641152  2751 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I1206 10:32:52.641160  2751 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1206 10:32:52.641168  2751 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1206 10:32:52.641244  2751 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1206 10:32:52.641252  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.641258  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.641263  2751 net.cpp:194] Memory required for data: 39772280
I1206 10:32:52.641268  2751 layer_factory.hpp:77] Creating layer conv4_2_0
I1206 10:32:52.641279  2751 net.cpp:128] Creating Layer conv4_2_0
I1206 10:32:52.641284  2751 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1206 10:32:52.641294  2751 net.cpp:522] conv4_2_0 -> conv4_2_0
I1206 10:32:52.643457  2751 net.cpp:172] Setting up conv4_2_0
I1206 10:32:52.643482  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.643486  2751 net.cpp:194] Memory required for data: 39936120
I1206 10:32:52.643497  2751 layer_factory.hpp:77] Creating layer conv4_2_bn0
I1206 10:32:52.643507  2751 net.cpp:128] Creating Layer conv4_2_bn0
I1206 10:32:52.643513  2751 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I1206 10:32:52.643522  2751 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I1206 10:32:52.643816  2751 net.cpp:172] Setting up conv4_2_bn0
I1206 10:32:52.643828  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.643832  2751 net.cpp:194] Memory required for data: 40099960
I1206 10:32:52.643842  2751 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1206 10:32:52.643849  2751 net.cpp:128] Creating Layer conv4_2_scale0
I1206 10:32:52.643853  2751 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I1206 10:32:52.643862  2751 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I1206 10:32:52.643910  2751 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1206 10:32:52.644074  2751 net.cpp:172] Setting up conv4_2_scale0
I1206 10:32:52.644084  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.644088  2751 net.cpp:194] Memory required for data: 40263800
I1206 10:32:52.644096  2751 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I1206 10:32:52.644102  2751 net.cpp:128] Creating Layer conv4_2_ReLU0
I1206 10:32:52.644107  2751 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I1206 10:32:52.644114  2751 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I1206 10:32:52.644372  2751 net.cpp:172] Setting up conv4_2_ReLU0
I1206 10:32:52.644390  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.644397  2751 net.cpp:194] Memory required for data: 40427640
I1206 10:32:52.644400  2751 layer_factory.hpp:77] Creating layer conv4_2_1
I1206 10:32:52.644413  2751 net.cpp:128] Creating Layer conv4_2_1
I1206 10:32:52.644418  2751 net.cpp:558] conv4_2_1 <- conv4_2_0
I1206 10:32:52.644428  2751 net.cpp:522] conv4_2_1 -> conv4_2_1
I1206 10:32:52.646345  2751 net.cpp:172] Setting up conv4_2_1
I1206 10:32:52.646368  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.646373  2751 net.cpp:194] Memory required for data: 40591480
I1206 10:32:52.646384  2751 layer_factory.hpp:77] Creating layer conv4_2bn1
I1206 10:32:52.646394  2751 net.cpp:128] Creating Layer conv4_2bn1
I1206 10:32:52.646399  2751 net.cpp:558] conv4_2bn1 <- conv4_2_1
I1206 10:32:52.646405  2751 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I1206 10:32:52.646690  2751 net.cpp:172] Setting up conv4_2bn1
I1206 10:32:52.646701  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.646706  2751 net.cpp:194] Memory required for data: 40755320
I1206 10:32:52.646730  2751 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1206 10:32:52.646739  2751 net.cpp:128] Creating Layer conv4_2_scale1
I1206 10:32:52.646744  2751 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I1206 10:32:52.646750  2751 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I1206 10:32:52.646805  2751 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1206 10:32:52.646965  2751 net.cpp:172] Setting up conv4_2_scale1
I1206 10:32:52.646978  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.646982  2751 net.cpp:194] Memory required for data: 40919160
I1206 10:32:52.646991  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I1206 10:32:52.646996  2751 net.cpp:128] Creating Layer conv4_Eltwise_2
I1206 10:32:52.647017  2751 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1206 10:32:52.647022  2751 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I1206 10:32:52.647030  2751 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I1206 10:32:52.647061  2751 net.cpp:172] Setting up conv4_Eltwise_2
I1206 10:32:52.647073  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.647078  2751 net.cpp:194] Memory required for data: 41083000
I1206 10:32:52.647081  2751 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I1206 10:32:52.647087  2751 net.cpp:128] Creating Layer conv4_2ReLU_1
I1206 10:32:52.647091  2751 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I1206 10:32:52.647097  2751 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I1206 10:32:52.647346  2751 net.cpp:172] Setting up conv4_2ReLU_1
I1206 10:32:52.647361  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.647366  2751 net.cpp:194] Memory required for data: 41246840
I1206 10:32:52.647370  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.647377  2751 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.647382  2751 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I1206 10:32:52.647389  2751 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1206 10:32:52.647398  2751 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1206 10:32:52.647454  2751 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1206 10:32:52.647462  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.647469  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.647472  2751 net.cpp:194] Memory required for data: 41574520
I1206 10:32:52.647476  2751 layer_factory.hpp:77] Creating layer conv4_3_0
I1206 10:32:52.647490  2751 net.cpp:128] Creating Layer conv4_3_0
I1206 10:32:52.647495  2751 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1206 10:32:52.647502  2751 net.cpp:522] conv4_3_0 -> conv4_3_0
I1206 10:32:52.649590  2751 net.cpp:172] Setting up conv4_3_0
I1206 10:32:52.649617  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.649622  2751 net.cpp:194] Memory required for data: 41738360
I1206 10:32:52.649634  2751 layer_factory.hpp:77] Creating layer conv4_3_bn0
I1206 10:32:52.649643  2751 net.cpp:128] Creating Layer conv4_3_bn0
I1206 10:32:52.649650  2751 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I1206 10:32:52.649660  2751 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I1206 10:32:52.649968  2751 net.cpp:172] Setting up conv4_3_bn0
I1206 10:32:52.649978  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.649983  2751 net.cpp:194] Memory required for data: 41902200
I1206 10:32:52.649992  2751 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1206 10:32:52.649999  2751 net.cpp:128] Creating Layer conv4_3_scale0
I1206 10:32:52.650004  2751 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I1206 10:32:52.650012  2751 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I1206 10:32:52.650064  2751 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1206 10:32:52.650231  2751 net.cpp:172] Setting up conv4_3_scale0
I1206 10:32:52.650243  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.650246  2751 net.cpp:194] Memory required for data: 42066040
I1206 10:32:52.650254  2751 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I1206 10:32:52.650262  2751 net.cpp:128] Creating Layer conv4_3_ReLU0
I1206 10:32:52.650267  2751 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I1206 10:32:52.650274  2751 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I1206 10:32:52.650524  2751 net.cpp:172] Setting up conv4_3_ReLU0
I1206 10:32:52.650538  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.650543  2751 net.cpp:194] Memory required for data: 42229880
I1206 10:32:52.650547  2751 layer_factory.hpp:77] Creating layer conv4_3_1
I1206 10:32:52.650562  2751 net.cpp:128] Creating Layer conv4_3_1
I1206 10:32:52.650583  2751 net.cpp:558] conv4_3_1 <- conv4_3_0
I1206 10:32:52.650590  2751 net.cpp:522] conv4_3_1 -> conv4_3_1
I1206 10:32:52.653843  2751 net.cpp:172] Setting up conv4_3_1
I1206 10:32:52.653872  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.653877  2751 net.cpp:194] Memory required for data: 42393720
I1206 10:32:52.653893  2751 layer_factory.hpp:77] Creating layer conv4_3bn1
I1206 10:32:52.653908  2751 net.cpp:128] Creating Layer conv4_3bn1
I1206 10:32:52.653913  2751 net.cpp:558] conv4_3bn1 <- conv4_3_1
I1206 10:32:52.653923  2751 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I1206 10:32:52.654214  2751 net.cpp:172] Setting up conv4_3bn1
I1206 10:32:52.654224  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.654228  2751 net.cpp:194] Memory required for data: 42557560
I1206 10:32:52.654237  2751 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1206 10:32:52.654247  2751 net.cpp:128] Creating Layer conv4_3_scale1
I1206 10:32:52.654251  2751 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I1206 10:32:52.654258  2751 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I1206 10:32:52.654321  2751 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1206 10:32:52.654487  2751 net.cpp:172] Setting up conv4_3_scale1
I1206 10:32:52.654496  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.654501  2751 net.cpp:194] Memory required for data: 42721400
I1206 10:32:52.654508  2751 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I1206 10:32:52.654523  2751 net.cpp:128] Creating Layer conv4_Eltwise_3
I1206 10:32:52.654532  2751 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1206 10:32:52.654538  2751 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I1206 10:32:52.654544  2751 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I1206 10:32:52.654575  2751 net.cpp:172] Setting up conv4_Eltwise_3
I1206 10:32:52.654584  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.654588  2751 net.cpp:194] Memory required for data: 42885240
I1206 10:32:52.654593  2751 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I1206 10:32:52.654599  2751 net.cpp:128] Creating Layer conv4_3ReLU_1
I1206 10:32:52.654604  2751 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I1206 10:32:52.654613  2751 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I1206 10:32:52.655047  2751 net.cpp:172] Setting up conv4_3ReLU_1
I1206 10:32:52.655067  2751 net.cpp:186] Top shape: 10 64 8 8 (40960)
I1206 10:32:52.655072  2751 net.cpp:194] Memory required for data: 43049080
I1206 10:32:52.655077  2751 layer_factory.hpp:77] Creating layer Pooling1
I1206 10:32:52.655091  2751 net.cpp:128] Creating Layer Pooling1
I1206 10:32:52.655097  2751 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I1206 10:32:52.655105  2751 net.cpp:522] Pooling1 -> Pooling1
I1206 10:32:52.655375  2751 net.cpp:172] Setting up Pooling1
I1206 10:32:52.655388  2751 net.cpp:186] Top shape: 10 64 1 1 (640)
I1206 10:32:52.655393  2751 net.cpp:194] Memory required for data: 43051640
I1206 10:32:52.655397  2751 layer_factory.hpp:77] Creating layer fc1
I1206 10:32:52.655411  2751 net.cpp:128] Creating Layer fc1
I1206 10:32:52.655418  2751 net.cpp:558] fc1 <- Pooling1
I1206 10:32:52.655426  2751 net.cpp:522] fc1 -> fc1
I1206 10:32:52.656805  2751 net.cpp:172] Setting up fc1
I1206 10:32:52.656831  2751 net.cpp:186] Top shape: 10 10 1 1 (100)
I1206 10:32:52.656834  2751 net.cpp:194] Memory required for data: 43052040
I1206 10:32:52.656844  2751 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I1206 10:32:52.656854  2751 net.cpp:128] Creating Layer fc1_fc1_0_split
I1206 10:32:52.656860  2751 net.cpp:558] fc1_fc1_0_split <- fc1
I1206 10:32:52.656872  2751 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I1206 10:32:52.656880  2751 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I1206 10:32:52.656939  2751 net.cpp:172] Setting up fc1_fc1_0_split
I1206 10:32:52.656951  2751 net.cpp:186] Top shape: 10 10 1 1 (100)
I1206 10:32:52.656957  2751 net.cpp:186] Top shape: 10 10 1 1 (100)
I1206 10:32:52.656960  2751 net.cpp:194] Memory required for data: 43052840
I1206 10:32:52.656982  2751 layer_factory.hpp:77] Creating layer Softmax1
I1206 10:32:52.656989  2751 net.cpp:128] Creating Layer Softmax1
I1206 10:32:52.656994  2751 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I1206 10:32:52.656999  2751 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I1206 10:32:52.657006  2751 net.cpp:522] Softmax1 -> Softmax1
I1206 10:32:52.657016  2751 layer_factory.hpp:77] Creating layer Softmax1
I1206 10:32:52.657394  2751 net.cpp:172] Setting up Softmax1
I1206 10:32:52.657414  2751 net.cpp:186] Top shape: (1)
I1206 10:32:52.657419  2751 net.cpp:189]     with loss weight 1
I1206 10:32:52.657435  2751 net.cpp:194] Memory required for data: 43052844
I1206 10:32:52.657440  2751 layer_factory.hpp:77] Creating layer prob
I1206 10:32:52.657449  2751 net.cpp:128] Creating Layer prob
I1206 10:32:52.657454  2751 net.cpp:558] prob <- fc1_fc1_0_split_1
I1206 10:32:52.657459  2751 net.cpp:558] prob <- label_Data1_1_split_1
I1206 10:32:52.657464  2751 net.cpp:522] prob -> prob
I1206 10:32:52.657477  2751 net.cpp:172] Setting up prob
I1206 10:32:52.657485  2751 net.cpp:186] Top shape: (1)
I1206 10:32:52.657490  2751 net.cpp:194] Memory required for data: 43052848
I1206 10:32:52.657493  2751 net.cpp:303] prob does not need backward computation.
I1206 10:32:52.657498  2751 net.cpp:301] Softmax1 needs backward computation.
I1206 10:32:52.657505  2751 net.cpp:301] fc1_fc1_0_split needs backward computation.
I1206 10:32:52.657508  2751 net.cpp:301] fc1 needs backward computation.
I1206 10:32:52.657512  2751 net.cpp:301] Pooling1 needs backward computation.
I1206 10:32:52.657517  2751 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I1206 10:32:52.657521  2751 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I1206 10:32:52.657526  2751 net.cpp:301] conv4_3_scale1 needs backward computation.
I1206 10:32:52.657531  2751 net.cpp:301] conv4_3bn1 needs backward computation.
I1206 10:32:52.657534  2751 net.cpp:301] conv4_3_1 needs backward computation.
I1206 10:32:52.657539  2751 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I1206 10:32:52.657543  2751 net.cpp:301] conv4_3_scale0 needs backward computation.
I1206 10:32:52.657547  2751 net.cpp:301] conv4_3_bn0 needs backward computation.
I1206 10:32:52.657552  2751 net.cpp:301] conv4_3_0 needs backward computation.
I1206 10:32:52.657557  2751 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.657560  2751 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I1206 10:32:52.657565  2751 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I1206 10:32:52.657572  2751 net.cpp:301] conv4_2_scale1 needs backward computation.
I1206 10:32:52.657575  2751 net.cpp:301] conv4_2bn1 needs backward computation.
I1206 10:32:52.657579  2751 net.cpp:301] conv4_2_1 needs backward computation.
I1206 10:32:52.657584  2751 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I1206 10:32:52.657588  2751 net.cpp:301] conv4_2_scale0 needs backward computation.
I1206 10:32:52.657593  2751 net.cpp:301] conv4_2_bn0 needs backward computation.
I1206 10:32:52.657596  2751 net.cpp:301] conv4_2_0 needs backward computation.
I1206 10:32:52.657601  2751 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.657606  2751 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I1206 10:32:52.657611  2751 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I1206 10:32:52.657615  2751 net.cpp:301] conv4_1_scale_down needs backward computation.
I1206 10:32:52.657620  2751 net.cpp:301] conv4_1_bn_down needs backward computation.
I1206 10:32:52.657624  2751 net.cpp:301] conv4_1_down needs backward computation.
I1206 10:32:52.657629  2751 net.cpp:301] conv4_1_scale1 needs backward computation.
I1206 10:32:52.657634  2751 net.cpp:301] conv4_1bn1 needs backward computation.
I1206 10:32:52.657639  2751 net.cpp:301] conv4_1_1 needs backward computation.
I1206 10:32:52.657642  2751 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I1206 10:32:52.657647  2751 net.cpp:301] conv4_1_scale0 needs backward computation.
I1206 10:32:52.657668  2751 net.cpp:301] conv4_1_bn0 needs backward computation.
I1206 10:32:52.657673  2751 net.cpp:301] conv4_1_0 needs backward computation.
I1206 10:32:52.657678  2751 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I1206 10:32:52.657683  2751 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I1206 10:32:52.657687  2751 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I1206 10:32:52.657692  2751 net.cpp:301] conv3_3_scale1 needs backward computation.
I1206 10:32:52.657699  2751 net.cpp:301] conv3_3bn1 needs backward computation.
I1206 10:32:52.657703  2751 net.cpp:301] conv3_3_1 needs backward computation.
I1206 10:32:52.657708  2751 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I1206 10:32:52.657712  2751 net.cpp:301] conv3_3_scale0 needs backward computation.
I1206 10:32:52.657716  2751 net.cpp:301] conv3_3_bn0 needs backward computation.
I1206 10:32:52.657721  2751 net.cpp:301] conv3_3_0 needs backward computation.
I1206 10:32:52.657727  2751 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.657730  2751 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I1206 10:32:52.657735  2751 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I1206 10:32:52.657740  2751 net.cpp:301] conv3_2_scale1 needs backward computation.
I1206 10:32:52.657744  2751 net.cpp:301] conv3_2bn1 needs backward computation.
I1206 10:32:52.657749  2751 net.cpp:301] conv3_2_1 needs backward computation.
I1206 10:32:52.657753  2751 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I1206 10:32:52.657757  2751 net.cpp:301] conv3_2_scale0 needs backward computation.
I1206 10:32:52.657763  2751 net.cpp:301] conv3_2_bn0 needs backward computation.
I1206 10:32:52.657766  2751 net.cpp:301] conv3_2_0 needs backward computation.
I1206 10:32:52.657770  2751 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.657775  2751 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I1206 10:32:52.657780  2751 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I1206 10:32:52.657785  2751 net.cpp:301] conv3_1_scale_down needs backward computation.
I1206 10:32:52.657789  2751 net.cpp:301] conv3_1_bn_down needs backward computation.
I1206 10:32:52.657793  2751 net.cpp:301] conv3_1_down needs backward computation.
I1206 10:32:52.657799  2751 net.cpp:301] conv3_1_scale1 needs backward computation.
I1206 10:32:52.657804  2751 net.cpp:301] conv3_1bn1 needs backward computation.
I1206 10:32:52.657807  2751 net.cpp:301] conv3_1_1 needs backward computation.
I1206 10:32:52.657812  2751 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I1206 10:32:52.657816  2751 net.cpp:301] conv3_1_scale0 needs backward computation.
I1206 10:32:52.657820  2751 net.cpp:301] conv3_1_bn0 needs backward computation.
I1206 10:32:52.657824  2751 net.cpp:301] conv3_1_0 needs backward computation.
I1206 10:32:52.657829  2751 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I1206 10:32:52.657835  2751 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I1206 10:32:52.657838  2751 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I1206 10:32:52.657843  2751 net.cpp:301] conv2_3_scale1 needs backward computation.
I1206 10:32:52.657848  2751 net.cpp:301] conv2_3bn1 needs backward computation.
I1206 10:32:52.657852  2751 net.cpp:301] conv2_3_1 needs backward computation.
I1206 10:32:52.657857  2751 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I1206 10:32:52.657861  2751 net.cpp:301] conv2_3_scale0 needs backward computation.
I1206 10:32:52.657866  2751 net.cpp:301] conv2_3_bn0 needs backward computation.
I1206 10:32:52.657869  2751 net.cpp:301] conv2_3_0 needs backward computation.
I1206 10:32:52.657874  2751 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I1206 10:32:52.657879  2751 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I1206 10:32:52.657883  2751 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I1206 10:32:52.657896  2751 net.cpp:301] conv2_2_scale1 needs backward computation.
I1206 10:32:52.657901  2751 net.cpp:301] conv2_2bn1 needs backward computation.
I1206 10:32:52.657904  2751 net.cpp:301] conv2_2_1 needs backward computation.
I1206 10:32:52.657909  2751 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I1206 10:32:52.657913  2751 net.cpp:301] conv2_2_scale0 needs backward computation.
I1206 10:32:52.657918  2751 net.cpp:301] conv2_2_bn0 needs backward computation.
I1206 10:32:52.657922  2751 net.cpp:301] conv2_2_0 needs backward computation.
I1206 10:32:52.657928  2751 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I1206 10:32:52.657935  2751 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I1206 10:32:52.657940  2751 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I1206 10:32:52.657945  2751 net.cpp:301] conv2_1_scale1 needs backward computation.
I1206 10:32:52.657949  2751 net.cpp:301] conv2_1bn1 needs backward computation.
I1206 10:32:52.657954  2751 net.cpp:301] conv2_1_1 needs backward computation.
I1206 10:32:52.657958  2751 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I1206 10:32:52.657963  2751 net.cpp:301] conv2_1_scale0 needs backward computation.
I1206 10:32:52.657968  2751 net.cpp:301] conv2_1_bn0 needs backward computation.
I1206 10:32:52.657972  2751 net.cpp:301] conv2_1_0 needs backward computation.
I1206 10:32:52.657977  2751 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I1206 10:32:52.657984  2751 net.cpp:301] conv1/ReLU needs backward computation.
I1206 10:32:52.657989  2751 net.cpp:301] conv1/scale needs backward computation.
I1206 10:32:52.657994  2751 net.cpp:301] conv1/bn needs backward computation.
I1206 10:32:52.657997  2751 net.cpp:301] conv1 needs backward computation.
I1206 10:32:52.658002  2751 net.cpp:303] label_Data1_1_split does not need backward computation.
I1206 10:32:52.658008  2751 net.cpp:303] Data1 does not need backward computation.
I1206 10:32:52.658011  2751 net.cpp:348] This network produces output Softmax1
I1206 10:32:52.658016  2751 net.cpp:348] This network produces output prob
I1206 10:32:52.658078  2751 net.cpp:363] Network initialization done.
I1206 10:32:52.658458  2751 solver.cpp:110] Solver scaffolding done.
I1206 10:32:52.666370  2751 caffe.cpp:313] Starting Optimization
I1206 10:32:52.666391  2751 solver.cpp:425] Solving ResNet-20
I1206 10:32:52.666396  2751 solver.cpp:427] Learning Rate Policy: multistep
I1206 10:32:52.669636  2751 solver.cpp:514] Iteration 0, Testing net (#0)
I1206 10:32:52.775897  2751 blocking_queue.cpp:49] Waiting for data
I1206 10:33:01.355799  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:33:01.367158  2751 solver.cpp:580]     Test net output #0: Softmax1 = 87.3361 (* 1 = 87.3361 loss)
I1206 10:33:01.367177  2751 solver.cpp:580]     Test net output #1: prob = 0
I1206 10:33:01.466163  2751 solver.cpp:357] Iteration 0 (-5.75046e-37 iter/s, 8.8s/100 iters), loss = 3.87523
I1206 10:33:01.466207  2751 solver.cpp:376]     Train net output #0: Softmax1 = 3.87523 (* 1 = 3.87523 loss)
I1206 10:33:01.466231  2751 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I1206 10:33:19.705868  2751 solver.cpp:357] Iteration 100 (5.48239 iter/s, 18.2402s/100 iters), loss = 1.77612
I1206 10:33:19.705927  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.77612 (* 1 = 1.77612 loss)
I1206 10:33:19.705938  2751 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I1206 10:33:38.401157  2751 solver.cpp:357] Iteration 200 (5.34879 iter/s, 18.6958s/100 iters), loss = 1.41219
I1206 10:33:38.401284  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.41219 (* 1 = 1.41219 loss)
I1206 10:33:38.401294  2751 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I1206 10:33:58.525111  2751 solver.cpp:357] Iteration 300 (4.96907 iter/s, 20.1245s/100 iters), loss = 1.36584
I1206 10:33:58.525172  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.36584 (* 1 = 1.36584 loss)
I1206 10:33:58.525187  2751 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I1206 10:34:08.119695  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:34:09.607120  2751 solver.cpp:357] Iteration 400 (9.02339 iter/s, 11.0823s/100 iters), loss = 1.25141
I1206 10:34:09.607353  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.25141 (* 1 = 1.25141 loss)
I1206 10:34:09.607364  2751 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I1206 10:34:20.180079  2751 solver.cpp:514] Iteration 500, Testing net (#0)
I1206 10:34:23.439682  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:34:23.452364  2751 solver.cpp:580]     Test net output #0: Softmax1 = 4.10977 (* 1 = 4.10977 loss)
I1206 10:34:23.452390  2751 solver.cpp:580]     Test net output #1: prob = 0.144
I1206 10:34:23.558010  2751 solver.cpp:357] Iteration 500 (7.16788 iter/s, 13.9511s/100 iters), loss = 1.11763
I1206 10:34:23.558073  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.11763 (* 1 = 1.11763 loss)
I1206 10:34:23.558086  2751 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I1206 10:34:34.249709  2751 solver.cpp:357] Iteration 600 (9.35279 iter/s, 10.692s/100 iters), loss = 1.03075
I1206 10:34:34.249775  2751 solver.cpp:376]     Train net output #0: Softmax1 = 1.03075 (* 1 = 1.03075 loss)
I1206 10:34:34.249784  2751 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I1206 10:34:44.923115  2751 solver.cpp:357] Iteration 700 (9.36882 iter/s, 10.6737s/100 iters), loss = 0.915484
I1206 10:34:44.923270  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.915484 (* 1 = 0.915484 loss)
I1206 10:34:44.923280  2751 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I1206 10:34:53.160892  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:34:55.613893  2751 solver.cpp:357] Iteration 800 (9.35367 iter/s, 10.691s/100 iters), loss = 0.945412
I1206 10:34:55.613960  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.945412 (* 1 = 0.945412 loss)
I1206 10:34:55.613968  2751 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I1206 10:35:06.314214  2751 solver.cpp:357] Iteration 900 (9.34526 iter/s, 10.7006s/100 iters), loss = 0.899566
I1206 10:35:06.314278  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.899566 (* 1 = 0.899566 loss)
I1206 10:35:06.314288  2751 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I1206 10:35:16.891443  2751 solver.cpp:514] Iteration 1000, Testing net (#0)
I1206 10:35:20.091938  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:35:20.104568  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.81512 (* 1 = 2.81512 loss)
I1206 10:35:20.104593  2751 solver.cpp:580]     Test net output #1: prob = 0.1581
I1206 10:35:20.210618  2751 solver.cpp:357] Iteration 1000 (7.19589 iter/s, 13.8968s/100 iters), loss = 0.827746
I1206 10:35:20.210660  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.827746 (* 1 = 0.827746 loss)
I1206 10:35:20.210671  2751 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I1206 10:35:30.920990  2751 solver.cpp:357] Iteration 1100 (9.33646 iter/s, 10.7107s/100 iters), loss = 0.722301
I1206 10:35:30.921054  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.722301 (* 1 = 0.722301 loss)
I1206 10:35:30.921063  2751 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I1206 10:35:38.104424  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:35:41.626873  2751 solver.cpp:357] Iteration 1200 (9.3404 iter/s, 10.7062s/100 iters), loss = 0.78252
I1206 10:35:41.626935  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.78252 (* 1 = 0.78252 loss)
I1206 10:35:41.626946  2751 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I1206 10:35:52.338253  2751 solver.cpp:357] Iteration 1300 (9.3356 iter/s, 10.7117s/100 iters), loss = 0.648833
I1206 10:35:52.338407  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.648833 (* 1 = 0.648833 loss)
I1206 10:35:52.338418  2751 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I1206 10:36:03.035147  2751 solver.cpp:357] Iteration 1400 (9.34832 iter/s, 10.6971s/100 iters), loss = 0.634855
I1206 10:36:03.035209  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.634855 (* 1 = 0.634855 loss)
I1206 10:36:03.035220  2751 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I1206 10:36:13.638568  2751 solver.cpp:514] Iteration 1500, Testing net (#0)
I1206 10:36:16.847448  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:36:16.859570  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.90265 (* 1 = 2.90265 loss)
I1206 10:36:16.859598  2751 solver.cpp:580]     Test net output #1: prob = 0.1029
I1206 10:36:16.859622  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_1500.caffemodel
I1206 10:36:16.889223  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_1500.solverstate
I1206 10:36:16.891721  2751 solver.cpp:593]     Max_acc: 0.1029  with iter: 1500
I1206 10:36:17.000630  2751 solver.cpp:357] Iteration 1500 (7.16029 iter/s, 13.9659s/100 iters), loss = 0.618454
I1206 10:36:17.000680  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.618454 (* 1 = 0.618454 loss)
I1206 10:36:17.000695  2751 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I1206 10:36:23.215330  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:36:27.702667  2751 solver.cpp:357] Iteration 1600 (9.34374 iter/s, 10.7024s/100 iters), loss = 0.649409
I1206 10:36:27.702731  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.649409 (* 1 = 0.649409 loss)
I1206 10:36:27.702741  2751 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I1206 10:36:38.405588  2751 solver.cpp:357] Iteration 1700 (9.34298 iter/s, 10.7032s/100 iters), loss = 0.740957
I1206 10:36:38.405650  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.740957 (* 1 = 0.740957 loss)
I1206 10:36:38.405661  2751 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I1206 10:36:49.115624  2751 solver.cpp:357] Iteration 1800 (9.33677 iter/s, 10.7103s/100 iters), loss = 0.895165
I1206 10:36:49.115685  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.895165 (* 1 = 0.895165 loss)
I1206 10:36:49.115697  2751 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I1206 10:36:59.834197  2751 solver.cpp:357] Iteration 1900 (9.32933 iter/s, 10.7189s/100 iters), loss = 0.592847
I1206 10:36:59.834357  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.592847 (* 1 = 0.592847 loss)
I1206 10:36:59.834365  2751 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I1206 10:37:05.092352  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:37:10.453691  2751 solver.cpp:514] Iteration 2000, Testing net (#0)
I1206 10:37:13.662456  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:37:13.674803  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.87044 (* 1 = 2.87044 loss)
I1206 10:37:13.674830  2751 solver.cpp:580]     Test net output #1: prob = 0.1688
I1206 10:37:13.674844  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_2000.caffemodel
I1206 10:37:13.682915  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_2000.solverstate
I1206 10:37:13.685325  2751 solver.cpp:593]     Max_acc: 0.1688  with iter: 2000
I1206 10:37:13.790787  2751 solver.cpp:357] Iteration 2000 (7.1649 iter/s, 13.9569s/100 iters), loss = 0.568076
I1206 10:37:13.790832  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.568076 (* 1 = 0.568076 loss)
I1206 10:37:13.790844  2751 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I1206 10:37:24.509043  2751 solver.cpp:357] Iteration 2100 (9.32959 iter/s, 10.7186s/100 iters), loss = 0.708163
I1206 10:37:24.509109  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.708163 (* 1 = 0.708163 loss)
I1206 10:37:24.509121  2751 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I1206 10:37:35.221508  2751 solver.cpp:357] Iteration 2200 (9.33465 iter/s, 10.7128s/100 iters), loss = 0.630509
I1206 10:37:35.221700  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.630509 (* 1 = 0.630509 loss)
I1206 10:37:35.221711  2751 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I1206 10:37:45.919564  2751 solver.cpp:357] Iteration 2300 (9.34733 iter/s, 10.6982s/100 iters), loss = 0.493122
I1206 10:37:45.919625  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.493122 (* 1 = 0.493122 loss)
I1206 10:37:45.919634  2751 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I1206 10:37:50.116431  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:37:56.649214  2751 solver.cpp:357] Iteration 2400 (9.31969 iter/s, 10.73s/100 iters), loss = 0.57714
I1206 10:37:56.649278  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.57714 (* 1 = 0.57714 loss)
I1206 10:37:56.649287  2751 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I1206 10:38:07.269178  2751 solver.cpp:514] Iteration 2500, Testing net (#0)
I1206 10:38:10.479846  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:38:10.492282  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.63946 (* 1 = 2.63946 loss)
I1206 10:38:10.492308  2751 solver.cpp:580]     Test net output #1: prob = 0.1928
I1206 10:38:10.492322  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_2500.caffemodel
I1206 10:38:10.500197  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_2500.solverstate
I1206 10:38:10.502615  2751 solver.cpp:593]     Max_acc: 0.1928  with iter: 2500
I1206 10:38:10.609035  2751 solver.cpp:357] Iteration 2500 (7.16319 iter/s, 13.9603s/100 iters), loss = 0.580054
I1206 10:38:10.609082  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.580054 (* 1 = 0.580054 loss)
I1206 10:38:10.609094  2751 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I1206 10:38:21.354030  2751 solver.cpp:357] Iteration 2600 (9.30637 iter/s, 10.7453s/100 iters), loss = 0.761495
I1206 10:38:21.354094  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.761495 (* 1 = 0.761495 loss)
I1206 10:38:21.354104  2751 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I1206 10:38:32.068073  2751 solver.cpp:357] Iteration 2700 (9.33327 iter/s, 10.7144s/100 iters), loss = 0.725041
I1206 10:38:32.068135  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.725041 (* 1 = 0.725041 loss)
I1206 10:38:32.068147  2751 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I1206 10:38:35.295485  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:38:42.797353  2751 solver.cpp:357] Iteration 2800 (9.32001 iter/s, 10.7296s/100 iters), loss = 0.43024
I1206 10:38:42.797500  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.43024 (* 1 = 0.43024 loss)
I1206 10:38:42.797510  2751 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I1206 10:38:53.525220  2751 solver.cpp:357] Iteration 2900 (9.32131 iter/s, 10.7281s/100 iters), loss = 0.564605
I1206 10:38:53.525283  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.564605 (* 1 = 0.564605 loss)
I1206 10:38:53.525295  2751 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I1206 10:39:04.142216  2751 solver.cpp:514] Iteration 3000, Testing net (#0)
I1206 10:39:07.348146  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:39:07.360267  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.27422 (* 1 = 2.27422 loss)
I1206 10:39:07.360293  2751 solver.cpp:580]     Test net output #1: prob = 0.2901
I1206 10:39:07.360307  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_3000.caffemodel
I1206 10:39:07.368170  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_3000.solverstate
I1206 10:39:07.370668  2751 solver.cpp:593]     Max_acc: 0.2901  with iter: 3000
I1206 10:39:07.475740  2751 solver.cpp:357] Iteration 3000 (7.16796 iter/s, 13.951s/100 iters), loss = 0.643095
I1206 10:39:07.475781  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.643095 (* 1 = 0.643095 loss)
I1206 10:39:07.475792  2751 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I1206 10:39:18.217237  2751 solver.cpp:357] Iteration 3100 (9.30939 iter/s, 10.7418s/100 iters), loss = 0.558223
I1206 10:39:18.217437  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.558223 (* 1 = 0.558223 loss)
I1206 10:39:18.217447  2751 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I1206 10:39:20.375315  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:39:28.943390  2751 solver.cpp:357] Iteration 3200 (9.32284 iter/s, 10.7263s/100 iters), loss = 0.581954
I1206 10:39:28.943454  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.581954 (* 1 = 0.581954 loss)
I1206 10:39:28.943464  2751 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I1206 10:39:39.676218  2751 solver.cpp:357] Iteration 3300 (9.31693 iter/s, 10.7332s/100 iters), loss = 0.610563
I1206 10:39:39.676285  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.610563 (* 1 = 0.610563 loss)
I1206 10:39:39.676295  2751 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I1206 10:39:50.399675  2751 solver.cpp:357] Iteration 3400 (9.32507 iter/s, 10.7238s/100 iters), loss = 0.429581
I1206 10:39:50.399824  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.429581 (* 1 = 0.429581 loss)
I1206 10:39:50.399834  2751 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I1206 10:40:01.033900  2751 solver.cpp:514] Iteration 3500, Testing net (#0)
I1206 10:40:04.290819  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:40:04.302902  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.54654 (* 1 = 1.54654 loss)
I1206 10:40:04.302929  2751 solver.cpp:580]     Test net output #1: prob = 0.4643
I1206 10:40:04.302942  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_3500.caffemodel
I1206 10:40:04.310837  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_3500.solverstate
I1206 10:40:04.313241  2751 solver.cpp:593]     Max_acc: 0.4643  with iter: 3500
I1206 10:40:04.419064  2751 solver.cpp:357] Iteration 3500 (7.13279 iter/s, 14.0198s/100 iters), loss = 0.654879
I1206 10:40:04.419108  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.654879 (* 1 = 0.654879 loss)
I1206 10:40:04.419121  2751 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I1206 10:40:05.602398  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:40:15.142483  2751 solver.cpp:357] Iteration 3600 (9.32508 iter/s, 10.7238s/100 iters), loss = 0.623427
I1206 10:40:15.142547  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.623427 (* 1 = 0.623427 loss)
I1206 10:40:15.142557  2751 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I1206 10:40:25.873034  2751 solver.cpp:357] Iteration 3700 (9.3189 iter/s, 10.7309s/100 iters), loss = 0.468322
I1206 10:40:25.873185  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.468322 (* 1 = 0.468322 loss)
I1206 10:40:25.873196  2751 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I1206 10:40:36.601238  2751 solver.cpp:357] Iteration 3800 (9.32101 iter/s, 10.7284s/100 iters), loss = 0.435492
I1206 10:40:36.601300  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.435492 (* 1 = 0.435492 loss)
I1206 10:40:36.601310  2751 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I1206 10:40:47.328368  2751 solver.cpp:357] Iteration 3900 (9.32187 iter/s, 10.7275s/100 iters), loss = 0.743231
I1206 10:40:47.328433  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.743231 (* 1 = 0.743231 loss)
I1206 10:40:47.328442  2751 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I1206 10:40:47.549461  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:40:57.949760  2751 solver.cpp:514] Iteration 4000, Testing net (#0)
I1206 10:41:01.126497  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:41:01.139230  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.60235 (* 1 = 1.60235 loss)
I1206 10:41:01.139257  2751 solver.cpp:580]     Test net output #1: prob = 0.3881
I1206 10:41:01.139264  2751 solver.cpp:593]     Max_acc: 0.4643  with iter: 3500
I1206 10:41:01.244971  2751 solver.cpp:357] Iteration 4000 (7.18542 iter/s, 13.9171s/100 iters), loss = 0.549474
I1206 10:41:01.245016  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.549474 (* 1 = 0.549474 loss)
I1206 10:41:01.245029  2751 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I1206 10:41:11.980116  2751 solver.cpp:357] Iteration 4100 (9.31489 iter/s, 10.7355s/100 iters), loss = 0.566935
I1206 10:41:11.980180  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.566935 (* 1 = 0.566935 loss)
I1206 10:41:11.980191  2751 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I1206 10:41:22.688257  2751 solver.cpp:357] Iteration 4200 (9.3384 iter/s, 10.7085s/100 iters), loss = 0.49171
I1206 10:41:22.688320  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.49171 (* 1 = 0.49171 loss)
I1206 10:41:22.688329  2751 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I1206 10:41:32.561163  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:41:33.409613  2751 solver.cpp:357] Iteration 4300 (9.32689 iter/s, 10.7217s/100 iters), loss = 0.493106
I1206 10:41:33.409678  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.493106 (* 1 = 0.493106 loss)
I1206 10:41:33.409687  2751 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I1206 10:41:44.142616  2751 solver.cpp:357] Iteration 4400 (9.31677 iter/s, 10.7333s/100 iters), loss = 0.604127
I1206 10:41:44.142679  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.604127 (* 1 = 0.604127 loss)
I1206 10:41:44.142689  2751 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I1206 10:41:54.754340  2751 solver.cpp:514] Iteration 4500, Testing net (#0)
I1206 10:41:57.974638  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:41:57.986824  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.16892 (* 1 = 1.16892 loss)
I1206 10:41:57.986850  2751 solver.cpp:580]     Test net output #1: prob = 0.5986
I1206 10:41:57.986865  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_4500.caffemodel
I1206 10:41:57.994741  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_4500.solverstate
I1206 10:41:57.997154  2751 solver.cpp:593]     Max_acc: 0.5986  with iter: 4500
I1206 10:41:58.103346  2751 solver.cpp:357] Iteration 4500 (7.16271 iter/s, 13.9612s/100 iters), loss = 0.58441
I1206 10:41:58.103392  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.58441 (* 1 = 0.58441 loss)
I1206 10:41:58.103404  2751 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I1206 10:42:08.824132  2751 solver.cpp:357] Iteration 4600 (9.32737 iter/s, 10.7211s/100 iters), loss = 0.464605
I1206 10:42:08.824301  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.464605 (* 1 = 0.464605 loss)
I1206 10:42:08.824311  2751 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I1206 10:42:17.725152  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:42:19.545182  2751 solver.cpp:357] Iteration 4700 (9.32725 iter/s, 10.7213s/100 iters), loss = 0.374368
I1206 10:42:19.545248  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.374368 (* 1 = 0.374368 loss)
I1206 10:42:19.545258  2751 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I1206 10:42:30.274077  2751 solver.cpp:357] Iteration 4800 (9.32033 iter/s, 10.7292s/100 iters), loss = 0.455628
I1206 10:42:30.274142  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.455628 (* 1 = 0.455628 loss)
I1206 10:42:30.274152  2751 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I1206 10:42:41.001189  2751 solver.cpp:357] Iteration 4900 (9.32188 iter/s, 10.7274s/100 iters), loss = 0.528201
I1206 10:42:41.001329  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.528201 (* 1 = 0.528201 loss)
I1206 10:42:41.001339  2751 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I1206 10:42:51.622983  2751 solver.cpp:514] Iteration 5000, Testing net (#0)
I1206 10:42:54.838691  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:42:54.850826  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.862284 (* 1 = 0.862284 loss)
I1206 10:42:54.850852  2751 solver.cpp:580]     Test net output #1: prob = 0.703701
I1206 10:42:54.850865  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_5000.caffemodel
I1206 10:42:54.858786  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_5000.solverstate
I1206 10:42:54.861183  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:42:54.966966  2751 solver.cpp:357] Iteration 5000 (7.16016 iter/s, 13.9662s/100 iters), loss = 0.368129
I1206 10:42:54.967013  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.368129 (* 1 = 0.368129 loss)
I1206 10:42:54.967025  2751 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I1206 10:43:02.909739  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:43:05.696985  2751 solver.cpp:357] Iteration 5100 (9.31934 iter/s, 10.7304s/100 iters), loss = 0.53506
I1206 10:43:05.697051  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.53506 (* 1 = 0.53506 loss)
I1206 10:43:05.697059  2751 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I1206 10:43:16.420249  2751 solver.cpp:357] Iteration 5200 (9.32523 iter/s, 10.7236s/100 iters), loss = 0.578256
I1206 10:43:16.420419  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.578256 (* 1 = 0.578256 loss)
I1206 10:43:16.420434  2751 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I1206 10:43:27.146574  2751 solver.cpp:357] Iteration 5300 (9.32266 iter/s, 10.7266s/100 iters), loss = 0.58028
I1206 10:43:27.146637  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.58028 (* 1 = 0.58028 loss)
I1206 10:43:27.146651  2751 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I1206 10:43:37.874992  2751 solver.cpp:357] Iteration 5400 (9.32075 iter/s, 10.7288s/100 iters), loss = 0.272289
I1206 10:43:37.875058  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.272289 (* 1 = 0.272289 loss)
I1206 10:43:37.875068  2751 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I1206 10:43:44.744699  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:43:48.478133  2751 solver.cpp:514] Iteration 5500, Testing net (#0)
I1206 10:43:51.677117  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:43:51.688935  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.29036 (* 1 = 1.29036 loss)
I1206 10:43:51.688962  2751 solver.cpp:580]     Test net output #1: prob = 0.5556
I1206 10:43:51.688969  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:43:51.794983  2751 solver.cpp:357] Iteration 5500 (7.18367 iter/s, 13.9205s/100 iters), loss = 0.417308
I1206 10:43:51.795025  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.417308 (* 1 = 0.417308 loss)
I1206 10:43:51.795035  2751 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I1206 10:44:02.505555  2751 solver.cpp:357] Iteration 5600 (9.33626 iter/s, 10.7109s/100 iters), loss = 0.490202
I1206 10:44:02.505620  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.490202 (* 1 = 0.490202 loss)
I1206 10:44:02.505630  2751 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I1206 10:44:13.236197  2751 solver.cpp:357] Iteration 5700 (9.31881 iter/s, 10.731s/100 iters), loss = 0.43642
I1206 10:44:13.236269  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.43642 (* 1 = 0.43642 loss)
I1206 10:44:13.236279  2751 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I1206 10:44:23.962749  2751 solver.cpp:357] Iteration 5800 (9.32237 iter/s, 10.7269s/100 iters), loss = 0.453869
I1206 10:44:23.962893  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.453869 (* 1 = 0.453869 loss)
I1206 10:44:23.962905  2751 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I1206 10:44:29.869879  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:44:34.689175  2751 solver.cpp:357] Iteration 5900 (9.32254 iter/s, 10.7267s/100 iters), loss = 0.598709
I1206 10:44:34.689239  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.598709 (* 1 = 0.598709 loss)
I1206 10:44:34.689249  2751 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I1206 10:44:45.289633  2751 solver.cpp:514] Iteration 6000, Testing net (#0)
I1206 10:44:48.552248  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:44:48.564091  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.56508 (* 1 = 1.56508 loss)
I1206 10:44:48.564119  2751 solver.cpp:580]     Test net output #1: prob = 0.4702
I1206 10:44:48.564126  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:44:48.669971  2751 solver.cpp:357] Iteration 6000 (7.15243 iter/s, 13.9813s/100 iters), loss = 0.415135
I1206 10:44:48.670013  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415135 (* 1 = 0.415135 loss)
I1206 10:44:48.670025  2751 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I1206 10:44:59.391541  2751 solver.cpp:357] Iteration 6100 (9.32668 iter/s, 10.7219s/100 iters), loss = 0.415662
I1206 10:44:59.391737  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415662 (* 1 = 0.415662 loss)
I1206 10:44:59.391747  2751 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I1206 10:45:10.101379  2751 solver.cpp:357] Iteration 6200 (9.33703 iter/s, 10.71s/100 iters), loss = 0.409649
I1206 10:45:10.101444  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.409649 (* 1 = 0.409649 loss)
I1206 10:45:10.101454  2751 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I1206 10:45:14.947856  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:45:20.824002  2751 solver.cpp:357] Iteration 6300 (9.32578 iter/s, 10.723s/100 iters), loss = 0.45183
I1206 10:45:20.824065  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.45183 (* 1 = 0.45183 loss)
I1206 10:45:20.824076  2751 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I1206 10:45:31.545892  2751 solver.cpp:357] Iteration 6400 (9.32642 iter/s, 10.7222s/100 iters), loss = 0.488458
I1206 10:45:31.546039  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.488458 (* 1 = 0.488458 loss)
I1206 10:45:31.546049  2751 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I1206 10:45:42.172039  2751 solver.cpp:514] Iteration 6500, Testing net (#0)
I1206 10:45:45.421139  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:45:45.433284  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.30817 (* 1 = 1.30817 loss)
I1206 10:45:45.433311  2751 solver.cpp:580]     Test net output #1: prob = 0.625201
I1206 10:45:45.433318  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:45:45.539049  2751 solver.cpp:357] Iteration 6500 (7.14615 iter/s, 13.9935s/100 iters), loss = 0.402394
I1206 10:45:45.539090  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.402394 (* 1 = 0.402394 loss)
I1206 10:45:45.539103  2751 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I1206 10:45:56.262446  2751 solver.cpp:357] Iteration 6600 (9.32509 iter/s, 10.7238s/100 iters), loss = 0.423095
I1206 10:45:56.262506  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.423095 (* 1 = 0.423095 loss)
I1206 10:45:56.262517  2751 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I1206 10:46:00.136209  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:46:06.981916  2751 solver.cpp:357] Iteration 6700 (9.32852 iter/s, 10.7198s/100 iters), loss = 0.507422
I1206 10:46:06.982017  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.507422 (* 1 = 0.507422 loss)
I1206 10:46:06.982029  2751 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I1206 10:46:17.711819  2751 solver.cpp:357] Iteration 6800 (9.31948 iter/s, 10.7302s/100 iters), loss = 0.38994
I1206 10:46:17.711881  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.38994 (* 1 = 0.38994 loss)
I1206 10:46:17.711892  2751 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I1206 10:46:28.442296  2751 solver.cpp:357] Iteration 6900 (9.31895 iter/s, 10.7308s/100 iters), loss = 0.446648
I1206 10:46:28.442359  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.446648 (* 1 = 0.446648 loss)
I1206 10:46:28.442370  2751 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I1206 10:46:39.049466  2751 solver.cpp:514] Iteration 7000, Testing net (#0)
I1206 10:46:42.238816  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:46:42.250955  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.21258 (* 1 = 1.21258 loss)
I1206 10:46:42.250983  2751 solver.cpp:580]     Test net output #1: prob = 0.6413
I1206 10:46:42.250990  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:46:42.356854  2751 solver.cpp:357] Iteration 7000 (7.18647 iter/s, 13.915s/100 iters), loss = 0.482318
I1206 10:46:42.356897  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.482318 (* 1 = 0.482318 loss)
I1206 10:46:42.356909  2751 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I1206 10:46:45.259065  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:46:53.092679  2751 solver.cpp:357] Iteration 7100 (9.31429 iter/s, 10.7362s/100 iters), loss = 0.415216
I1206 10:46:53.092742  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415216 (* 1 = 0.415216 loss)
I1206 10:46:53.092754  2751 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I1206 10:47:03.833658  2751 solver.cpp:357] Iteration 7200 (9.30984 iter/s, 10.7413s/100 iters), loss = 0.681099
I1206 10:47:03.833725  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.681099 (* 1 = 0.681099 loss)
I1206 10:47:03.833734  2751 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I1206 10:47:14.565714  2751 solver.cpp:357] Iteration 7300 (9.31758 iter/s, 10.7324s/100 iters), loss = 0.455066
I1206 10:47:14.565870  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.455066 (* 1 = 0.455066 loss)
I1206 10:47:14.565878  2751 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I1206 10:47:25.278694  2751 solver.cpp:357] Iteration 7400 (9.33488 iter/s, 10.7125s/100 iters), loss = 0.422559
I1206 10:47:25.278759  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.422559 (* 1 = 0.422559 loss)
I1206 10:47:25.278769  2751 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I1206 10:47:27.108315  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:47:35.889575  2751 solver.cpp:514] Iteration 7500, Testing net (#0)
I1206 10:47:39.103904  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:47:39.116865  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.96337 (* 1 = 1.96337 loss)
I1206 10:47:39.116892  2751 solver.cpp:580]     Test net output #1: prob = 0.4024
I1206 10:47:39.116899  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:47:39.223325  2751 solver.cpp:357] Iteration 7500 (7.17308 iter/s, 13.941s/100 iters), loss = 0.516873
I1206 10:47:39.223367  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.516873 (* 1 = 0.516873 loss)
I1206 10:47:39.223381  2751 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I1206 10:47:49.940495  2751 solver.cpp:357] Iteration 7600 (9.33302 iter/s, 10.7146s/100 iters), loss = 0.387522
I1206 10:47:49.940639  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.387522 (* 1 = 0.387522 loss)
I1206 10:47:49.940652  2751 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I1206 10:48:00.679572  2751 solver.cpp:357] Iteration 7700 (9.3139 iter/s, 10.7366s/100 iters), loss = 0.402058
I1206 10:48:00.679638  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.402058 (* 1 = 0.402058 loss)
I1206 10:48:00.679647  2751 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I1206 10:48:11.399000  2751 solver.cpp:357] Iteration 7800 (9.33074 iter/s, 10.7173s/100 iters), loss = 0.419386
I1206 10:48:11.399065  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.419386 (* 1 = 0.419386 loss)
I1206 10:48:11.399075  2751 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I1206 10:48:12.265758  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:48:22.129142  2751 solver.cpp:357] Iteration 7900 (9.32127 iter/s, 10.7282s/100 iters), loss = 0.510747
I1206 10:48:22.129297  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.510747 (* 1 = 0.510747 loss)
I1206 10:48:22.129307  2751 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I1206 10:48:32.762323  2751 solver.cpp:514] Iteration 8000, Testing net (#0)
I1206 10:48:35.931272  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:48:35.943413  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.22148 (* 1 = 1.22148 loss)
I1206 10:48:35.943439  2751 solver.cpp:580]     Test net output #1: prob = 0.6314
I1206 10:48:35.943447  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:48:36.049083  2751 solver.cpp:357] Iteration 8000 (7.18518 iter/s, 13.9175s/100 iters), loss = 0.321453
I1206 10:48:36.049125  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.321453 (* 1 = 0.321453 loss)
I1206 10:48:36.049139  2751 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I1206 10:48:46.762156  2751 solver.cpp:357] Iteration 8100 (9.3358 iter/s, 10.7115s/100 iters), loss = 0.421862
I1206 10:48:46.762218  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.421862 (* 1 = 0.421862 loss)
I1206 10:48:46.762231  2751 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I1206 10:48:57.394127  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:48:57.497324  2751 solver.cpp:357] Iteration 8200 (9.31649 iter/s, 10.7337s/100 iters), loss = 0.498953
I1206 10:48:57.497375  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.498953 (* 1 = 0.498953 loss)
I1206 10:48:57.497385  2751 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I1206 10:49:08.229333  2751 solver.cpp:357] Iteration 8300 (9.31912 iter/s, 10.7306s/100 iters), loss = 0.533675
I1206 10:49:08.229395  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.533675 (* 1 = 0.533675 loss)
I1206 10:49:08.229406  2751 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I1206 10:49:18.960011  2751 solver.cpp:357] Iteration 8400 (9.32019 iter/s, 10.7294s/100 iters), loss = 0.423658
I1206 10:49:18.960077  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.423658 (* 1 = 0.423658 loss)
I1206 10:49:18.960086  2751 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I1206 10:49:29.595855  2751 solver.cpp:514] Iteration 8500, Testing net (#0)
I1206 10:49:32.785843  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:49:32.798713  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.04605 (* 1 = 1.04605 loss)
I1206 10:49:32.798740  2751 solver.cpp:580]     Test net output #1: prob = 0.672599
I1206 10:49:32.798748  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:49:32.904350  2751 solver.cpp:357] Iteration 8500 (7.17214 iter/s, 13.9428s/100 iters), loss = 0.437088
I1206 10:49:32.904392  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.437088 (* 1 = 0.437088 loss)
I1206 10:49:32.904402  2751 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I1206 10:49:42.460804  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:49:43.621132  2751 solver.cpp:357] Iteration 8600 (9.33207 iter/s, 10.7157s/100 iters), loss = 0.512344
I1206 10:49:43.621196  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.512344 (* 1 = 0.512344 loss)
I1206 10:49:43.621204  2751 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I1206 10:49:54.343385  2751 solver.cpp:357] Iteration 8700 (9.32725 iter/s, 10.7213s/100 iters), loss = 0.345527
I1206 10:49:54.343451  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.345527 (* 1 = 0.345527 loss)
I1206 10:49:54.343461  2751 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I1206 10:50:05.062641  2751 solver.cpp:357] Iteration 8800 (9.32979 iter/s, 10.7184s/100 iters), loss = 0.467377
I1206 10:50:05.062741  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.467377 (* 1 = 0.467377 loss)
I1206 10:50:05.062753  2751 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I1206 10:50:15.770061  2751 solver.cpp:357] Iteration 8900 (9.34008 iter/s, 10.7066s/100 iters), loss = 0.467595
I1206 10:50:15.770125  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.467595 (* 1 = 0.467595 loss)
I1206 10:50:15.770135  2751 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I1206 10:50:24.366253  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:50:26.398785  2751 solver.cpp:514] Iteration 9000, Testing net (#0)
I1206 10:50:29.638360  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:50:29.650465  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.98165 (* 1 = 1.98165 loss)
I1206 10:50:29.650491  2751 solver.cpp:580]     Test net output #1: prob = 0.447899
I1206 10:50:29.650499  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:50:29.755769  2751 solver.cpp:357] Iteration 9000 (7.15065 iter/s, 13.9847s/100 iters), loss = 0.280371
I1206 10:50:29.755810  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.280371 (* 1 = 0.280371 loss)
I1206 10:50:29.755820  2751 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I1206 10:50:40.484505  2751 solver.cpp:357] Iteration 9100 (9.32134 iter/s, 10.7281s/100 iters), loss = 0.447438
I1206 10:50:40.484704  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.447438 (* 1 = 0.447438 loss)
I1206 10:50:40.484715  2751 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I1206 10:50:51.212355  2751 solver.cpp:357] Iteration 9200 (9.3222 iter/s, 10.7271s/100 iters), loss = 0.444299
I1206 10:50:51.212420  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.444299 (* 1 = 0.444299 loss)
I1206 10:50:51.212430  2751 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I1206 10:51:01.936902  2751 solver.cpp:357] Iteration 9300 (9.32491 iter/s, 10.724s/100 iters), loss = 0.35366
I1206 10:51:01.936965  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.35366 (* 1 = 0.35366 loss)
I1206 10:51:01.936975  2751 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I1206 10:51:09.459542  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:51:12.664127  2751 solver.cpp:357] Iteration 9400 (9.32255 iter/s, 10.7267s/100 iters), loss = 0.449183
I1206 10:51:12.664254  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.449183 (* 1 = 0.449183 loss)
I1206 10:51:12.664268  2751 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I1206 10:51:23.279233  2751 solver.cpp:514] Iteration 9500, Testing net (#0)
I1206 10:51:26.469688  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:51:26.482133  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.85019 (* 1 = 1.85019 loss)
I1206 10:51:26.482161  2751 solver.cpp:580]     Test net output #1: prob = 0.4887
I1206 10:51:26.482168  2751 solver.cpp:593]     Max_acc: 0.703701  with iter: 5000
I1206 10:51:26.587337  2751 solver.cpp:357] Iteration 9500 (7.1826 iter/s, 13.9225s/100 iters), loss = 0.524249
I1206 10:51:26.587379  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.524249 (* 1 = 0.524249 loss)
I1206 10:51:26.587389  2751 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I1206 10:51:37.303550  2751 solver.cpp:357] Iteration 9600 (9.33203 iter/s, 10.7158s/100 iters), loss = 0.544355
I1206 10:51:37.303611  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.544355 (* 1 = 0.544355 loss)
I1206 10:51:37.303623  2751 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I1206 10:51:48.029664  2751 solver.cpp:357] Iteration 9700 (9.3234 iter/s, 10.7257s/100 iters), loss = 0.385213
I1206 10:51:48.029809  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.385213 (* 1 = 0.385213 loss)
I1206 10:51:48.029820  2751 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I1206 10:51:54.571172  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:51:58.744170  2751 solver.cpp:357] Iteration 9800 (9.33355 iter/s, 10.714s/100 iters), loss = 0.381625
I1206 10:51:58.744238  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.381625 (* 1 = 0.381625 loss)
I1206 10:51:58.744247  2751 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I1206 10:52:09.473948  2751 solver.cpp:357] Iteration 9900 (9.32017 iter/s, 10.7294s/100 iters), loss = 0.386497
I1206 10:52:09.474010  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.386497 (* 1 = 0.386497 loss)
I1206 10:52:09.474021  2751 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I1206 10:52:20.084836  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.caffemodel
I1206 10:52:20.092938  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.solverstate
I1206 10:52:20.095685  2751 solver.cpp:514] Iteration 10000, Testing net (#0)
I1206 10:52:23.292407  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:52:23.305037  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.73726 (* 1 = 0.73726 loss)
I1206 10:52:23.305063  2751 solver.cpp:580]     Test net output #1: prob = 0.7457
I1206 10:52:23.305076  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.caffemodel
I1206 10:52:23.310117  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.solverstate
I1206 10:52:23.312598  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:52:23.419075  2751 solver.cpp:357] Iteration 10000 (7.17117 iter/s, 13.9447s/100 iters), loss = 0.399627
I1206 10:52:23.419119  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.399627 (* 1 = 0.399627 loss)
I1206 10:52:23.419133  2751 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I1206 10:52:34.121482  2751 solver.cpp:357] Iteration 10100 (9.34394 iter/s, 10.7021s/100 iters), loss = 0.501949
I1206 10:52:34.121546  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.501949 (* 1 = 0.501949 loss)
I1206 10:52:34.121554  2751 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I1206 10:52:39.700223  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:52:44.833443  2751 solver.cpp:357] Iteration 10200 (9.3356 iter/s, 10.7117s/100 iters), loss = 0.495485
I1206 10:52:44.833508  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.495485 (* 1 = 0.495485 loss)
I1206 10:52:44.833516  2751 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I1206 10:52:55.557850  2751 solver.cpp:357] Iteration 10300 (9.32475 iter/s, 10.7242s/100 iters), loss = 0.465111
I1206 10:52:55.558008  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.465111 (* 1 = 0.465111 loss)
I1206 10:52:55.558018  2751 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I1206 10:53:06.280560  2751 solver.cpp:357] Iteration 10400 (9.32629 iter/s, 10.7224s/100 iters), loss = 0.415956
I1206 10:53:06.280622  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415956 (* 1 = 0.415956 loss)
I1206 10:53:06.280633  2751 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I1206 10:53:16.898680  2751 solver.cpp:514] Iteration 10500, Testing net (#0)
I1206 10:53:20.109014  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:53:20.121140  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.12716 (* 1 = 2.12716 loss)
I1206 10:53:20.121168  2751 solver.cpp:580]     Test net output #1: prob = 0.4947
I1206 10:53:20.121176  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:53:20.227334  2751 solver.cpp:357] Iteration 10500 (7.17025 iter/s, 13.9465s/100 iters), loss = 0.409484
I1206 10:53:20.227377  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.409484 (* 1 = 0.409484 loss)
I1206 10:53:20.227391  2751 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I1206 10:53:24.729065  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:53:30.929220  2751 solver.cpp:357] Iteration 10600 (9.34431 iter/s, 10.7017s/100 iters), loss = 0.434266
I1206 10:53:30.929370  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.434266 (* 1 = 0.434266 loss)
I1206 10:53:30.929380  2751 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I1206 10:53:41.654304  2751 solver.cpp:357] Iteration 10700 (9.32417 iter/s, 10.7248s/100 iters), loss = 0.427814
I1206 10:53:41.654367  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.427814 (* 1 = 0.427814 loss)
I1206 10:53:41.654379  2751 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I1206 10:53:52.380939  2751 solver.cpp:357] Iteration 10800 (9.32274 iter/s, 10.7265s/100 iters), loss = 0.435264
I1206 10:53:52.380998  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.435264 (* 1 = 0.435264 loss)
I1206 10:53:52.381011  2751 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I1206 10:54:03.113534  2751 solver.cpp:357] Iteration 10900 (9.31755 iter/s, 10.7324s/100 iters), loss = 0.410901
I1206 10:54:03.113687  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.410901 (* 1 = 0.410901 loss)
I1206 10:54:03.113698  2751 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I1206 10:54:06.670095  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:54:13.737668  2751 solver.cpp:514] Iteration 11000, Testing net (#0)
I1206 10:54:16.939319  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:54:16.952149  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.02936 (* 1 = 1.02936 loss)
I1206 10:54:16.952178  2751 solver.cpp:580]     Test net output #1: prob = 0.6858
I1206 10:54:16.952184  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:54:17.057240  2751 solver.cpp:357] Iteration 11000 (7.17183 iter/s, 13.9435s/100 iters), loss = 0.417272
I1206 10:54:17.057281  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.417272 (* 1 = 0.417272 loss)
I1206 10:54:17.057292  2751 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I1206 10:54:27.780812  2751 solver.cpp:357] Iteration 11100 (9.32535 iter/s, 10.7235s/100 iters), loss = 0.465376
I1206 10:54:27.780874  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.465376 (* 1 = 0.465376 loss)
I1206 10:54:27.780885  2751 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I1206 10:54:38.508625  2751 solver.cpp:357] Iteration 11200 (9.32168 iter/s, 10.7277s/100 iters), loss = 0.39021
I1206 10:54:38.508772  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.39021 (* 1 = 0.39021 loss)
I1206 10:54:38.508781  2751 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I1206 10:54:49.220356  2751 solver.cpp:357] Iteration 11300 (9.33574 iter/s, 10.7115s/100 iters), loss = 0.415602
I1206 10:54:49.220420  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415602 (* 1 = 0.415602 loss)
I1206 10:54:49.220429  2751 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I1206 10:54:51.797827  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:54:59.939653  2751 solver.cpp:357] Iteration 11400 (9.32907 iter/s, 10.7192s/100 iters), loss = 0.348956
I1206 10:54:59.939716  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.348956 (* 1 = 0.348956 loss)
I1206 10:54:59.939728  2751 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I1206 10:55:10.567551  2751 solver.cpp:514] Iteration 11500, Testing net (#0)
I1206 10:55:13.766113  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:55:13.777961  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.898293 (* 1 = 0.898293 loss)
I1206 10:55:13.777988  2751 solver.cpp:580]     Test net output #1: prob = 0.7068
I1206 10:55:13.777995  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:55:13.883752  2751 solver.cpp:357] Iteration 11500 (7.17155 iter/s, 13.944s/100 iters), loss = 0.527628
I1206 10:55:13.883795  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.527628 (* 1 = 0.527628 loss)
I1206 10:55:13.883810  2751 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I1206 10:55:24.603672  2751 solver.cpp:357] Iteration 11600 (9.3285 iter/s, 10.7198s/100 iters), loss = 0.410741
I1206 10:55:24.603736  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.410741 (* 1 = 0.410741 loss)
I1206 10:55:24.603747  2751 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I1206 10:55:35.339844  2751 solver.cpp:357] Iteration 11700 (9.31439 iter/s, 10.7361s/100 iters), loss = 0.422987
I1206 10:55:35.339908  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.422987 (* 1 = 0.422987 loss)
I1206 10:55:35.339920  2751 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I1206 10:55:36.851753  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:55:46.059073  2751 solver.cpp:357] Iteration 11800 (9.32911 iter/s, 10.7191s/100 iters), loss = 0.654492
I1206 10:55:46.059276  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.654492 (* 1 = 0.654492 loss)
I1206 10:55:46.059285  2751 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I1206 10:55:56.777137  2751 solver.cpp:357] Iteration 11900 (9.33019 iter/s, 10.7179s/100 iters), loss = 0.377195
I1206 10:55:56.777201  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.377195 (* 1 = 0.377195 loss)
I1206 10:55:56.777211  2751 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I1206 10:56:07.411099  2751 solver.cpp:514] Iteration 12000, Testing net (#0)
I1206 10:56:10.629951  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:56:10.642122  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.59282 (* 1 = 1.59282 loss)
I1206 10:56:10.642149  2751 solver.cpp:580]     Test net output #1: prob = 0.600501
I1206 10:56:10.642156  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:56:10.747639  2751 solver.cpp:357] Iteration 12000 (7.1576 iter/s, 13.9712s/100 iters), loss = 0.457122
I1206 10:56:10.747681  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.457122 (* 1 = 0.457122 loss)
I1206 10:56:10.747692  2751 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I1206 10:56:21.483299  2751 solver.cpp:357] Iteration 12100 (9.31433 iter/s, 10.7361s/100 iters), loss = 0.384379
I1206 10:56:21.483425  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.384379 (* 1 = 0.384379 loss)
I1206 10:56:21.483436  2751 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I1206 10:56:22.026569  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:56:32.204625  2751 solver.cpp:357] Iteration 12200 (9.32687 iter/s, 10.7217s/100 iters), loss = 0.435092
I1206 10:56:32.204689  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.435092 (* 1 = 0.435092 loss)
I1206 10:56:32.204699  2751 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I1206 10:56:42.906267  2751 solver.cpp:357] Iteration 12300 (9.34398 iter/s, 10.7021s/100 iters), loss = 0.368953
I1206 10:56:42.906328  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.368953 (* 1 = 0.368953 loss)
I1206 10:56:42.906337  2751 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I1206 10:56:53.627861  2751 solver.cpp:357] Iteration 12400 (9.32661 iter/s, 10.722s/100 iters), loss = 0.594797
I1206 10:56:53.627982  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.594797 (* 1 = 0.594797 loss)
I1206 10:56:53.627993  2751 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I1206 10:57:03.825646  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:57:04.245326  2751 solver.cpp:514] Iteration 12500, Testing net (#0)
I1206 10:57:07.500125  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:57:07.512575  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.40103 (* 1 = 1.40103 loss)
I1206 10:57:07.512603  2751 solver.cpp:580]     Test net output #1: prob = 0.5344
I1206 10:57:07.512609  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:57:07.618659  2751 solver.cpp:357] Iteration 12500 (7.1473 iter/s, 13.9913s/100 iters), loss = 0.458211
I1206 10:57:07.618703  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.458211 (* 1 = 0.458211 loss)
I1206 10:57:07.618716  2751 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I1206 10:57:18.359001  2751 solver.cpp:357] Iteration 12600 (9.31034 iter/s, 10.7407s/100 iters), loss = 0.457509
I1206 10:57:18.359064  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.457509 (* 1 = 0.457509 loss)
I1206 10:57:18.359074  2751 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I1206 10:57:29.088727  2751 solver.cpp:357] Iteration 12700 (9.31958 iter/s, 10.7301s/100 iters), loss = 0.491518
I1206 10:57:29.088874  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.491518 (* 1 = 0.491518 loss)
I1206 10:57:29.088884  2751 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I1206 10:57:39.811431  2751 solver.cpp:357] Iteration 12800 (9.32577 iter/s, 10.723s/100 iters), loss = 0.457717
I1206 10:57:39.811496  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.457717 (* 1 = 0.457717 loss)
I1206 10:57:39.811506  2751 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I1206 10:57:49.026015  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:57:50.521172  2751 solver.cpp:357] Iteration 12900 (9.337 iter/s, 10.7101s/100 iters), loss = 0.523778
I1206 10:57:50.521235  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.523778 (* 1 = 0.523778 loss)
I1206 10:57:50.521245  2751 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I1206 10:58:01.150749  2751 solver.cpp:514] Iteration 13000, Testing net (#0)
I1206 10:58:04.394836  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:58:04.407132  2751 solver.cpp:580]     Test net output #0: Softmax1 = 2.13234 (* 1 = 2.13234 loss)
I1206 10:58:04.407160  2751 solver.cpp:580]     Test net output #1: prob = 0.5162
I1206 10:58:04.407167  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:58:04.513371  2751 solver.cpp:357] Iteration 13000 (7.14661 iter/s, 13.9927s/100 iters), loss = 0.367244
I1206 10:58:04.513415  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.367244 (* 1 = 0.367244 loss)
I1206 10:58:04.513428  2751 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I1206 10:58:15.233932  2751 solver.cpp:357] Iteration 13100 (9.32758 iter/s, 10.7209s/100 iters), loss = 0.397111
I1206 10:58:15.233994  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.397111 (* 1 = 0.397111 loss)
I1206 10:58:15.234005  2751 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I1206 10:58:25.962357  2751 solver.cpp:357] Iteration 13200 (9.32077 iter/s, 10.7287s/100 iters), loss = 0.331625
I1206 10:58:25.962420  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.331625 (* 1 = 0.331625 loss)
I1206 10:58:25.962430  2751 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I1206 10:58:34.213515  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:58:36.677062  2751 solver.cpp:357] Iteration 13300 (9.33272 iter/s, 10.715s/100 iters), loss = 0.490904
I1206 10:58:36.677126  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.490904 (* 1 = 0.490904 loss)
I1206 10:58:36.677135  2751 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I1206 10:58:47.400630  2751 solver.cpp:357] Iteration 13400 (9.32501 iter/s, 10.7238s/100 iters), loss = 0.551561
I1206 10:58:47.400692  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.551561 (* 1 = 0.551561 loss)
I1206 10:58:47.400702  2751 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I1206 10:58:58.011775  2751 solver.cpp:514] Iteration 13500, Testing net (#0)
I1206 10:59:01.222535  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:59:01.234721  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.58378 (* 1 = 1.58378 loss)
I1206 10:59:01.234750  2751 solver.cpp:580]     Test net output #1: prob = 0.5793
I1206 10:59:01.234756  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:59:01.340598  2751 solver.cpp:357] Iteration 13500 (7.17342 iter/s, 13.9403s/100 iters), loss = 0.51638
I1206 10:59:01.340649  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.51638 (* 1 = 0.51638 loss)
I1206 10:59:01.340661  2751 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I1206 10:59:12.062108  2751 solver.cpp:357] Iteration 13600 (9.32681 iter/s, 10.7218s/100 iters), loss = 0.413272
I1206 10:59:12.062252  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.413272 (* 1 = 0.413272 loss)
I1206 10:59:12.062263  2751 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I1206 10:59:19.255806  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:59:22.793316  2751 solver.cpp:357] Iteration 13700 (9.31847 iter/s, 10.7314s/100 iters), loss = 0.489648
I1206 10:59:22.793380  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.489648 (* 1 = 0.489648 loss)
I1206 10:59:22.793390  2751 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I1206 10:59:33.510432  2751 solver.cpp:357] Iteration 13800 (9.33066 iter/s, 10.7174s/100 iters), loss = 0.350334
I1206 10:59:33.510493  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.350334 (* 1 = 0.350334 loss)
I1206 10:59:33.510504  2751 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I1206 10:59:44.244063  2751 solver.cpp:357] Iteration 13900 (9.31631 iter/s, 10.7339s/100 iters), loss = 0.386573
I1206 10:59:44.244216  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.386573 (* 1 = 0.386573 loss)
I1206 10:59:44.244230  2751 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I1206 10:59:54.870349  2751 solver.cpp:514] Iteration 14000, Testing net (#0)
I1206 10:59:58.053865  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 10:59:58.065865  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.935829 (* 1 = 0.935829 loss)
I1206 10:59:58.065891  2751 solver.cpp:580]     Test net output #1: prob = 0.7149
I1206 10:59:58.065898  2751 solver.cpp:593]     Max_acc: 0.7457  with iter: 10000
I1206 10:59:58.172112  2751 solver.cpp:357] Iteration 14000 (7.17964 iter/s, 13.9283s/100 iters), loss = 0.401087
I1206 10:59:58.172153  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.401087 (* 1 = 0.401087 loss)
I1206 10:59:58.172163  2751 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I1206 11:00:04.391206  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:00:08.894362  2751 solver.cpp:357] Iteration 14100 (9.3262 iter/s, 10.7225s/100 iters), loss = 0.3528
I1206 11:00:08.894428  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.352799 (* 1 = 0.352799 loss)
I1206 11:00:08.894435  2751 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I1206 11:00:19.614151  2751 solver.cpp:357] Iteration 14200 (9.32836 iter/s, 10.72s/100 iters), loss = 0.497006
I1206 11:00:19.614303  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.497006 (* 1 = 0.497006 loss)
I1206 11:00:19.614312  2751 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I1206 11:00:30.343888  2751 solver.cpp:357] Iteration 14300 (9.3198 iter/s, 10.7298s/100 iters), loss = 0.506691
I1206 11:00:30.343951  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.506691 (* 1 = 0.506691 loss)
I1206 11:00:30.343962  2751 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I1206 11:00:41.066692  2751 solver.cpp:357] Iteration 14400 (9.32575 iter/s, 10.723s/100 iters), loss = 0.428085
I1206 11:00:41.066757  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.428085 (* 1 = 0.428085 loss)
I1206 11:00:41.066767  2751 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I1206 11:00:46.318965  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:00:51.673614  2751 solver.cpp:514] Iteration 14500, Testing net (#0)
I1206 11:00:54.901278  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:00:54.914350  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.632838 (* 1 = 0.632838 loss)
I1206 11:00:54.914377  2751 solver.cpp:580]     Test net output #1: prob = 0.7765
I1206 11:00:54.914394  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_14500.caffemodel
I1206 11:00:54.922102  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_14500.solverstate
I1206 11:00:54.924353  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:00:55.030390  2751 solver.cpp:357] Iteration 14500 (7.16129 iter/s, 13.964s/100 iters), loss = 0.381734
I1206 11:00:55.030434  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.381734 (* 1 = 0.381734 loss)
I1206 11:00:55.030449  2751 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I1206 11:01:05.749372  2751 solver.cpp:357] Iteration 14600 (9.32907 iter/s, 10.7192s/100 iters), loss = 0.455667
I1206 11:01:05.749438  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.455667 (* 1 = 0.455667 loss)
I1206 11:01:05.749446  2751 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I1206 11:01:16.473942  2751 solver.cpp:357] Iteration 14700 (9.32424 iter/s, 10.7247s/100 iters), loss = 0.401342
I1206 11:01:16.474004  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.401342 (* 1 = 0.401342 loss)
I1206 11:01:16.474014  2751 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I1206 11:01:27.199013  2751 solver.cpp:357] Iteration 14800 (9.3238 iter/s, 10.7252s/100 iters), loss = 0.31836
I1206 11:01:27.199215  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.31836 (* 1 = 0.31836 loss)
I1206 11:01:27.199225  2751 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I1206 11:01:31.387137  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:01:37.924008  2751 solver.cpp:357] Iteration 14900 (9.32399 iter/s, 10.725s/100 iters), loss = 0.308648
I1206 11:01:37.924072  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.308648 (* 1 = 0.308648 loss)
I1206 11:01:37.924082  2751 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I1206 11:01:48.536906  2751 solver.cpp:514] Iteration 15000, Testing net (#0)
I1206 11:01:51.724495  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:01:51.736662  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.60764 (* 1 = 1.60764 loss)
I1206 11:01:51.736690  2751 solver.cpp:580]     Test net output #1: prob = 0.5419
I1206 11:01:51.736696  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:01:51.842478  2751 solver.cpp:357] Iteration 15000 (7.18458 iter/s, 13.9187s/100 iters), loss = 0.470675
I1206 11:01:51.842520  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.470675 (* 1 = 0.470675 loss)
I1206 11:01:51.842532  2751 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I1206 11:02:02.561209  2751 solver.cpp:357] Iteration 15100 (9.32932 iter/s, 10.7189s/100 iters), loss = 0.523084
I1206 11:02:02.561313  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.523084 (* 1 = 0.523084 loss)
I1206 11:02:02.561322  2751 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I1206 11:02:13.278364  2751 solver.cpp:357] Iteration 15200 (9.33075 iter/s, 10.7173s/100 iters), loss = 0.582348
I1206 11:02:13.278429  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.582347 (* 1 = 0.582347 loss)
I1206 11:02:13.278437  2751 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I1206 11:02:16.499784  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:02:23.989544  2751 solver.cpp:357] Iteration 15300 (9.33592 iter/s, 10.7113s/100 iters), loss = 0.412591
I1206 11:02:23.989607  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.412591 (* 1 = 0.412591 loss)
I1206 11:02:23.989619  2751 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I1206 11:02:34.715940  2751 solver.cpp:357] Iteration 15400 (9.32268 iter/s, 10.7265s/100 iters), loss = 0.527084
I1206 11:02:34.716079  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.527084 (* 1 = 0.527084 loss)
I1206 11:02:34.716090  2751 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I1206 11:02:45.330060  2751 solver.cpp:514] Iteration 15500, Testing net (#0)
I1206 11:02:48.508770  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:02:48.520861  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.66204 (* 1 = 1.66204 loss)
I1206 11:02:48.520889  2751 solver.cpp:580]     Test net output #1: prob = 0.556901
I1206 11:02:48.520895  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:02:48.627408  2751 solver.cpp:357] Iteration 15500 (7.18825 iter/s, 13.9116s/100 iters), loss = 0.505976
I1206 11:02:48.627454  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.505975 (* 1 = 0.505975 loss)
I1206 11:02:48.627465  2751 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I1206 11:02:59.356806  2751 solver.cpp:357] Iteration 15600 (9.32007 iter/s, 10.7295s/100 iters), loss = 0.344075
I1206 11:02:59.356870  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.344075 (* 1 = 0.344075 loss)
I1206 11:02:59.356881  2751 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I1206 11:03:01.512583  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:03:10.081104  2751 solver.cpp:357] Iteration 15700 (9.32451 iter/s, 10.7244s/100 iters), loss = 0.507166
I1206 11:03:10.081205  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.507166 (* 1 = 0.507166 loss)
I1206 11:03:10.081216  2751 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I1206 11:03:20.809485  2751 solver.cpp:357] Iteration 15800 (9.321 iter/s, 10.7285s/100 iters), loss = 0.411464
I1206 11:03:20.809547  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.411463 (* 1 = 0.411463 loss)
I1206 11:03:20.809558  2751 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I1206 11:03:31.525872  2751 solver.cpp:357] Iteration 15900 (9.3314 iter/s, 10.7165s/100 iters), loss = 0.363499
I1206 11:03:31.525934  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.363499 (* 1 = 0.363499 loss)
I1206 11:03:31.525945  2751 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I1206 11:03:42.142545  2751 solver.cpp:514] Iteration 16000, Testing net (#0)
I1206 11:03:45.340855  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:03:45.353127  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.787827 (* 1 = 0.787827 loss)
I1206 11:03:45.353153  2751 solver.cpp:580]     Test net output #1: prob = 0.7365
I1206 11:03:45.353160  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:03:45.459233  2751 solver.cpp:357] Iteration 16000 (7.17693 iter/s, 13.9335s/100 iters), loss = 0.379986
I1206 11:03:45.459276  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.379986 (* 1 = 0.379986 loss)
I1206 11:03:45.459290  2751 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I1206 11:03:46.640112  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:03:56.179926  2751 solver.cpp:357] Iteration 16100 (9.32765 iter/s, 10.7208s/100 iters), loss = 0.466822
I1206 11:03:56.179989  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.466822 (* 1 = 0.466822 loss)
I1206 11:03:56.180001  2751 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I1206 11:04:06.902952  2751 solver.cpp:357] Iteration 16200 (9.32564 iter/s, 10.7231s/100 iters), loss = 0.386516
I1206 11:04:06.903015  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.386516 (* 1 = 0.386516 loss)
I1206 11:04:06.903024  2751 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I1206 11:04:17.634426  2751 solver.cpp:357] Iteration 16300 (9.3183 iter/s, 10.7316s/100 iters), loss = 0.380433
I1206 11:04:17.634533  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.380433 (* 1 = 0.380433 loss)
I1206 11:04:17.634542  2751 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I1206 11:04:28.361253  2751 solver.cpp:357] Iteration 16400 (9.32237 iter/s, 10.7269s/100 iters), loss = 0.434543
I1206 11:04:28.361316  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.434542 (* 1 = 0.434542 loss)
I1206 11:04:28.361328  2751 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I1206 11:04:28.582051  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:04:38.966219  2751 solver.cpp:514] Iteration 16500, Testing net (#0)
I1206 11:04:42.161869  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:04:42.174033  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.27543 (* 1 = 1.27543 loss)
I1206 11:04:42.174062  2751 solver.cpp:580]     Test net output #1: prob = 0.5955
I1206 11:04:42.174068  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:04:42.280359  2751 solver.cpp:357] Iteration 16500 (7.18429 iter/s, 13.9193s/100 iters), loss = 0.416127
I1206 11:04:42.280400  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.416126 (* 1 = 0.416126 loss)
I1206 11:04:42.280413  2751 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I1206 11:04:53.016733  2751 solver.cpp:357] Iteration 16600 (9.31403 iter/s, 10.7365s/100 iters), loss = 0.352563
I1206 11:04:53.016880  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.352563 (* 1 = 0.352563 loss)
I1206 11:04:53.016891  2751 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I1206 11:05:03.737848  2751 solver.cpp:357] Iteration 16700 (9.32738 iter/s, 10.7211s/100 iters), loss = 0.411794
I1206 11:05:03.737912  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.411794 (* 1 = 0.411794 loss)
I1206 11:05:03.737922  2751 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I1206 11:05:13.613312  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:05:14.458184  2751 solver.cpp:357] Iteration 16800 (9.32799 iter/s, 10.7204s/100 iters), loss = 0.441821
I1206 11:05:14.458250  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.441821 (* 1 = 0.441821 loss)
I1206 11:05:14.458258  2751 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I1206 11:05:25.177182  2751 solver.cpp:357] Iteration 16900 (9.32916 iter/s, 10.7191s/100 iters), loss = 0.461137
I1206 11:05:25.177377  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.461137 (* 1 = 0.461137 loss)
I1206 11:05:25.177388  2751 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I1206 11:05:35.787449  2751 solver.cpp:514] Iteration 17000, Testing net (#0)
I1206 11:05:39.006088  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:05:39.027968  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.21732 (* 1 = 1.21732 loss)
I1206 11:05:39.027995  2751 solver.cpp:580]     Test net output #1: prob = 0.66
I1206 11:05:39.028002  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:05:39.136761  2751 solver.cpp:357] Iteration 17000 (7.16354 iter/s, 13.9596s/100 iters), loss = 0.404049
I1206 11:05:39.136804  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.404049 (* 1 = 0.404049 loss)
I1206 11:05:39.136819  2751 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I1206 11:05:49.856295  2751 solver.cpp:357] Iteration 17100 (9.32868 iter/s, 10.7196s/100 iters), loss = 0.337082
I1206 11:05:49.856357  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.337082 (* 1 = 0.337082 loss)
I1206 11:05:49.856369  2751 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I1206 11:05:58.756392  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:06:00.574721  2751 solver.cpp:357] Iteration 17200 (9.32966 iter/s, 10.7185s/100 iters), loss = 0.24797
I1206 11:06:00.574784  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.247969 (* 1 = 0.247969 loss)
I1206 11:06:00.574795  2751 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I1206 11:06:11.311539  2751 solver.cpp:357] Iteration 17300 (9.31368 iter/s, 10.7369s/100 iters), loss = 0.318758
I1206 11:06:11.311607  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.318758 (* 1 = 0.318758 loss)
I1206 11:06:11.311620  2751 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I1206 11:06:22.030625  2751 solver.cpp:357] Iteration 17400 (9.32909 iter/s, 10.7192s/100 iters), loss = 0.373552
I1206 11:06:22.030689  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.373551 (* 1 = 0.373551 loss)
I1206 11:06:22.030699  2751 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I1206 11:06:32.647348  2751 solver.cpp:514] Iteration 17500, Testing net (#0)
I1206 11:06:35.865234  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:06:35.877388  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.10208 (* 1 = 1.10208 loss)
I1206 11:06:35.877416  2751 solver.cpp:580]     Test net output #1: prob = 0.6407
I1206 11:06:35.877424  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:06:35.982873  2751 solver.cpp:357] Iteration 17500 (7.16724 iter/s, 13.9524s/100 iters), loss = 0.27289
I1206 11:06:35.982915  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.27289 (* 1 = 0.27289 loss)
I1206 11:06:35.982926  2751 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I1206 11:06:43.928607  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:06:46.706044  2751 solver.cpp:357] Iteration 17600 (9.32552 iter/s, 10.7233s/100 iters), loss = 0.428096
I1206 11:06:46.706109  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.428096 (* 1 = 0.428096 loss)
I1206 11:06:46.706117  2751 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I1206 11:06:57.442307  2751 solver.cpp:357] Iteration 17700 (9.31417 iter/s, 10.7363s/100 iters), loss = 0.499446
I1206 11:06:57.442370  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.499445 (* 1 = 0.499445 loss)
I1206 11:06:57.442378  2751 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I1206 11:07:08.170795  2751 solver.cpp:357] Iteration 17800 (9.32092 iter/s, 10.7286s/100 iters), loss = 0.357208
I1206 11:07:08.170949  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.357208 (* 1 = 0.357208 loss)
I1206 11:07:08.170958  2751 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I1206 11:07:18.903975  2751 solver.cpp:357] Iteration 17900 (9.31692 iter/s, 10.7332s/100 iters), loss = 0.242103
I1206 11:07:18.904038  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.242103 (* 1 = 0.242103 loss)
I1206 11:07:18.904048  2751 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I1206 11:07:25.778914  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:07:29.524394  2751 solver.cpp:514] Iteration 18000, Testing net (#0)
I1206 11:07:32.677599  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:07:32.690364  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.678452 (* 1 = 0.678452 loss)
I1206 11:07:32.690392  2751 solver.cpp:580]     Test net output #1: prob = 0.7724
I1206 11:07:32.690397  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:07:32.796463  2751 solver.cpp:357] Iteration 18000 (7.19808 iter/s, 13.8926s/100 iters), loss = 0.316021
I1206 11:07:32.796504  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.316021 (* 1 = 0.316021 loss)
I1206 11:07:32.796514  2751 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I1206 11:07:43.518610  2751 solver.cpp:357] Iteration 18100 (9.32642 iter/s, 10.7222s/100 iters), loss = 0.391902
I1206 11:07:43.518769  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.391902 (* 1 = 0.391902 loss)
I1206 11:07:43.518780  2751 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I1206 11:07:54.247153  2751 solver.cpp:357] Iteration 18200 (9.32096 iter/s, 10.7285s/100 iters), loss = 0.401778
I1206 11:07:54.247216  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.401778 (* 1 = 0.401778 loss)
I1206 11:07:54.247226  2751 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I1206 11:08:04.970747  2751 solver.cpp:357] Iteration 18300 (9.32518 iter/s, 10.7237s/100 iters), loss = 0.381166
I1206 11:08:04.970814  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.381166 (* 1 = 0.381166 loss)
I1206 11:08:04.970824  2751 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I1206 11:08:10.883294  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:08:15.690958  2751 solver.cpp:357] Iteration 18400 (9.32813 iter/s, 10.7203s/100 iters), loss = 0.472302
I1206 11:08:15.691095  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.472302 (* 1 = 0.472302 loss)
I1206 11:08:15.691105  2751 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I1206 11:08:26.303165  2751 solver.cpp:514] Iteration 18500, Testing net (#0)
I1206 11:08:29.512986  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:08:29.525072  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.869299 (* 1 = 0.869299 loss)
I1206 11:08:29.525099  2751 solver.cpp:580]     Test net output #1: prob = 0.7306
I1206 11:08:29.525106  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:08:29.630862  2751 solver.cpp:357] Iteration 18500 (7.17363 iter/s, 13.9399s/100 iters), loss = 0.371389
I1206 11:08:29.630905  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.371389 (* 1 = 0.371389 loss)
I1206 11:08:29.630915  2751 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I1206 11:08:40.351749  2751 solver.cpp:357] Iteration 18600 (9.32752 iter/s, 10.721s/100 iters), loss = 0.5627
I1206 11:08:40.351814  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.5627 (* 1 = 0.5627 loss)
I1206 11:08:40.351824  2751 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I1206 11:08:51.075284  2751 solver.cpp:357] Iteration 18700 (9.32524 iter/s, 10.7236s/100 iters), loss = 0.354542
I1206 11:08:51.075428  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.354542 (* 1 = 0.354542 loss)
I1206 11:08:51.075436  2751 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I1206 11:08:55.907428  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:09:01.793821  2751 solver.cpp:357] Iteration 18800 (9.32965 iter/s, 10.7185s/100 iters), loss = 0.283019
I1206 11:09:01.793881  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.283019 (* 1 = 0.283019 loss)
I1206 11:09:01.793893  2751 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I1206 11:09:12.517385  2751 solver.cpp:357] Iteration 18900 (9.32521 iter/s, 10.7236s/100 iters), loss = 0.458212
I1206 11:09:12.517448  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.458212 (* 1 = 0.458212 loss)
I1206 11:09:12.517459  2751 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I1206 11:09:23.125820  2751 solver.cpp:514] Iteration 19000, Testing net (#0)
I1206 11:09:26.326172  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:09:26.338225  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.71323 (* 1 = 1.71323 loss)
I1206 11:09:26.338253  2751 solver.cpp:580]     Test net output #1: prob = 0.576301
I1206 11:09:26.338260  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:09:26.443783  2751 solver.cpp:357] Iteration 19000 (7.18056 iter/s, 13.9265s/100 iters), loss = 0.333591
I1206 11:09:26.443825  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.333591 (* 1 = 0.333591 loss)
I1206 11:09:26.443835  2751 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I1206 11:09:37.179010  2751 solver.cpp:357] Iteration 19100 (9.31506 iter/s, 10.7353s/100 iters), loss = 0.475235
I1206 11:09:37.179075  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.475235 (* 1 = 0.475235 loss)
I1206 11:09:37.179083  2751 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I1206 11:09:41.049546  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:09:47.907119  2751 solver.cpp:357] Iteration 19200 (9.32126 iter/s, 10.7282s/100 iters), loss = 0.388299
I1206 11:09:47.907183  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.388299 (* 1 = 0.388299 loss)
I1206 11:09:47.907192  2751 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I1206 11:09:58.631319  2751 solver.cpp:357] Iteration 19300 (9.32466 iter/s, 10.7242s/100 iters), loss = 0.331916
I1206 11:09:58.631469  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.331916 (* 1 = 0.331916 loss)
I1206 11:09:58.631477  2751 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I1206 11:10:09.362709  2751 solver.cpp:357] Iteration 19400 (9.31849 iter/s, 10.7314s/100 iters), loss = 0.403491
I1206 11:10:09.362771  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.403491 (* 1 = 0.403491 loss)
I1206 11:10:09.362781  2751 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I1206 11:10:19.985529  2751 solver.cpp:514] Iteration 19500, Testing net (#0)
I1206 11:10:23.198379  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:10:23.210716  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.86731 (* 1 = 1.86731 loss)
I1206 11:10:23.210743  2751 solver.cpp:580]     Test net output #1: prob = 0.535
I1206 11:10:23.210750  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:10:23.316805  2751 solver.cpp:357] Iteration 19500 (7.16631 iter/s, 13.9542s/100 iters), loss = 0.310727
I1206 11:10:23.316848  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.310727 (* 1 = 0.310727 loss)
I1206 11:10:23.316859  2751 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I1206 11:10:26.210952  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:10:34.016638  2751 solver.cpp:357] Iteration 19600 (9.34588 iter/s, 10.6999s/100 iters), loss = 0.371439
I1206 11:10:34.016757  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.371439 (* 1 = 0.371439 loss)
I1206 11:10:34.016770  2751 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I1206 11:10:44.741259  2751 solver.cpp:357] Iteration 19700 (9.32434 iter/s, 10.7246s/100 iters), loss = 0.650881
I1206 11:10:44.741320  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.650881 (* 1 = 0.650881 loss)
I1206 11:10:44.741331  2751 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I1206 11:10:55.461212  2751 solver.cpp:357] Iteration 19800 (9.32836 iter/s, 10.72s/100 iters), loss = 0.381989
I1206 11:10:55.461278  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.381989 (* 1 = 0.381989 loss)
I1206 11:10:55.461288  2751 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I1206 11:11:06.185256  2751 solver.cpp:357] Iteration 19900 (9.3248 iter/s, 10.7241s/100 iters), loss = 0.413045
I1206 11:11:06.185407  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.413045 (* 1 = 0.413045 loss)
I1206 11:11:06.185417  2751 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I1206 11:11:08.015727  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:11:16.802137  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.caffemodel
I1206 11:11:16.810147  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.solverstate
I1206 11:11:16.812952  2751 solver.cpp:514] Iteration 20000, Testing net (#0)
I1206 11:11:20.035097  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:11:20.047190  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.12384 (* 1 = 1.12384 loss)
I1206 11:11:20.047219  2751 solver.cpp:580]     Test net output #1: prob = 0.625701
I1206 11:11:20.047225  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:11:20.153364  2751 solver.cpp:357] Iteration 20000 (7.15916 iter/s, 13.9681s/100 iters), loss = 0.357545
I1206 11:11:20.153407  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.357544 (* 1 = 0.357544 loss)
I1206 11:11:20.153417  2751 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I1206 11:11:30.888649  2751 solver.cpp:357] Iteration 20100 (9.31502 iter/s, 10.7353s/100 iters), loss = 0.370134
I1206 11:11:30.888715  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.370134 (* 1 = 0.370134 loss)
I1206 11:11:30.888725  2751 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I1206 11:11:41.614492  2751 solver.cpp:357] Iteration 20200 (9.32324 iter/s, 10.7259s/100 iters), loss = 0.361308
I1206 11:11:41.614648  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.361308 (* 1 = 0.361308 loss)
I1206 11:11:41.614658  2751 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I1206 11:11:52.316684  2751 solver.cpp:357] Iteration 20300 (9.34392 iter/s, 10.7021s/100 iters), loss = 0.357272
I1206 11:11:52.316747  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.357272 (* 1 = 0.357272 loss)
I1206 11:11:52.316757  2751 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I1206 11:11:53.180088  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:12:03.041121  2751 solver.cpp:357] Iteration 20400 (9.32446 iter/s, 10.7245s/100 iters), loss = 0.392311
I1206 11:12:03.041188  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.392311 (* 1 = 0.392311 loss)
I1206 11:12:03.041196  2751 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I1206 11:12:13.656127  2751 solver.cpp:514] Iteration 20500, Testing net (#0)
I1206 11:12:16.851685  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:12:16.863301  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.56428 (* 1 = 1.56428 loss)
I1206 11:12:16.863327  2751 solver.cpp:580]     Test net output #1: prob = 0.577
I1206 11:12:16.863334  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:12:16.969293  2751 solver.cpp:357] Iteration 20500 (7.17965 iter/s, 13.9283s/100 iters), loss = 0.343001
I1206 11:12:16.969336  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.343 (* 1 = 0.343 loss)
I1206 11:12:16.969347  2751 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I1206 11:12:27.700245  2751 solver.cpp:357] Iteration 20600 (9.31878 iter/s, 10.731s/100 iters), loss = 0.437971
I1206 11:12:27.700310  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.437971 (* 1 = 0.437971 loss)
I1206 11:12:27.700320  2751 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I1206 11:12:38.330647  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:12:38.435124  2751 solver.cpp:357] Iteration 20700 (9.31539 iter/s, 10.7349s/100 iters), loss = 0.265474
I1206 11:12:38.435174  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.265474 (* 1 = 0.265474 loss)
I1206 11:12:38.435185  2751 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I1206 11:12:49.169631  2751 solver.cpp:357] Iteration 20800 (9.3157 iter/s, 10.7346s/100 iters), loss = 0.495281
I1206 11:12:49.169832  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.49528 (* 1 = 0.49528 loss)
I1206 11:12:49.169842  2751 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I1206 11:12:59.872083  2751 solver.cpp:357] Iteration 20900 (9.34373 iter/s, 10.7024s/100 iters), loss = 0.326426
I1206 11:12:59.872148  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.326426 (* 1 = 0.326426 loss)
I1206 11:12:59.872156  2751 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I1206 11:13:10.493628  2751 solver.cpp:514] Iteration 21000, Testing net (#0)
I1206 11:13:13.684353  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:13:13.696277  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.796672 (* 1 = 0.796672 loss)
I1206 11:13:13.696303  2751 solver.cpp:580]     Test net output #1: prob = 0.7425
I1206 11:13:13.696310  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:13:13.801944  2751 solver.cpp:357] Iteration 21000 (7.17847 iter/s, 13.9305s/100 iters), loss = 0.333049
I1206 11:13:13.801986  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.333049 (* 1 = 0.333049 loss)
I1206 11:13:13.801997  2751 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I1206 11:13:23.359681  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:13:24.527294  2751 solver.cpp:357] Iteration 21100 (9.32326 iter/s, 10.7259s/100 iters), loss = 0.361315
I1206 11:13:24.527359  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.361314 (* 1 = 0.361314 loss)
I1206 11:13:24.527369  2751 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I1206 11:13:35.253458  2751 solver.cpp:357] Iteration 21200 (9.32258 iter/s, 10.7266s/100 iters), loss = 0.430877
I1206 11:13:35.253520  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.430877 (* 1 = 0.430877 loss)
I1206 11:13:35.253530  2751 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I1206 11:13:45.972064  2751 solver.cpp:357] Iteration 21300 (9.32916 iter/s, 10.7191s/100 iters), loss = 0.463215
I1206 11:13:45.972126  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.463215 (* 1 = 0.463215 loss)
I1206 11:13:45.972137  2751 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I1206 11:13:56.686730  2751 solver.cpp:357] Iteration 21400 (9.3326 iter/s, 10.7151s/100 iters), loss = 0.403318
I1206 11:13:56.686868  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.403318 (* 1 = 0.403318 loss)
I1206 11:13:56.686878  2751 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I1206 11:14:05.281440  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:14:07.314659  2751 solver.cpp:514] Iteration 21500, Testing net (#0)
I1206 11:14:10.547096  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:14:10.559154  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.723065 (* 1 = 0.723065 loss)
I1206 11:14:10.559180  2751 solver.cpp:580]     Test net output #1: prob = 0.7496
I1206 11:14:10.559186  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:14:10.665022  2751 solver.cpp:357] Iteration 21500 (7.15367 iter/s, 13.9788s/100 iters), loss = 0.340581
I1206 11:14:10.665064  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.340581 (* 1 = 0.340581 loss)
I1206 11:14:10.665074  2751 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I1206 11:14:21.380990  2751 solver.cpp:357] Iteration 21600 (9.33146 iter/s, 10.7164s/100 iters), loss = 0.424972
I1206 11:14:21.381054  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.424972 (* 1 = 0.424972 loss)
I1206 11:14:21.381063  2751 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I1206 11:14:32.110049  2751 solver.cpp:357] Iteration 21700 (9.3201 iter/s, 10.7295s/100 iters), loss = 0.482506
I1206 11:14:32.110257  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.482506 (* 1 = 0.482506 loss)
I1206 11:14:32.110267  2751 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I1206 11:14:42.825605  2751 solver.cpp:357] Iteration 21800 (9.33197 iter/s, 10.7158s/100 iters), loss = 0.424414
I1206 11:14:42.825668  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.424414 (* 1 = 0.424414 loss)
I1206 11:14:42.825680  2751 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I1206 11:14:50.336735  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:14:53.542042  2751 solver.cpp:357] Iteration 21900 (9.33109 iter/s, 10.7169s/100 iters), loss = 0.54959
I1206 11:14:53.542104  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.54959 (* 1 = 0.54959 loss)
I1206 11:14:53.542114  2751 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I1206 11:15:04.157017  2751 solver.cpp:514] Iteration 22000, Testing net (#0)
I1206 11:15:07.353061  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:15:07.365250  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.01268 (* 1 = 1.01268 loss)
I1206 11:15:07.365278  2751 solver.cpp:580]     Test net output #1: prob = 0.685
I1206 11:15:07.365285  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:15:07.471002  2751 solver.cpp:357] Iteration 22000 (7.17899 iter/s, 13.9295s/100 iters), loss = 0.55278
I1206 11:15:07.471045  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.55278 (* 1 = 0.55278 loss)
I1206 11:15:07.471055  2751 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I1206 11:15:18.197196  2751 solver.cpp:357] Iteration 22100 (9.3226 iter/s, 10.7266s/100 iters), loss = 0.48957
I1206 11:15:18.197260  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.489569 (* 1 = 0.489569 loss)
I1206 11:15:18.197271  2751 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I1206 11:15:28.915848  2751 solver.cpp:357] Iteration 22200 (9.32918 iter/s, 10.7191s/100 iters), loss = 0.429965
I1206 11:15:28.915911  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.429965 (* 1 = 0.429965 loss)
I1206 11:15:28.915923  2751 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I1206 11:15:35.466392  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:15:39.638846  2751 solver.cpp:357] Iteration 22300 (9.3254 iter/s, 10.7234s/100 iters), loss = 0.33828
I1206 11:15:39.638912  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.33828 (* 1 = 0.33828 loss)
I1206 11:15:39.638921  2751 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I1206 11:15:50.361284  2751 solver.cpp:357] Iteration 22400 (9.3259 iter/s, 10.7228s/100 iters), loss = 0.286348
I1206 11:15:50.361351  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.286348 (* 1 = 0.286348 loss)
I1206 11:15:50.361359  2751 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I1206 11:16:00.972044  2751 solver.cpp:514] Iteration 22500, Testing net (#0)
I1206 11:16:04.267349  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:16:04.279152  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.3301 (* 1 = 1.3301 loss)
I1206 11:16:04.279179  2751 solver.cpp:580]     Test net output #1: prob = 0.6579
I1206 11:16:04.279187  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:16:04.385767  2751 solver.cpp:357] Iteration 22500 (7.13012 iter/s, 14.025s/100 iters), loss = 0.315914
I1206 11:16:04.385809  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.315914 (* 1 = 0.315914 loss)
I1206 11:16:04.385820  2751 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I1206 11:16:15.103330  2751 solver.cpp:357] Iteration 22600 (9.33013 iter/s, 10.718s/100 iters), loss = 0.507023
I1206 11:16:15.103474  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.507023 (* 1 = 0.507023 loss)
I1206 11:16:15.103485  2751 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I1206 11:16:20.691931  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:16:25.836954  2751 solver.cpp:357] Iteration 22700 (9.31626 iter/s, 10.7339s/100 iters), loss = 0.366538
I1206 11:16:25.837016  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.366538 (* 1 = 0.366538 loss)
I1206 11:16:25.837025  2751 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I1206 11:16:36.568027  2751 solver.cpp:357] Iteration 22800 (9.31841 iter/s, 10.7314s/100 iters), loss = 0.413348
I1206 11:16:36.568090  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.413348 (* 1 = 0.413348 loss)
I1206 11:16:36.568102  2751 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I1206 11:16:47.307201  2751 solver.cpp:357] Iteration 22900 (9.31139 iter/s, 10.7395s/100 iters), loss = 0.433531
I1206 11:16:47.307404  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.433531 (* 1 = 0.433531 loss)
I1206 11:16:47.307413  2751 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I1206 11:16:57.927868  2751 solver.cpp:514] Iteration 23000, Testing net (#0)
I1206 11:17:01.133687  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:17:01.145624  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.861928 (* 1 = 0.861928 loss)
I1206 11:17:01.145651  2751 solver.cpp:580]     Test net output #1: prob = 0.727899
I1206 11:17:01.145658  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:17:01.251508  2751 solver.cpp:357] Iteration 23000 (7.1712 iter/s, 13.9447s/100 iters), loss = 0.445546
I1206 11:17:01.251551  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.445546 (* 1 = 0.445546 loss)
I1206 11:17:01.251564  2751 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I1206 11:17:05.772676  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:17:11.964479  2751 solver.cpp:357] Iteration 23100 (9.33416 iter/s, 10.7133s/100 iters), loss = 0.482272
I1206 11:17:11.964543  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.482272 (* 1 = 0.482272 loss)
I1206 11:17:11.964552  2751 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I1206 11:17:22.689290  2751 solver.cpp:357] Iteration 23200 (9.32388 iter/s, 10.7252s/100 iters), loss = 0.331272
I1206 11:17:22.689411  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.331272 (* 1 = 0.331272 loss)
I1206 11:17:22.689424  2751 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I1206 11:17:33.418843  2751 solver.cpp:357] Iteration 23300 (9.31981 iter/s, 10.7298s/100 iters), loss = 0.43551
I1206 11:17:33.418906  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.43551 (* 1 = 0.43551 loss)
I1206 11:17:33.418918  2751 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I1206 11:17:44.141405  2751 solver.cpp:357] Iteration 23400 (9.32584 iter/s, 10.7229s/100 iters), loss = 0.407202
I1206 11:17:44.141469  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.407202 (* 1 = 0.407202 loss)
I1206 11:17:44.141481  2751 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I1206 11:17:47.687232  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:17:54.760756  2751 solver.cpp:514] Iteration 23500, Testing net (#0)
I1206 11:17:58.003017  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:17:58.015133  2751 solver.cpp:580]     Test net output #0: Softmax1 = 3.12821 (* 1 = 3.12821 loss)
I1206 11:17:58.015161  2751 solver.cpp:580]     Test net output #1: prob = 0.412699
I1206 11:17:58.015168  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:17:58.121104  2751 solver.cpp:357] Iteration 23500 (7.153 iter/s, 13.9801s/100 iters), loss = 0.469247
I1206 11:17:58.121145  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.469247 (* 1 = 0.469247 loss)
I1206 11:17:58.121158  2751 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I1206 11:18:08.826961  2751 solver.cpp:357] Iteration 23600 (9.34039 iter/s, 10.7062s/100 iters), loss = 0.347335
I1206 11:18:08.827023  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.347335 (* 1 = 0.347335 loss)
I1206 11:18:08.827033  2751 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I1206 11:18:19.552572  2751 solver.cpp:357] Iteration 23700 (9.3232 iter/s, 10.7259s/100 iters), loss = 0.36507
I1206 11:18:19.552639  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.36507 (* 1 = 0.36507 loss)
I1206 11:18:19.552649  2751 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I1206 11:18:30.274492  2751 solver.cpp:357] Iteration 23800 (9.32642 iter/s, 10.7222s/100 iters), loss = 0.426843
I1206 11:18:30.274688  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.426843 (* 1 = 0.426843 loss)
I1206 11:18:30.274698  2751 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I1206 11:18:32.857383  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:18:41.006042  2751 solver.cpp:357] Iteration 23900 (9.31817 iter/s, 10.7317s/100 iters), loss = 0.47649
I1206 11:18:41.006103  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.476489 (* 1 = 0.476489 loss)
I1206 11:18:41.006112  2751 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I1206 11:18:51.638682  2751 solver.cpp:514] Iteration 24000, Testing net (#0)
I1206 11:18:54.847417  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:18:54.859486  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.83872 (* 1 = 0.83872 loss)
I1206 11:18:54.859513  2751 solver.cpp:580]     Test net output #1: prob = 0.7217
I1206 11:18:54.859519  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:18:54.968194  2751 solver.cpp:357] Iteration 24000 (7.162 iter/s, 13.9626s/100 iters), loss = 0.444789
I1206 11:18:54.968243  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.444789 (* 1 = 0.444789 loss)
I1206 11:18:54.968256  2751 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I1206 11:19:05.693361  2751 solver.cpp:357] Iteration 24100 (9.3236 iter/s, 10.7255s/100 iters), loss = 0.356225
I1206 11:19:05.693506  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.356225 (* 1 = 0.356225 loss)
I1206 11:19:05.693516  2751 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I1206 11:19:16.408746  2751 solver.cpp:357] Iteration 24200 (9.33219 iter/s, 10.7156s/100 iters), loss = 0.396624
I1206 11:19:16.408809  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.396624 (* 1 = 0.396624 loss)
I1206 11:19:16.408820  2751 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I1206 11:19:17.921907  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:19:27.113276  2751 solver.cpp:357] Iteration 24300 (9.34159 iter/s, 10.7048s/100 iters), loss = 0.582975
I1206 11:19:27.113340  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.582975 (* 1 = 0.582975 loss)
I1206 11:19:27.113349  2751 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I1206 11:19:37.833614  2751 solver.cpp:357] Iteration 24400 (9.32782 iter/s, 10.7206s/100 iters), loss = 0.442304
I1206 11:19:37.833755  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.442304 (* 1 = 0.442304 loss)
I1206 11:19:37.833768  2751 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I1206 11:19:48.438541  2751 solver.cpp:514] Iteration 24500, Testing net (#0)
I1206 11:19:51.633267  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:19:51.645337  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.865023 (* 1 = 0.865023 loss)
I1206 11:19:51.645364  2751 solver.cpp:580]     Test net output #1: prob = 0.7426
I1206 11:19:51.645371  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:19:51.751205  2751 solver.cpp:357] Iteration 24500 (7.18499 iter/s, 13.9179s/100 iters), loss = 0.378507
I1206 11:19:51.751247  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.378507 (* 1 = 0.378507 loss)
I1206 11:19:51.751261  2751 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I1206 11:20:02.489244  2751 solver.cpp:357] Iteration 24600 (9.31243 iter/s, 10.7383s/100 iters), loss = 0.435086
I1206 11:20:02.489308  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.435086 (* 1 = 0.435086 loss)
I1206 11:20:02.489317  2751 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I1206 11:20:03.032990  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:20:13.214313  2751 solver.cpp:357] Iteration 24700 (9.32372 iter/s, 10.7253s/100 iters), loss = 0.45729
I1206 11:20:13.214468  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.45729 (* 1 = 0.45729 loss)
I1206 11:20:13.214478  2751 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I1206 11:20:23.945085  2751 solver.cpp:357] Iteration 24800 (9.31884 iter/s, 10.7309s/100 iters), loss = 0.386797
I1206 11:20:23.945149  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.386797 (* 1 = 0.386797 loss)
I1206 11:20:23.945159  2751 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I1206 11:20:34.664535  2751 solver.cpp:357] Iteration 24900 (9.32861 iter/s, 10.7197s/100 iters), loss = 0.544033
I1206 11:20:34.664600  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.544033 (* 1 = 0.544033 loss)
I1206 11:20:34.664609  2751 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I1206 11:20:44.866873  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:20:45.283303  2751 solver.cpp:514] Iteration 25000, Testing net (#0)
I1206 11:20:48.501700  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:20:48.513870  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.34836 (* 1 = 1.34836 loss)
I1206 11:20:48.513898  2751 solver.cpp:580]     Test net output #1: prob = 0.619901
I1206 11:20:48.513906  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:20:48.619380  2751 solver.cpp:357] Iteration 25000 (7.16578 iter/s, 13.9552s/100 iters), loss = 0.449774
I1206 11:20:48.619423  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.449774 (* 1 = 0.449774 loss)
I1206 11:20:48.619434  2751 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I1206 11:20:59.328019  2751 solver.cpp:357] Iteration 25100 (9.33802 iter/s, 10.7089s/100 iters), loss = 0.360461
I1206 11:20:59.328083  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.36046 (* 1 = 0.36046 loss)
I1206 11:20:59.328092  2751 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I1206 11:21:10.052357  2751 solver.cpp:357] Iteration 25200 (9.32437 iter/s, 10.7246s/100 iters), loss = 0.408496
I1206 11:21:10.052422  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.408496 (* 1 = 0.408496 loss)
I1206 11:21:10.052430  2751 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I1206 11:21:20.775367  2751 solver.cpp:357] Iteration 25300 (9.32553 iter/s, 10.7233s/100 iters), loss = 0.400338
I1206 11:21:20.775470  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.400338 (* 1 = 0.400338 loss)
I1206 11:21:20.775481  2751 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I1206 11:21:29.998307  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:21:31.498821  2751 solver.cpp:357] Iteration 25400 (9.32518 iter/s, 10.7237s/100 iters), loss = 0.526959
I1206 11:21:31.498884  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.526959 (* 1 = 0.526959 loss)
I1206 11:21:31.498894  2751 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I1206 11:21:42.114481  2751 solver.cpp:514] Iteration 25500, Testing net (#0)
I1206 11:21:45.326220  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:21:45.345291  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.02396 (* 1 = 1.02396 loss)
I1206 11:21:45.345321  2751 solver.cpp:580]     Test net output #1: prob = 0.685
I1206 11:21:45.345330  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:21:45.450378  2751 solver.cpp:357] Iteration 25500 (7.16748 iter/s, 13.9519s/100 iters), loss = 0.391461
I1206 11:21:45.450418  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.391461 (* 1 = 0.391461 loss)
I1206 11:21:45.450429  2751 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I1206 11:21:56.175595  2751 solver.cpp:357] Iteration 25600 (9.3236 iter/s, 10.7255s/100 iters), loss = 0.326045
I1206 11:21:56.175740  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.326045 (* 1 = 0.326045 loss)
I1206 11:21:56.175751  2751 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I1206 11:22:06.895223  2751 solver.cpp:357] Iteration 25700 (9.32855 iter/s, 10.7198s/100 iters), loss = 0.375427
I1206 11:22:06.895287  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.375427 (* 1 = 0.375427 loss)
I1206 11:22:06.895295  2751 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I1206 11:22:15.154531  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:22:17.615849  2751 solver.cpp:357] Iteration 25800 (9.32761 iter/s, 10.7209s/100 iters), loss = 0.463676
I1206 11:22:17.615913  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.463676 (* 1 = 0.463676 loss)
I1206 11:22:17.615922  2751 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I1206 11:22:28.340885  2751 solver.cpp:357] Iteration 25900 (9.32378 iter/s, 10.7253s/100 iters), loss = 0.457196
I1206 11:22:28.341092  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.457196 (* 1 = 0.457196 loss)
I1206 11:22:28.341105  2751 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I1206 11:22:38.944248  2751 solver.cpp:514] Iteration 26000, Testing net (#0)
I1206 11:22:42.160604  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:22:42.172641  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.09963 (* 1 = 1.09963 loss)
I1206 11:22:42.172669  2751 solver.cpp:580]     Test net output #1: prob = 0.643001
I1206 11:22:42.172677  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:22:42.278867  2751 solver.cpp:357] Iteration 26000 (7.17455 iter/s, 13.9382s/100 iters), loss = 0.447532
I1206 11:22:42.278910  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.447531 (* 1 = 0.447531 loss)
I1206 11:22:42.278923  2751 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I1206 11:22:53.002283  2751 solver.cpp:357] Iteration 26100 (9.32518 iter/s, 10.7237s/100 iters), loss = 0.371261
I1206 11:22:53.002346  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.371261 (* 1 = 0.371261 loss)
I1206 11:22:53.002354  2751 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I1206 11:23:00.180857  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:23:03.710717  2751 solver.cpp:357] Iteration 26200 (9.33824 iter/s, 10.7087s/100 iters), loss = 0.428263
I1206 11:23:03.710783  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.428263 (* 1 = 0.428263 loss)
I1206 11:23:03.710791  2751 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I1206 11:23:14.434577  2751 solver.cpp:357] Iteration 26300 (9.32481 iter/s, 10.7241s/100 iters), loss = 0.358967
I1206 11:23:14.434640  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.358967 (* 1 = 0.358967 loss)
I1206 11:23:14.434653  2751 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I1206 11:23:25.157336  2751 solver.cpp:357] Iteration 26400 (9.32577 iter/s, 10.723s/100 iters), loss = 0.366727
I1206 11:23:25.157399  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.366727 (* 1 = 0.366727 loss)
I1206 11:23:25.157411  2751 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I1206 11:23:35.774441  2751 solver.cpp:514] Iteration 26500, Testing net (#0)
I1206 11:23:39.022964  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:23:39.034658  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.22287 (* 1 = 1.22287 loss)
I1206 11:23:39.034685  2751 solver.cpp:580]     Test net output #1: prob = 0.6443
I1206 11:23:39.034693  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:23:39.141440  2751 solver.cpp:357] Iteration 26500 (7.15082 iter/s, 13.9844s/100 iters), loss = 0.412531
I1206 11:23:39.141484  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.412531 (* 1 = 0.412531 loss)
I1206 11:23:39.141494  2751 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I1206 11:23:45.371515  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:23:49.858194  2751 solver.cpp:357] Iteration 26600 (9.33099 iter/s, 10.717s/100 iters), loss = 0.380117
I1206 11:23:49.858260  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.380117 (* 1 = 0.380117 loss)
I1206 11:23:49.858271  2751 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I1206 11:24:00.591768  2751 solver.cpp:357] Iteration 26700 (9.31639 iter/s, 10.7338s/100 iters), loss = 0.426216
I1206 11:24:00.591832  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.426216 (* 1 = 0.426216 loss)
I1206 11:24:00.591845  2751 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I1206 11:24:11.330425  2751 solver.cpp:357] Iteration 26800 (9.31198 iter/s, 10.7389s/100 iters), loss = 0.49893
I1206 11:24:11.330629  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.49893 (* 1 = 0.49893 loss)
I1206 11:24:11.330639  2751 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I1206 11:24:22.063760  2751 solver.cpp:357] Iteration 26900 (9.31672 iter/s, 10.7334s/100 iters), loss = 0.342333
I1206 11:24:22.063823  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.342333 (* 1 = 0.342333 loss)
I1206 11:24:22.063833  2751 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I1206 11:24:27.329568  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:24:32.698921  2751 solver.cpp:514] Iteration 27000, Testing net (#0)
I1206 11:24:35.888097  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:24:35.899971  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.00672 (* 1 = 1.00672 loss)
I1206 11:24:35.899997  2751 solver.cpp:580]     Test net output #1: prob = 0.7022
I1206 11:24:35.900005  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:24:36.005733  2751 solver.cpp:357] Iteration 27000 (7.17244 iter/s, 13.9423s/100 iters), loss = 0.360282
I1206 11:24:36.005776  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.360281 (* 1 = 0.360281 loss)
I1206 11:24:36.005789  2751 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I1206 11:24:46.752521  2751 solver.cpp:357] Iteration 27100 (9.30492 iter/s, 10.747s/100 iters), loss = 0.454413
I1206 11:24:46.752663  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.454413 (* 1 = 0.454413 loss)
I1206 11:24:46.752672  2751 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I1206 11:24:57.499568  2751 solver.cpp:357] Iteration 27200 (9.30478 iter/s, 10.7472s/100 iters), loss = 0.406024
I1206 11:24:57.499632  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.406024 (* 1 = 0.406024 loss)
I1206 11:24:57.499644  2751 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I1206 11:25:08.240314  2751 solver.cpp:357] Iteration 27300 (9.31018 iter/s, 10.7409s/100 iters), loss = 0.345669
I1206 11:25:08.240377  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.345669 (* 1 = 0.345669 loss)
I1206 11:25:08.240387  2751 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I1206 11:25:12.445384  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:25:18.980176  2751 solver.cpp:357] Iteration 27400 (9.31094 iter/s, 10.74s/100 iters), loss = 0.316203
I1206 11:25:18.980301  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.316203 (* 1 = 0.316203 loss)
I1206 11:25:18.980314  2751 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I1206 11:25:29.618924  2751 solver.cpp:514] Iteration 27500, Testing net (#0)
I1206 11:25:32.789222  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:25:32.801005  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.896616 (* 1 = 0.896616 loss)
I1206 11:25:32.801033  2751 solver.cpp:580]     Test net output #1: prob = 0.6923
I1206 11:25:32.801039  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:25:32.907052  2751 solver.cpp:357] Iteration 27500 (7.18025 iter/s, 13.9271s/100 iters), loss = 0.421301
I1206 11:25:32.907096  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.421301 (* 1 = 0.421301 loss)
I1206 11:25:32.907106  2751 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I1206 11:25:43.645124  2751 solver.cpp:357] Iteration 27600 (9.31248 iter/s, 10.7383s/100 iters), loss = 0.47847
I1206 11:25:43.645189  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.47847 (* 1 = 0.47847 loss)
I1206 11:25:43.645200  2751 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I1206 11:25:54.389297  2751 solver.cpp:357] Iteration 27700 (9.30722 iter/s, 10.7444s/100 iters), loss = 0.62949
I1206 11:25:54.389442  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.62949 (* 1 = 0.62949 loss)
I1206 11:25:54.389451  2751 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I1206 11:25:57.614543  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:26:05.127765  2751 solver.cpp:357] Iteration 27800 (9.31223 iter/s, 10.7386s/100 iters), loss = 0.358995
I1206 11:26:05.127830  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.358995 (* 1 = 0.358995 loss)
I1206 11:26:05.127838  2751 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I1206 11:26:15.867070  2751 solver.cpp:357] Iteration 27900 (9.31144 iter/s, 10.7395s/100 iters), loss = 0.507556
I1206 11:26:15.867133  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.507556 (* 1 = 0.507556 loss)
I1206 11:26:15.867142  2751 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I1206 11:26:26.497589  2751 solver.cpp:514] Iteration 28000, Testing net (#0)
I1206 11:26:29.734027  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:26:29.746148  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.851334 (* 1 = 0.851334 loss)
I1206 11:26:29.746176  2751 solver.cpp:580]     Test net output #1: prob = 0.7404
I1206 11:26:29.746182  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:26:29.852493  2751 solver.cpp:357] Iteration 28000 (7.15017 iter/s, 13.9857s/100 iters), loss = 0.412136
I1206 11:26:29.852535  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.412136 (* 1 = 0.412136 loss)
I1206 11:26:29.852545  2751 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I1206 11:26:40.591078  2751 solver.cpp:357] Iteration 28100 (9.31205 iter/s, 10.7388s/100 iters), loss = 0.397522
I1206 11:26:40.591141  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.397522 (* 1 = 0.397522 loss)
I1206 11:26:40.591153  2751 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I1206 11:26:42.758045  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:26:51.343634  2751 solver.cpp:357] Iteration 28200 (9.29997 iter/s, 10.7527s/100 iters), loss = 0.563845
I1206 11:26:51.343699  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.563845 (* 1 = 0.563845 loss)
I1206 11:26:51.343709  2751 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I1206 11:27:02.088305  2751 solver.cpp:357] Iteration 28300 (9.30679 iter/s, 10.7448s/100 iters), loss = 0.415675
I1206 11:27:02.088404  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.415674 (* 1 = 0.415674 loss)
I1206 11:27:02.088414  2751 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I1206 11:27:12.830772  2751 solver.cpp:357] Iteration 28400 (9.30873 iter/s, 10.7426s/100 iters), loss = 0.309254
I1206 11:27:12.830835  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.309254 (* 1 = 0.309254 loss)
I1206 11:27:12.830847  2751 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I1206 11:27:23.458758  2751 solver.cpp:514] Iteration 28500, Testing net (#0)
I1206 11:27:26.660483  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:27:26.673135  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.76893 (* 1 = 1.76893 loss)
I1206 11:27:26.673161  2751 solver.cpp:580]     Test net output #1: prob = 0.5551
I1206 11:27:26.673168  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:27:26.779340  2751 solver.cpp:357] Iteration 28500 (7.16907 iter/s, 13.9488s/100 iters), loss = 0.354449
I1206 11:27:26.779381  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.354449 (* 1 = 0.354449 loss)
I1206 11:27:26.779395  2751 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I1206 11:27:27.974988  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:27:37.520233  2751 solver.cpp:357] Iteration 28600 (9.31005 iter/s, 10.7411s/100 iters), loss = 0.378698
I1206 11:27:37.520378  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.378698 (* 1 = 0.378698 loss)
I1206 11:27:37.520388  2751 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I1206 11:27:48.265988  2751 solver.cpp:357] Iteration 28700 (9.30593 iter/s, 10.7458s/100 iters), loss = 0.316216
I1206 11:27:48.266052  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.316216 (* 1 = 0.316216 loss)
I1206 11:27:48.266062  2751 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I1206 11:27:58.999858  2751 solver.cpp:357] Iteration 28800 (9.31616 iter/s, 10.734s/100 iters), loss = 0.340759
I1206 11:27:58.999922  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.340759 (* 1 = 0.340759 loss)
I1206 11:27:58.999933  2751 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I1206 11:28:09.747617  2751 solver.cpp:357] Iteration 28900 (9.30413 iter/s, 10.7479s/100 iters), loss = 0.441795
I1206 11:28:09.747774  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.441794 (* 1 = 0.441794 loss)
I1206 11:28:09.747784  2751 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I1206 11:28:09.968958  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:28:20.366446  2751 solver.cpp:514] Iteration 29000, Testing net (#0)
I1206 11:28:23.599038  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:28:23.611155  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.939924 (* 1 = 0.939924 loss)
I1206 11:28:23.611183  2751 solver.cpp:580]     Test net output #1: prob = 0.6975
I1206 11:28:23.611189  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:28:23.719741  2751 solver.cpp:357] Iteration 29000 (7.15704 iter/s, 13.9723s/100 iters), loss = 0.500119
I1206 11:28:23.719784  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.500119 (* 1 = 0.500119 loss)
I1206 11:28:23.719797  2751 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I1206 11:28:34.471258  2751 solver.cpp:357] Iteration 29100 (9.30086 iter/s, 10.7517s/100 iters), loss = 0.395593
I1206 11:28:34.471323  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.395593 (* 1 = 0.395593 loss)
I1206 11:28:34.471331  2751 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I1206 11:28:45.218734  2751 solver.cpp:357] Iteration 29200 (9.30438 iter/s, 10.7476s/100 iters), loss = 0.386846
I1206 11:28:45.218881  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.386846 (* 1 = 0.386846 loss)
I1206 11:28:45.218890  2751 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I1206 11:28:55.126796  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:28:55.973989  2751 solver.cpp:357] Iteration 29300 (9.29772 iter/s, 10.7553s/100 iters), loss = 0.360105
I1206 11:28:55.974052  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.360105 (* 1 = 0.360105 loss)
I1206 11:28:55.974061  2751 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I1206 11:29:06.723373  2751 solver.cpp:357] Iteration 29400 (9.30273 iter/s, 10.7495s/100 iters), loss = 0.368709
I1206 11:29:06.723438  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.368709 (* 1 = 0.368709 loss)
I1206 11:29:06.723448  2751 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I1206 11:29:17.363157  2751 solver.cpp:514] Iteration 29500, Testing net (#0)
I1206 11:29:20.562366  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:29:20.583544  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.987955 (* 1 = 0.987955 loss)
I1206 11:29:20.583621  2751 solver.cpp:580]     Test net output #1: prob = 0.6772
I1206 11:29:20.583647  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:29:20.689823  2751 solver.cpp:357] Iteration 29500 (7.1599 iter/s, 13.9667s/100 iters), loss = 0.441206
I1206 11:29:20.689864  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.441206 (* 1 = 0.441206 loss)
I1206 11:29:20.689874  2751 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I1206 11:29:31.431119  2751 solver.cpp:357] Iteration 29600 (9.30972 iter/s, 10.7415s/100 iters), loss = 0.309709
I1206 11:29:31.431183  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.309709 (* 1 = 0.309709 loss)
I1206 11:29:31.431192  2751 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I1206 11:29:40.361138  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:29:42.178748  2751 solver.cpp:357] Iteration 29700 (9.30425 iter/s, 10.7478s/100 iters), loss = 0.317199
I1206 11:29:42.178812  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.317199 (* 1 = 0.317199 loss)
I1206 11:29:42.178820  2751 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I1206 11:29:52.927673  2751 solver.cpp:357] Iteration 29800 (9.30313 iter/s, 10.7491s/100 iters), loss = 0.333285
I1206 11:29:52.927886  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.333285 (* 1 = 0.333285 loss)
I1206 11:29:52.927896  2751 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I1206 11:30:03.669423  2751 solver.cpp:357] Iteration 29900 (9.30947 iter/s, 10.7417s/100 iters), loss = 0.377954
I1206 11:30:03.669488  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.377954 (* 1 = 0.377954 loss)
I1206 11:30:03.669498  2751 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I1206 11:30:14.318694  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.caffemodel
I1206 11:30:14.326699  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.solverstate
I1206 11:30:14.329483  2751 solver.cpp:514] Iteration 30000, Testing net (#0)
I1206 11:30:17.551223  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:30:17.563287  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.10487 (* 1 = 1.10487 loss)
I1206 11:30:17.563314  2751 solver.cpp:580]     Test net output #1: prob = 0.6728
I1206 11:30:17.563321  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:30:17.668949  2751 solver.cpp:357] Iteration 30000 (7.14299 iter/s, 13.9997s/100 iters), loss = 0.262593
I1206 11:30:17.668992  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.262593 (* 1 = 0.262593 loss)
I1206 11:30:17.669001  2751 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I1206 11:30:25.619308  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:30:28.407184  2751 solver.cpp:357] Iteration 30100 (9.31238 iter/s, 10.7384s/100 iters), loss = 0.369707
I1206 11:30:28.407246  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.369707 (* 1 = 0.369707 loss)
I1206 11:30:28.407258  2751 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I1206 11:30:39.140645  2751 solver.cpp:357] Iteration 30200 (9.31654 iter/s, 10.7336s/100 iters), loss = 0.50865
I1206 11:30:39.140707  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.50865 (* 1 = 0.50865 loss)
I1206 11:30:39.140717  2751 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I1206 11:30:49.876349  2751 solver.cpp:357] Iteration 30300 (9.31459 iter/s, 10.7358s/100 iters), loss = 0.397455
I1206 11:30:49.876413  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.397455 (* 1 = 0.397455 loss)
I1206 11:30:49.876423  2751 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I1206 11:31:00.625566  2751 solver.cpp:357] Iteration 30400 (9.30288 iter/s, 10.7494s/100 iters), loss = 0.277963
I1206 11:31:00.625713  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.277963 (* 1 = 0.277963 loss)
I1206 11:31:00.625722  2751 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I1206 11:31:07.506264  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:31:11.257169  2751 solver.cpp:514] Iteration 30500, Testing net (#0)
I1206 11:31:14.499186  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:31:14.511384  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.56281 (* 1 = 1.56281 loss)
I1206 11:31:14.511412  2751 solver.cpp:580]     Test net output #1: prob = 0.6192
I1206 11:31:14.511420  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:31:14.617413  2751 solver.cpp:357] Iteration 30500 (7.14696 iter/s, 13.992s/100 iters), loss = 0.332931
I1206 11:31:14.617455  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.332931 (* 1 = 0.332931 loss)
I1206 11:31:14.617468  2751 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I1206 11:31:25.352591  2751 solver.cpp:357] Iteration 30600 (9.31503 iter/s, 10.7353s/100 iters), loss = 0.398323
I1206 11:31:25.352653  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.398323 (* 1 = 0.398323 loss)
I1206 11:31:25.352663  2751 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I1206 11:31:36.098821  2751 solver.cpp:357] Iteration 30700 (9.30547 iter/s, 10.7464s/100 iters), loss = 0.434982
I1206 11:31:36.099020  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.434982 (* 1 = 0.434982 loss)
I1206 11:31:36.099030  2751 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I1206 11:31:46.831429  2751 solver.cpp:357] Iteration 30800 (9.3174 iter/s, 10.7326s/100 iters), loss = 0.291879
I1206 11:31:46.831491  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.291879 (* 1 = 0.291879 loss)
I1206 11:31:46.831503  2751 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I1206 11:31:52.749188  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:31:57.584404  2751 solver.cpp:357] Iteration 30900 (9.29963 iter/s, 10.7531s/100 iters), loss = 0.502286
I1206 11:31:57.584470  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.502286 (* 1 = 0.502286 loss)
I1206 11:31:57.584480  2751 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I1206 11:32:08.216905  2751 solver.cpp:514] Iteration 31000, Testing net (#0)
I1206 11:32:11.435417  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:32:11.447752  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.4076 (* 1 = 1.4076 loss)
I1206 11:32:11.447779  2751 solver.cpp:580]     Test net output #1: prob = 0.5907
I1206 11:32:11.447788  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:32:11.553655  2751 solver.cpp:357] Iteration 31000 (7.15848 iter/s, 13.9695s/100 iters), loss = 0.39695
I1206 11:32:11.553697  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.39695 (* 1 = 0.39695 loss)
I1206 11:32:11.553707  2751 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I1206 11:32:22.298082  2751 solver.cpp:357] Iteration 31100 (9.30702 iter/s, 10.7446s/100 iters), loss = 0.4177
I1206 11:32:22.298146  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.4177 (* 1 = 0.4177 loss)
I1206 11:32:22.298154  2751 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I1206 11:32:33.050958  2751 solver.cpp:357] Iteration 31200 (9.29972 iter/s, 10.753s/100 iters), loss = 0.334215
I1206 11:32:33.051019  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.334215 (* 1 = 0.334215 loss)
I1206 11:32:33.051030  2751 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I1206 11:32:37.895663  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:32:43.779484  2751 solver.cpp:357] Iteration 31300 (9.32083 iter/s, 10.7287s/100 iters), loss = 0.299747
I1206 11:32:43.779583  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.299747 (* 1 = 0.299747 loss)
I1206 11:32:43.779594  2751 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I1206 11:32:54.517640  2751 solver.cpp:357] Iteration 31400 (9.3125 iter/s, 10.7383s/100 iters), loss = 0.399268
I1206 11:32:54.517704  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.399268 (* 1 = 0.399268 loss)
I1206 11:32:54.517715  2751 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I1206 11:33:05.149375  2751 solver.cpp:514] Iteration 31500, Testing net (#0)
I1206 11:33:08.377197  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:33:08.389304  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.943645 (* 1 = 0.943645 loss)
I1206 11:33:08.389333  2751 solver.cpp:580]     Test net output #1: prob = 0.6976
I1206 11:33:08.389338  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:33:08.495229  2751 solver.cpp:357] Iteration 31500 (7.15421 iter/s, 13.9778s/100 iters), loss = 0.294445
I1206 11:33:08.495270  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.294445 (* 1 = 0.294445 loss)
I1206 11:33:08.495280  2751 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I1206 11:33:19.246601  2751 solver.cpp:357] Iteration 31600 (9.30101 iter/s, 10.7515s/100 iters), loss = 0.307931
I1206 11:33:19.246742  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.307931 (* 1 = 0.307931 loss)
I1206 11:33:19.246752  2751 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I1206 11:33:23.124070  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:33:29.987604  2751 solver.cpp:357] Iteration 31700 (9.31007 iter/s, 10.7411s/100 iters), loss = 0.354684
I1206 11:33:29.987669  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.354684 (* 1 = 0.354684 loss)
I1206 11:33:29.987680  2751 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I1206 11:33:40.732048  2751 solver.cpp:357] Iteration 31800 (9.30703 iter/s, 10.7446s/100 iters), loss = 0.382497
I1206 11:33:40.732110  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.382497 (* 1 = 0.382497 loss)
I1206 11:33:40.732121  2751 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I1206 11:33:51.486965  2751 solver.cpp:357] Iteration 31900 (9.29796 iter/s, 10.755s/100 iters), loss = 0.462706
I1206 11:33:51.487151  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.462706 (* 1 = 0.462706 loss)
I1206 11:33:51.487161  2751 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I1206 11:34:02.118582  2751 solver.cpp:514] Iteration 32000, Testing net (#0)
I1206 11:34:05.326501  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:34:05.338697  2751 solver.cpp:580]     Test net output #0: Softmax1 = 1.90231 (* 1 = 1.90231 loss)
I1206 11:34:05.338726  2751 solver.cpp:580]     Test net output #1: prob = 0.5471
I1206 11:34:05.338732  2751 solver.cpp:593]     Max_acc: 0.7765  with iter: 14500
I1206 11:34:05.443997  2751 solver.cpp:357] Iteration 32000 (7.16481 iter/s, 13.9571s/100 iters), loss = 0.426426
I1206 11:34:05.444041  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.426426 (* 1 = 0.426426 loss)
I1206 11:34:05.444054  2751 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I1206 11:34:05.444061  2751 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I1206 11:34:08.341933  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:34:16.155709  2751 solver.cpp:357] Iteration 32100 (9.33545 iter/s, 10.7119s/100 iters), loss = 0.251625
I1206 11:34:16.155773  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.251625 (* 1 = 0.251625 loss)
I1206 11:34:16.155782  2751 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I1206 11:34:26.889559  2751 solver.cpp:357] Iteration 32200 (9.31622 iter/s, 10.734s/100 iters), loss = 0.398369
I1206 11:34:26.889679  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.398369 (* 1 = 0.398369 loss)
I1206 11:34:26.889693  2751 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I1206 11:34:37.636888  2751 solver.cpp:357] Iteration 32300 (9.30458 iter/s, 10.7474s/100 iters), loss = 0.204612
I1206 11:34:37.636951  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.204612 (* 1 = 0.204612 loss)
I1206 11:34:37.636961  2751 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I1206 11:34:48.383687  2751 solver.cpp:357] Iteration 32400 (9.30499 iter/s, 10.7469s/100 iters), loss = 0.218743
I1206 11:34:48.383749  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.218743 (* 1 = 0.218743 loss)
I1206 11:34:48.383759  2751 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I1206 11:34:50.217295  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:34:59.018846  2751 solver.cpp:514] Iteration 32500, Testing net (#0)
I1206 11:35:02.263685  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:35:02.275769  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.356491 (* 1 = 0.356491 loss)
I1206 11:35:02.275796  2751 solver.cpp:580]     Test net output #1: prob = 0.877002
I1206 11:35:02.275810  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_32500.caffemodel
I1206 11:35:02.283712  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_32500.solverstate
I1206 11:35:02.286123  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:35:02.392313  2751 solver.cpp:357] Iteration 32500 (7.13836 iter/s, 14.0088s/100 iters), loss = 0.172368
I1206 11:35:02.392359  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.172368 (* 1 = 0.172368 loss)
I1206 11:35:02.392370  2751 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I1206 11:35:13.120935  2751 solver.cpp:357] Iteration 32600 (9.32074 iter/s, 10.7288s/100 iters), loss = 0.191564
I1206 11:35:13.120998  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.191564 (* 1 = 0.191564 loss)
I1206 11:35:13.121009  2751 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I1206 11:35:23.856259  2751 solver.cpp:357] Iteration 32700 (9.31494 iter/s, 10.7354s/100 iters), loss = 0.261149
I1206 11:35:23.856323  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.261149 (* 1 = 0.261149 loss)
I1206 11:35:23.856333  2751 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I1206 11:35:34.586258  2751 solver.cpp:357] Iteration 32800 (9.31956 iter/s, 10.7301s/100 iters), loss = 0.223531
I1206 11:35:34.586462  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.223531 (* 1 = 0.223531 loss)
I1206 11:35:34.586472  2751 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I1206 11:35:35.455557  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:35:45.319494  2751 solver.cpp:357] Iteration 32900 (9.31687 iter/s, 10.7332s/100 iters), loss = 0.137475
I1206 11:35:45.319557  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.137475 (* 1 = 0.137475 loss)
I1206 11:35:45.319568  2751 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I1206 11:35:55.942997  2751 solver.cpp:514] Iteration 33000, Testing net (#0)
I1206 11:35:59.181232  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:35:59.192673  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.451331 (* 1 = 0.451331 loss)
I1206 11:35:59.192700  2751 solver.cpp:580]     Test net output #1: prob = 0.846701
I1206 11:35:59.192706  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:35:59.298049  2751 solver.cpp:357] Iteration 33000 (7.15372 iter/s, 13.9787s/100 iters), loss = 0.18912
I1206 11:35:59.298095  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.18912 (* 1 = 0.18912 loss)
I1206 11:35:59.298106  2751 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I1206 11:36:10.053915  2751 solver.cpp:357] Iteration 33100 (9.29714 iter/s, 10.756s/100 iters), loss = 0.165202
I1206 11:36:10.054067  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.165202 (* 1 = 0.165202 loss)
I1206 11:36:10.054076  2751 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I1206 11:36:20.700940  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:36:20.805573  2751 solver.cpp:357] Iteration 33200 (9.30086 iter/s, 10.7517s/100 iters), loss = 0.154533
I1206 11:36:20.805624  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.154533 (* 1 = 0.154533 loss)
I1206 11:36:20.805634  2751 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I1206 11:36:31.548056  2751 solver.cpp:357] Iteration 33300 (9.30872 iter/s, 10.7426s/100 iters), loss = 0.211073
I1206 11:36:31.548120  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.211073 (* 1 = 0.211073 loss)
I1206 11:36:31.548130  2751 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I1206 11:36:42.293912  2751 solver.cpp:357] Iteration 33400 (9.30581 iter/s, 10.746s/100 iters), loss = 0.128478
I1206 11:36:42.294011  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.128478 (* 1 = 0.128478 loss)
I1206 11:36:42.294023  2751 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I1206 11:36:52.933967  2751 solver.cpp:514] Iteration 33500, Testing net (#0)
I1206 11:36:56.182831  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:36:56.194866  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.511691 (* 1 = 0.511691 loss)
I1206 11:36:56.194893  2751 solver.cpp:580]     Test net output #1: prob = 0.829201
I1206 11:36:56.194900  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:36:56.301266  2751 solver.cpp:357] Iteration 33500 (7.13903 iter/s, 14.0075s/100 iters), loss = 0.195501
I1206 11:36:56.301309  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.1955 (* 1 = 0.1955 loss)
I1206 11:36:56.301321  2751 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I1206 11:37:05.874585  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:37:07.050458  2751 solver.cpp:357] Iteration 33600 (9.30291 iter/s, 10.7493s/100 iters), loss = 0.22441
I1206 11:37:07.050521  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.22441 (* 1 = 0.22441 loss)
I1206 11:37:07.050530  2751 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I1206 11:37:17.789804  2751 solver.cpp:357] Iteration 33700 (9.31145 iter/s, 10.7395s/100 iters), loss = 0.16691
I1206 11:37:17.790002  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.16691 (* 1 = 0.16691 loss)
I1206 11:37:17.790011  2751 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I1206 11:37:28.531939  2751 solver.cpp:357] Iteration 33800 (9.30915 iter/s, 10.7421s/100 iters), loss = 0.188558
I1206 11:37:28.531998  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.188558 (* 1 = 0.188558 loss)
I1206 11:37:28.532009  2751 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I1206 11:37:39.279397  2751 solver.cpp:357] Iteration 33900 (9.30443 iter/s, 10.7476s/100 iters), loss = 0.16158
I1206 11:37:39.279462  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.16158 (* 1 = 0.16158 loss)
I1206 11:37:39.279472  2751 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I1206 11:37:47.878396  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:37:49.916548  2751 solver.cpp:514] Iteration 34000, Testing net (#0)
I1206 11:37:53.164963  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:37:53.176606  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.760587 (* 1 = 0.760587 loss)
I1206 11:37:53.176632  2751 solver.cpp:580]     Test net output #1: prob = 0.7591
I1206 11:37:53.176638  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:37:53.285049  2751 solver.cpp:357] Iteration 34000 (7.13989 iter/s, 14.0058s/100 iters), loss = 0.139579
I1206 11:37:53.285094  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.139579 (* 1 = 0.139579 loss)
I1206 11:37:53.285107  2751 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I1206 11:38:04.036409  2751 solver.cpp:357] Iteration 34100 (9.30104 iter/s, 10.7515s/100 iters), loss = 0.192536
I1206 11:38:04.036475  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.192536 (* 1 = 0.192536 loss)
I1206 11:38:04.036484  2751 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I1206 11:38:14.773512  2751 solver.cpp:357] Iteration 34200 (9.3134 iter/s, 10.7372s/100 iters), loss = 0.114008
I1206 11:38:14.773576  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.114008 (* 1 = 0.114008 loss)
I1206 11:38:14.773586  2751 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I1206 11:38:25.505885  2751 solver.cpp:357] Iteration 34300 (9.31751 iter/s, 10.7325s/100 iters), loss = 0.130915
I1206 11:38:25.505991  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.130915 (* 1 = 0.130915 loss)
I1206 11:38:25.506003  2751 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I1206 11:38:33.036690  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:38:36.244446  2751 solver.cpp:357] Iteration 34400 (9.31218 iter/s, 10.7386s/100 iters), loss = 0.248779
I1206 11:38:36.244510  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.248779 (* 1 = 0.248779 loss)
I1206 11:38:36.244521  2751 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I1206 11:38:46.882495  2751 solver.cpp:514] Iteration 34500, Testing net (#0)
I1206 11:38:50.062431  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:38:50.074545  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.754067 (* 1 = 0.754067 loss)
I1206 11:38:50.074573  2751 solver.cpp:580]     Test net output #1: prob = 0.76
I1206 11:38:50.074579  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:38:50.180905  2751 solver.cpp:357] Iteration 34500 (7.17534 iter/s, 13.9366s/100 iters), loss = 0.140128
I1206 11:38:50.180948  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.140127 (* 1 = 0.140127 loss)
I1206 11:38:50.180958  2751 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I1206 11:39:00.921660  2751 solver.cpp:357] Iteration 34600 (9.31022 iter/s, 10.7409s/100 iters), loss = 0.147101
I1206 11:39:00.921814  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.147101 (* 1 = 0.147101 loss)
I1206 11:39:00.921824  2751 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I1206 11:39:11.657774  2751 solver.cpp:357] Iteration 34700 (9.31434 iter/s, 10.7361s/100 iters), loss = 0.130636
I1206 11:39:11.657840  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.130636 (* 1 = 0.130636 loss)
I1206 11:39:11.657850  2751 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I1206 11:39:18.210168  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:39:22.399513  2751 solver.cpp:357] Iteration 34800 (9.30939 iter/s, 10.7418s/100 iters), loss = 0.154956
I1206 11:39:22.399577  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.154956 (* 1 = 0.154956 loss)
I1206 11:39:22.399586  2751 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I1206 11:39:33.137588  2751 solver.cpp:357] Iteration 34900 (9.31256 iter/s, 10.7382s/100 iters), loss = 0.181941
I1206 11:39:33.137742  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.181941 (* 1 = 0.181941 loss)
I1206 11:39:33.137753  2751 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I1206 11:39:43.777901  2751 solver.cpp:514] Iteration 35000, Testing net (#0)
I1206 11:39:46.990288  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:39:47.002343  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.591591 (* 1 = 0.591591 loss)
I1206 11:39:47.002372  2751 solver.cpp:580]     Test net output #1: prob = 0.8063
I1206 11:39:47.002378  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:39:47.107558  2751 solver.cpp:357] Iteration 35000 (7.15817 iter/s, 13.97s/100 iters), loss = 0.112543
I1206 11:39:47.107600  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.112543 (* 1 = 0.112543 loss)
I1206 11:39:47.107610  2751 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I1206 11:39:57.853595  2751 solver.cpp:357] Iteration 35100 (9.30565 iter/s, 10.7462s/100 iters), loss = 0.118245
I1206 11:39:57.853658  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.118245 (* 1 = 0.118245 loss)
I1206 11:39:57.853669  2751 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I1206 11:40:03.435050  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:40:08.588711  2751 solver.cpp:357] Iteration 35200 (9.31513 iter/s, 10.7352s/100 iters), loss = 0.182126
I1206 11:40:08.588776  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.182126 (* 1 = 0.182126 loss)
I1206 11:40:08.588786  2751 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I1206 11:40:19.331918  2751 solver.cpp:357] Iteration 35300 (9.30812 iter/s, 10.7433s/100 iters), loss = 0.126399
I1206 11:40:19.331980  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.126399 (* 1 = 0.126399 loss)
I1206 11:40:19.331990  2751 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I1206 11:40:30.081578  2751 solver.cpp:357] Iteration 35400 (9.30253 iter/s, 10.7498s/100 iters), loss = 0.142513
I1206 11:40:30.081640  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.142513 (* 1 = 0.142513 loss)
I1206 11:40:30.081652  2751 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I1206 11:40:40.721346  2751 solver.cpp:514] Iteration 35500, Testing net (#0)
I1206 11:40:43.922883  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:40:43.935034  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.550799 (* 1 = 0.550799 loss)
I1206 11:40:43.935060  2751 solver.cpp:580]     Test net output #1: prob = 0.814801
I1206 11:40:43.935066  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:40:44.040772  2751 solver.cpp:357] Iteration 35500 (7.16365 iter/s, 13.9594s/100 iters), loss = 0.165007
I1206 11:40:44.040814  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.165007 (* 1 = 0.165007 loss)
I1206 11:40:44.040827  2751 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I1206 11:40:48.566928  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:40:54.793146  2751 solver.cpp:357] Iteration 35600 (9.30016 iter/s, 10.7525s/100 iters), loss = 0.18212
I1206 11:40:54.793210  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.18212 (* 1 = 0.18212 loss)
I1206 11:40:54.793220  2751 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I1206 11:41:05.533432  2751 solver.cpp:357] Iteration 35700 (9.31065 iter/s, 10.7404s/100 iters), loss = 0.184312
I1206 11:41:05.533495  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.184312 (* 1 = 0.184312 loss)
I1206 11:41:05.533504  2751 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I1206 11:41:16.280910  2751 solver.cpp:357] Iteration 35800 (9.30442 iter/s, 10.7476s/100 iters), loss = 0.171652
I1206 11:41:16.281065  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.171652 (* 1 = 0.171652 loss)
I1206 11:41:16.281075  2751 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I1206 11:41:27.023471  2751 solver.cpp:357] Iteration 35900 (9.30875 iter/s, 10.7426s/100 iters), loss = 0.19867
I1206 11:41:27.023535  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.198669 (* 1 = 0.198669 loss)
I1206 11:41:27.023546  2751 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I1206 11:41:30.571126  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:41:37.659348  2751 solver.cpp:514] Iteration 36000, Testing net (#0)
I1206 11:41:40.868896  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:41:40.881062  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.732919 (* 1 = 0.732919 loss)
I1206 11:41:40.881090  2751 solver.cpp:580]     Test net output #1: prob = 0.7586
I1206 11:41:40.881096  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:41:40.986754  2751 solver.cpp:357] Iteration 36000 (7.16156 iter/s, 13.9634s/100 iters), loss = 0.16086
I1206 11:41:40.986796  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.16086 (* 1 = 0.16086 loss)
I1206 11:41:40.986806  2751 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I1206 11:41:51.716382  2751 solver.cpp:357] Iteration 36100 (9.31988 iter/s, 10.7297s/100 iters), loss = 0.119962
I1206 11:41:51.716527  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.119962 (* 1 = 0.119962 loss)
I1206 11:41:51.716539  2751 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I1206 11:42:02.471065  2751 solver.cpp:357] Iteration 36200 (9.29825 iter/s, 10.7547s/100 iters), loss = 0.0778415
I1206 11:42:02.471127  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0778414 (* 1 = 0.0778414 loss)
I1206 11:42:02.471137  2751 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I1206 11:42:13.211169  2751 solver.cpp:357] Iteration 36300 (9.31081 iter/s, 10.7402s/100 iters), loss = 0.179214
I1206 11:42:13.211232  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.179214 (* 1 = 0.179214 loss)
I1206 11:42:13.211243  2751 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I1206 11:42:15.791627  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:42:23.941673  2751 solver.cpp:357] Iteration 36400 (9.31914 iter/s, 10.7306s/100 iters), loss = 0.153972
I1206 11:42:23.941823  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.153972 (* 1 = 0.153972 loss)
I1206 11:42:23.941833  2751 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I1206 11:42:34.571455  2751 solver.cpp:514] Iteration 36500, Testing net (#0)
I1206 11:42:37.793810  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:42:37.805888  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.467604 (* 1 = 0.467604 loss)
I1206 11:42:37.805917  2751 solver.cpp:580]     Test net output #1: prob = 0.843901
I1206 11:42:37.805922  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:42:37.911458  2751 solver.cpp:357] Iteration 36500 (7.15827 iter/s, 13.9699s/100 iters), loss = 0.139855
I1206 11:42:37.911500  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.139855 (* 1 = 0.139855 loss)
I1206 11:42:37.911511  2751 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I1206 11:42:48.648418  2751 solver.cpp:357] Iteration 36600 (9.31352 iter/s, 10.7371s/100 iters), loss = 0.152873
I1206 11:42:48.648479  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.152873 (* 1 = 0.152873 loss)
I1206 11:42:48.648509  2751 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I1206 11:42:59.397713  2751 solver.cpp:357] Iteration 36700 (9.30285 iter/s, 10.7494s/100 iters), loss = 0.138892
I1206 11:42:59.397997  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.138892 (* 1 = 0.138892 loss)
I1206 11:42:59.398007  2751 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I1206 11:43:00.907336  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:43:10.139946  2751 solver.cpp:357] Iteration 36800 (9.30915 iter/s, 10.7421s/100 iters), loss = 0.185988
I1206 11:43:10.140012  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.185987 (* 1 = 0.185987 loss)
I1206 11:43:10.140022  2751 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I1206 11:43:20.886112  2751 solver.cpp:357] Iteration 36900 (9.30556 iter/s, 10.7463s/100 iters), loss = 0.145911
I1206 11:43:20.886176  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.145911 (* 1 = 0.145911 loss)
I1206 11:43:20.886188  2751 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I1206 11:43:31.517292  2751 solver.cpp:514] Iteration 37000, Testing net (#0)
I1206 11:43:34.728489  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:43:34.740572  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.488053 (* 1 = 0.488053 loss)
I1206 11:43:34.740599  2751 solver.cpp:580]     Test net output #1: prob = 0.842701
I1206 11:43:34.740607  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:43:34.846489  2751 solver.cpp:357] Iteration 37000 (7.16305 iter/s, 13.9605s/100 iters), loss = 0.147141
I1206 11:43:34.846532  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.147141 (* 1 = 0.147141 loss)
I1206 11:43:34.846544  2751 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I1206 11:43:45.593659  2751 solver.cpp:357] Iteration 37100 (9.30467 iter/s, 10.7473s/100 iters), loss = 0.0931945
I1206 11:43:45.593724  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0931945 (* 1 = 0.0931945 loss)
I1206 11:43:45.593734  2751 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I1206 11:43:46.134021  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:43:56.344954  2751 solver.cpp:357] Iteration 37200 (9.30112 iter/s, 10.7514s/100 iters), loss = 0.162426
I1206 11:43:56.345016  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.162426 (* 1 = 0.162426 loss)
I1206 11:43:56.345027  2751 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I1206 11:44:07.088732  2751 solver.cpp:357] Iteration 37300 (9.30762 iter/s, 10.7439s/100 iters), loss = 0.0889936
I1206 11:44:07.088841  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0889936 (* 1 = 0.0889936 loss)
I1206 11:44:07.088855  2751 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I1206 11:44:17.844905  2751 solver.cpp:357] Iteration 37400 (9.29694 iter/s, 10.7562s/100 iters), loss = 0.162014
I1206 11:44:17.844969  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.162014 (* 1 = 0.162014 loss)
I1206 11:44:17.844980  2751 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I1206 11:44:28.048810  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:44:28.474478  2751 solver.cpp:514] Iteration 37500, Testing net (#0)
I1206 11:44:31.660372  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:44:31.672400  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.524438 (* 1 = 0.524438 loss)
I1206 11:44:31.672426  2751 solver.cpp:580]     Test net output #1: prob = 0.827401
I1206 11:44:31.672433  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:44:31.778161  2751 solver.cpp:357] Iteration 37500 (7.17699 iter/s, 13.9334s/100 iters), loss = 0.102518
I1206 11:44:31.778203  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.102518 (* 1 = 0.102518 loss)
I1206 11:44:31.778213  2751 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I1206 11:44:42.520012  2751 solver.cpp:357] Iteration 37600 (9.30928 iter/s, 10.742s/100 iters), loss = 0.097678
I1206 11:44:42.520186  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.097678 (* 1 = 0.097678 loss)
I1206 11:44:42.520200  2751 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I1206 11:44:53.267743  2751 solver.cpp:357] Iteration 37700 (9.3043 iter/s, 10.7477s/100 iters), loss = 0.224776
I1206 11:44:53.267808  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.224776 (* 1 = 0.224776 loss)
I1206 11:44:53.267817  2751 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I1206 11:45:04.008051  2751 solver.cpp:357] Iteration 37800 (9.31064 iter/s, 10.7404s/100 iters), loss = 0.103371
I1206 11:45:04.008118  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.103371 (* 1 = 0.103371 loss)
I1206 11:45:04.008129  2751 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I1206 11:45:13.261201  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:45:14.758103  2751 solver.cpp:357] Iteration 37900 (9.3022 iter/s, 10.7501s/100 iters), loss = 0.173077
I1206 11:45:14.758164  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.173077 (* 1 = 0.173077 loss)
I1206 11:45:14.758173  2751 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I1206 11:45:25.412204  2751 solver.cpp:514] Iteration 38000, Testing net (#0)
I1206 11:45:28.554153  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:45:28.566217  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.560738 (* 1 = 0.560738 loss)
I1206 11:45:28.566246  2751 solver.cpp:580]     Test net output #1: prob = 0.8173
I1206 11:45:28.566251  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:45:28.673310  2751 solver.cpp:357] Iteration 38000 (7.1863 iter/s, 13.9154s/100 iters), loss = 0.133018
I1206 11:45:28.673352  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.133018 (* 1 = 0.133018 loss)
I1206 11:45:28.673364  2751 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I1206 11:45:39.419930  2751 solver.cpp:357] Iteration 38100 (9.30515 iter/s, 10.7467s/100 iters), loss = 0.111924
I1206 11:45:39.419993  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.111924 (* 1 = 0.111924 loss)
I1206 11:45:39.420003  2751 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I1206 11:45:50.165302  2751 solver.cpp:357] Iteration 38200 (9.30625 iter/s, 10.7455s/100 iters), loss = 0.0720815
I1206 11:45:50.165407  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0720815 (* 1 = 0.0720815 loss)
I1206 11:45:50.165419  2751 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I1206 11:45:58.445224  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:46:00.908406  2751 solver.cpp:357] Iteration 38300 (9.30825 iter/s, 10.7432s/100 iters), loss = 0.219595
I1206 11:46:00.908469  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.219595 (* 1 = 0.219595 loss)
I1206 11:46:00.908479  2751 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I1206 11:46:11.646342  2751 solver.cpp:357] Iteration 38400 (9.31269 iter/s, 10.738s/100 iters), loss = 0.13999
I1206 11:46:11.646404  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.13999 (* 1 = 0.13999 loss)
I1206 11:46:11.646414  2751 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I1206 11:46:22.283831  2751 solver.cpp:514] Iteration 38500, Testing net (#0)
I1206 11:46:25.486807  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:46:25.498790  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.555599 (* 1 = 0.555599 loss)
I1206 11:46:25.498817  2751 solver.cpp:580]     Test net output #1: prob = 0.828801
I1206 11:46:25.498823  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:46:25.604923  2751 solver.cpp:357] Iteration 38500 (7.16397 iter/s, 13.9587s/100 iters), loss = 0.117962
I1206 11:46:25.604966  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.117962 (* 1 = 0.117962 loss)
I1206 11:46:25.604976  2751 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I1206 11:46:36.351938  2751 solver.cpp:357] Iteration 38600 (9.30481 iter/s, 10.7471s/100 iters), loss = 0.056483
I1206 11:46:36.352002  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0564829 (* 1 = 0.0564829 loss)
I1206 11:46:36.352011  2751 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I1206 11:46:43.553962  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:46:47.093875  2751 solver.cpp:357] Iteration 38700 (9.30923 iter/s, 10.742s/100 iters), loss = 0.136118
I1206 11:46:47.093938  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.136118 (* 1 = 0.136118 loss)
I1206 11:46:47.093950  2751 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I1206 11:46:57.832036  2751 solver.cpp:357] Iteration 38800 (9.3125 iter/s, 10.7383s/100 iters), loss = 0.146066
I1206 11:46:57.832243  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.146065 (* 1 = 0.146065 loss)
I1206 11:46:57.832253  2751 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I1206 11:47:08.569164  2751 solver.cpp:357] Iteration 38900 (9.3135 iter/s, 10.7371s/100 iters), loss = 0.125655
I1206 11:47:08.569226  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.125655 (* 1 = 0.125655 loss)
I1206 11:47:08.569237  2751 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I1206 11:47:19.216862  2751 solver.cpp:514] Iteration 39000, Testing net (#0)
I1206 11:47:22.425246  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:47:22.437352  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.497007 (* 1 = 0.497007 loss)
I1206 11:47:22.437381  2751 solver.cpp:580]     Test net output #1: prob = 0.8427
I1206 11:47:22.437386  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:47:22.542881  2751 solver.cpp:357] Iteration 39000 (7.15508 iter/s, 13.9761s/100 iters), loss = 0.107665
I1206 11:47:22.542923  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.107665 (* 1 = 0.107665 loss)
I1206 11:47:22.542935  2751 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I1206 11:47:28.780544  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:47:33.276221  2751 solver.cpp:357] Iteration 39100 (9.31517 iter/s, 10.7352s/100 iters), loss = 0.1837
I1206 11:47:33.276290  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.183699 (* 1 = 0.183699 loss)
I1206 11:47:33.276300  2751 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I1206 11:47:44.019872  2751 solver.cpp:357] Iteration 39200 (9.30628 iter/s, 10.7454s/100 iters), loss = 0.196448
I1206 11:47:44.019935  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.196447 (* 1 = 0.196447 loss)
I1206 11:47:44.019945  2751 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I1206 11:47:54.761225  2751 solver.cpp:357] Iteration 39300 (9.30829 iter/s, 10.7431s/100 iters), loss = 0.11667
I1206 11:47:54.761291  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.116669 (* 1 = 0.116669 loss)
I1206 11:47:54.761301  2751 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I1206 11:48:05.501885  2751 solver.cpp:357] Iteration 39400 (9.30892 iter/s, 10.7424s/100 iters), loss = 0.10119
I1206 11:48:05.501986  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.10119 (* 1 = 0.10119 loss)
I1206 11:48:05.501997  2751 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I1206 11:48:10.764973  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:48:16.129163  2751 solver.cpp:514] Iteration 39500, Testing net (#0)
I1206 11:48:19.359706  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:48:19.372617  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.533365 (* 1 = 0.533365 loss)
I1206 11:48:19.372644  2751 solver.cpp:580]     Test net output #1: prob = 0.830901
I1206 11:48:19.372650  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:48:19.478772  2751 solver.cpp:357] Iteration 39500 (7.15355 iter/s, 13.9791s/100 iters), loss = 0.0719022
I1206 11:48:19.478816  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0719022 (* 1 = 0.0719022 loss)
I1206 11:48:19.478828  2751 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I1206 11:48:30.215826  2751 solver.cpp:357] Iteration 39600 (9.31208 iter/s, 10.7387s/100 iters), loss = 0.117246
I1206 11:48:30.215889  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.117246 (* 1 = 0.117246 loss)
I1206 11:48:30.215899  2751 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I1206 11:48:40.956336  2751 solver.cpp:357] Iteration 39700 (9.30913 iter/s, 10.7421s/100 iters), loss = 0.16949
I1206 11:48:40.956503  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.16949 (* 1 = 0.16949 loss)
I1206 11:48:40.956513  2751 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I1206 11:48:51.693049  2751 solver.cpp:357] Iteration 39800 (9.31253 iter/s, 10.7382s/100 iters), loss = 0.0931821
I1206 11:48:51.693110  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.093182 (* 1 = 0.093182 loss)
I1206 11:48:51.693122  2751 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I1206 11:48:55.893544  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:49:02.437997  2751 solver.cpp:357] Iteration 39900 (9.30533 iter/s, 10.7465s/100 iters), loss = 0.093466
I1206 11:49:02.438061  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.093466 (* 1 = 0.093466 loss)
I1206 11:49:02.438072  2751 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I1206 11:49:13.074558  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.caffemodel
I1206 11:49:13.082626  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.solverstate
I1206 11:49:13.085443  2751 solver.cpp:514] Iteration 40000, Testing net (#0)
I1206 11:49:16.277583  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:49:16.289739  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.470468 (* 1 = 0.470468 loss)
I1206 11:49:16.289767  2751 solver.cpp:580]     Test net output #1: prob = 0.8516
I1206 11:49:16.289773  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:49:16.394613  2751 solver.cpp:357] Iteration 40000 (7.16401 iter/s, 13.9587s/100 iters), loss = 0.184037
I1206 11:49:16.394656  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.184037 (* 1 = 0.184037 loss)
I1206 11:49:16.394670  2751 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I1206 11:49:27.143656  2751 solver.cpp:357] Iteration 40100 (9.30182 iter/s, 10.7506s/100 iters), loss = 0.175431
I1206 11:49:27.143719  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.175431 (* 1 = 0.175431 loss)
I1206 11:49:27.143728  2751 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I1206 11:49:37.893651  2751 solver.cpp:357] Iteration 40200 (9.30103 iter/s, 10.7515s/100 iters), loss = 0.167579
I1206 11:49:37.893715  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.167579 (* 1 = 0.167579 loss)
I1206 11:49:37.893728  2751 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I1206 11:49:41.118600  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:49:48.634064  2751 solver.cpp:357] Iteration 40300 (9.30935 iter/s, 10.7419s/100 iters), loss = 0.150004
I1206 11:49:48.634210  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.150003 (* 1 = 0.150003 loss)
I1206 11:49:48.634220  2751 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I1206 11:49:59.364940  2751 solver.cpp:357] Iteration 40400 (9.31771 iter/s, 10.7322s/100 iters), loss = 0.19506
I1206 11:49:59.365003  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.19506 (* 1 = 0.19506 loss)
I1206 11:49:59.365012  2751 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I1206 11:50:09.992314  2751 solver.cpp:514] Iteration 40500, Testing net (#0)
I1206 11:50:13.188019  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:50:13.200152  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.453326 (* 1 = 0.453326 loss)
I1206 11:50:13.200181  2751 solver.cpp:580]     Test net output #1: prob = 0.853501
I1206 11:50:13.200187  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:50:13.306901  2751 solver.cpp:357] Iteration 40500 (7.17162 iter/s, 13.9438s/100 iters), loss = 0.157459
I1206 11:50:13.306943  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.157459 (* 1 = 0.157459 loss)
I1206 11:50:13.306957  2751 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I1206 11:50:24.045830  2751 solver.cpp:357] Iteration 40600 (9.31068 iter/s, 10.7404s/100 iters), loss = 0.196456
I1206 11:50:24.046026  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.196456 (* 1 = 0.196456 loss)
I1206 11:50:24.046036  2751 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I1206 11:50:26.204749  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:50:34.787835  2751 solver.cpp:357] Iteration 40700 (9.30817 iter/s, 10.7433s/100 iters), loss = 0.19718
I1206 11:50:34.787899  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.19718 (* 1 = 0.19718 loss)
I1206 11:50:34.787910  2751 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I1206 11:50:45.521370  2751 solver.cpp:357] Iteration 40800 (9.31541 iter/s, 10.7349s/100 iters), loss = 0.119115
I1206 11:50:45.521432  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.119115 (* 1 = 0.119115 loss)
I1206 11:50:45.521442  2751 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I1206 11:50:56.261060  2751 solver.cpp:357] Iteration 40900 (9.31009 iter/s, 10.741s/100 iters), loss = 0.127048
I1206 11:50:56.261168  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.127048 (* 1 = 0.127048 loss)
I1206 11:50:56.261181  2751 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I1206 11:51:06.896443  2751 solver.cpp:514] Iteration 41000, Testing net (#0)
I1206 11:51:10.139535  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:51:10.152026  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.452141 (* 1 = 0.452141 loss)
I1206 11:51:10.152055  2751 solver.cpp:580]     Test net output #1: prob = 0.857801
I1206 11:51:10.152060  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:51:10.258174  2751 solver.cpp:357] Iteration 41000 (7.14346 iter/s, 13.9988s/100 iters), loss = 0.116557
I1206 11:51:10.258217  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.116556 (* 1 = 0.116556 loss)
I1206 11:51:10.258230  2751 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I1206 11:51:11.445518  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:51:20.994700  2751 solver.cpp:357] Iteration 41100 (9.31286 iter/s, 10.7378s/100 iters), loss = 0.0944878
I1206 11:51:20.994763  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0944878 (* 1 = 0.0944878 loss)
I1206 11:51:20.994776  2751 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I1206 11:51:31.732709  2751 solver.cpp:357] Iteration 41200 (9.31161 iter/s, 10.7393s/100 iters), loss = 0.0653019
I1206 11:51:31.732859  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0653019 (* 1 = 0.0653019 loss)
I1206 11:51:31.732869  2751 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I1206 11:51:42.476487  2751 solver.cpp:357] Iteration 41300 (9.3067 iter/s, 10.745s/100 iters), loss = 0.153221
I1206 11:51:42.476549  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.153221 (* 1 = 0.153221 loss)
I1206 11:51:42.476560  2751 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I1206 11:51:53.219630  2751 solver.cpp:357] Iteration 41400 (9.30719 iter/s, 10.7444s/100 iters), loss = 0.0950383
I1206 11:51:53.219694  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0950383 (* 1 = 0.0950383 loss)
I1206 11:51:53.219705  2751 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I1206 11:51:53.441813  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:52:03.849040  2751 solver.cpp:514] Iteration 41500, Testing net (#0)
I1206 11:52:07.064888  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:52:07.077137  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.709975 (* 1 = 0.709975 loss)
I1206 11:52:07.077165  2751 solver.cpp:580]     Test net output #1: prob = 0.792201
I1206 11:52:07.077172  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:52:07.182587  2751 solver.cpp:357] Iteration 41500 (7.16098 iter/s, 13.9646s/100 iters), loss = 0.122933
I1206 11:52:07.182631  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.122933 (* 1 = 0.122933 loss)
I1206 11:52:07.182643  2751 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I1206 11:52:17.921993  2751 solver.cpp:357] Iteration 41600 (9.31045 iter/s, 10.7406s/100 iters), loss = 0.164061
I1206 11:52:17.922057  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.164061 (* 1 = 0.164061 loss)
I1206 11:52:17.922067  2751 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I1206 11:52:28.660583  2751 solver.cpp:357] Iteration 41700 (9.31119 iter/s, 10.7398s/100 iters), loss = 0.160356
I1206 11:52:28.660645  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.160356 (* 1 = 0.160356 loss)
I1206 11:52:28.660656  2751 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I1206 11:52:38.537029  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:52:39.390964  2751 solver.cpp:357] Iteration 41800 (9.31832 iter/s, 10.7315s/100 iters), loss = 0.153143
I1206 11:52:39.391026  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.153143 (* 1 = 0.153143 loss)
I1206 11:52:39.391036  2751 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I1206 11:52:50.129009  2751 solver.cpp:357] Iteration 41900 (9.31169 iter/s, 10.7392s/100 iters), loss = 0.0695989
I1206 11:52:50.129072  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0695989 (* 1 = 0.0695989 loss)
I1206 11:52:50.129082  2751 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I1206 11:53:00.766566  2751 solver.cpp:514] Iteration 42000, Testing net (#0)
I1206 11:53:03.953112  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:53:03.965184  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.712297 (* 1 = 0.712297 loss)
I1206 11:53:03.965214  2751 solver.cpp:580]     Test net output #1: prob = 0.808801
I1206 11:53:03.965219  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:53:04.073710  2751 solver.cpp:357] Iteration 42000 (7.17041 iter/s, 13.9462s/100 iters), loss = 0.0663234
I1206 11:53:04.073753  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0663233 (* 1 = 0.0663233 loss)
I1206 11:53:04.073768  2751 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I1206 11:53:14.814744  2751 solver.cpp:357] Iteration 42100 (9.30911 iter/s, 10.7422s/100 iters), loss = 0.0905136
I1206 11:53:14.814870  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0905136 (* 1 = 0.0905136 loss)
I1206 11:53:14.814880  2751 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I1206 11:53:23.737741  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:53:25.564746  2751 solver.cpp:357] Iteration 42200 (9.30143 iter/s, 10.751s/100 iters), loss = 0.124851
I1206 11:53:25.564810  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.124851 (* 1 = 0.124851 loss)
I1206 11:53:25.564819  2751 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I1206 11:53:36.307279  2751 solver.cpp:357] Iteration 42300 (9.30786 iter/s, 10.7436s/100 iters), loss = 0.0409682
I1206 11:53:36.307345  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0409681 (* 1 = 0.0409681 loss)
I1206 11:53:36.307355  2751 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I1206 11:53:47.033432  2751 solver.cpp:357] Iteration 42400 (9.32208 iter/s, 10.7272s/100 iters), loss = 0.156601
I1206 11:53:47.033532  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.156601 (* 1 = 0.156601 loss)
I1206 11:53:47.033542  2751 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I1206 11:53:57.661108  2751 solver.cpp:514] Iteration 42500, Testing net (#0)
I1206 11:54:00.863521  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:54:00.875634  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.594758 (* 1 = 0.594758 loss)
I1206 11:54:00.875663  2751 solver.cpp:580]     Test net output #1: prob = 0.828501
I1206 11:54:00.875669  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:54:00.981765  2751 solver.cpp:357] Iteration 42500 (7.16862 iter/s, 13.9497s/100 iters), loss = 0.0791291
I1206 11:54:00.981808  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.079129 (* 1 = 0.079129 loss)
I1206 11:54:00.981818  2751 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I1206 11:54:08.930333  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:54:11.720438  2751 solver.cpp:357] Iteration 42600 (9.31123 iter/s, 10.7397s/100 iters), loss = 0.130843
I1206 11:54:11.720499  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.130843 (* 1 = 0.130843 loss)
I1206 11:54:11.720508  2751 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I1206 11:54:22.450762  2751 solver.cpp:357] Iteration 42700 (9.3185 iter/s, 10.7313s/100 iters), loss = 0.147122
I1206 11:54:22.450959  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.147122 (* 1 = 0.147122 loss)
I1206 11:54:22.451002  2751 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I1206 11:54:33.188505  2751 solver.cpp:357] Iteration 42800 (9.31219 iter/s, 10.7386s/100 iters), loss = 0.181306
I1206 11:54:33.188566  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.181306 (* 1 = 0.181306 loss)
I1206 11:54:33.188578  2751 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I1206 11:54:43.936555  2751 solver.cpp:357] Iteration 42900 (9.30315 iter/s, 10.749s/100 iters), loss = 0.0742568
I1206 11:54:43.936619  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0742567 (* 1 = 0.0742567 loss)
I1206 11:54:43.936630  2751 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I1206 11:54:50.815794  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:54:54.571537  2751 solver.cpp:514] Iteration 43000, Testing net (#0)
I1206 11:54:57.765720  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:54:57.777825  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.790584 (* 1 = 0.790584 loss)
I1206 11:54:57.777853  2751 solver.cpp:580]     Test net output #1: prob = 0.7761
I1206 11:54:57.777858  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:54:57.883496  2751 solver.cpp:357] Iteration 43000 (7.16936 iter/s, 13.9482s/100 iters), loss = 0.137062
I1206 11:54:57.883539  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.137062 (* 1 = 0.137062 loss)
I1206 11:54:57.883549  2751 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I1206 11:55:08.628165  2751 solver.cpp:357] Iteration 43100 (9.30609 iter/s, 10.7457s/100 iters), loss = 0.130353
I1206 11:55:08.628235  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.130352 (* 1 = 0.130352 loss)
I1206 11:55:08.628244  2751 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I1206 11:55:19.382836  2751 solver.cpp:357] Iteration 43200 (9.29746 iter/s, 10.7556s/100 iters), loss = 0.117618
I1206 11:55:19.382900  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.117618 (* 1 = 0.117618 loss)
I1206 11:55:19.382911  2751 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I1206 11:55:30.122776  2751 solver.cpp:357] Iteration 43300 (9.31023 iter/s, 10.7409s/100 iters), loss = 0.0941518
I1206 11:55:30.122923  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0941517 (* 1 = 0.0941517 loss)
I1206 11:55:30.122932  2751 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I1206 11:55:36.027992  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:55:40.857147  2751 solver.cpp:357] Iteration 43400 (9.31514 iter/s, 10.7352s/100 iters), loss = 0.159042
I1206 11:55:40.857211  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.159042 (* 1 = 0.159042 loss)
I1206 11:55:40.857220  2751 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I1206 11:55:51.488368  2751 solver.cpp:514] Iteration 43500, Testing net (#0)
I1206 11:55:54.744837  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:55:54.756669  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.424764 (* 1 = 0.424764 loss)
I1206 11:55:54.756696  2751 solver.cpp:580]     Test net output #1: prob = 0.871701
I1206 11:55:54.756703  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:55:54.862937  2751 solver.cpp:357] Iteration 43500 (7.13928 iter/s, 14.007s/100 iters), loss = 0.110844
I1206 11:55:54.862980  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.110844 (* 1 = 0.110844 loss)
I1206 11:55:54.862992  2751 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I1206 11:56:05.609442  2751 solver.cpp:357] Iteration 43600 (9.30455 iter/s, 10.7474s/100 iters), loss = 0.108902
I1206 11:56:05.609601  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.108902 (* 1 = 0.108902 loss)
I1206 11:56:05.609611  2751 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I1206 11:56:16.354590  2751 solver.cpp:357] Iteration 43700 (9.30584 iter/s, 10.7459s/100 iters), loss = 0.0761356
I1206 11:56:16.354652  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0761355 (* 1 = 0.0761355 loss)
I1206 11:56:16.354661  2751 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I1206 11:56:21.212456  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:56:27.109587  2751 solver.cpp:357] Iteration 43800 (9.29724 iter/s, 10.7559s/100 iters), loss = 0.0765714
I1206 11:56:27.109652  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0765713 (* 1 = 0.0765713 loss)
I1206 11:56:27.109661  2751 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I1206 11:56:37.859092  2751 solver.cpp:357] Iteration 43900 (9.302 iter/s, 10.7504s/100 iters), loss = 0.132776
I1206 11:56:37.859241  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.132776 (* 1 = 0.132776 loss)
I1206 11:56:37.859251  2751 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I1206 11:56:48.493654  2751 solver.cpp:514] Iteration 44000, Testing net (#0)
I1206 11:56:51.704677  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:56:51.716780  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.559212 (* 1 = 0.559212 loss)
I1206 11:56:51.716809  2751 solver.cpp:580]     Test net output #1: prob = 0.830501
I1206 11:56:51.716814  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:56:51.823062  2751 solver.cpp:357] Iteration 44000 (7.16074 iter/s, 13.965s/100 iters), loss = 0.136207
I1206 11:56:51.823104  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.136206 (* 1 = 0.136206 loss)
I1206 11:56:51.823115  2751 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I1206 11:57:02.549383  2751 solver.cpp:357] Iteration 44100 (9.32211 iter/s, 10.7272s/100 iters), loss = 0.0780644
I1206 11:57:02.549448  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0780642 (* 1 = 0.0780642 loss)
I1206 11:57:02.549458  2751 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I1206 11:57:06.416342  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:57:13.284989  2751 solver.cpp:357] Iteration 44200 (9.31407 iter/s, 10.7364s/100 iters), loss = 0.119277
I1206 11:57:13.285137  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.119277 (* 1 = 0.119277 loss)
I1206 11:57:13.285151  2751 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I1206 11:57:24.038424  2751 solver.cpp:357] Iteration 44300 (9.29871 iter/s, 10.7542s/100 iters), loss = 0.127003
I1206 11:57:24.038488  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.127002 (* 1 = 0.127002 loss)
I1206 11:57:24.038497  2751 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I1206 11:57:34.773171  2751 solver.cpp:357] Iteration 44400 (9.31484 iter/s, 10.7356s/100 iters), loss = 0.172434
I1206 11:57:34.773234  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.172434 (* 1 = 0.172434 loss)
I1206 11:57:34.773243  2751 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I1206 11:57:45.423207  2751 solver.cpp:514] Iteration 44500, Testing net (#0)
I1206 11:57:48.655112  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:57:48.667536  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.465566 (* 1 = 0.465566 loss)
I1206 11:57:48.667564  2751 solver.cpp:580]     Test net output #1: prob = 0.855402
I1206 11:57:48.667572  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:57:48.773182  2751 solver.cpp:357] Iteration 44500 (7.1423 iter/s, 14.0011s/100 iters), loss = 0.0960844
I1206 11:57:48.773226  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0960842 (* 1 = 0.0960842 loss)
I1206 11:57:48.773239  2751 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I1206 11:57:51.669474  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:57:59.511134  2751 solver.cpp:357] Iteration 44600 (9.31206 iter/s, 10.7388s/100 iters), loss = 0.119854
I1206 11:57:59.511199  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.119854 (* 1 = 0.119854 loss)
I1206 11:57:59.511210  2751 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I1206 11:58:10.253504  2751 solver.cpp:357] Iteration 44700 (9.30825 iter/s, 10.7432s/100 iters), loss = 0.137389
I1206 11:58:10.253568  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.137389 (* 1 = 0.137389 loss)
I1206 11:58:10.253579  2751 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I1206 11:58:20.991505  2751 solver.cpp:357] Iteration 44800 (9.31205 iter/s, 10.7388s/100 iters), loss = 0.12098
I1206 11:58:20.991709  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.12098 (* 1 = 0.12098 loss)
I1206 11:58:20.991719  2751 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I1206 11:58:31.723448  2751 solver.cpp:357] Iteration 44900 (9.31743 iter/s, 10.7326s/100 iters), loss = 0.110891
I1206 11:58:31.723511  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.110891 (* 1 = 0.110891 loss)
I1206 11:58:31.723521  2751 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I1206 11:58:33.554054  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:58:42.367292  2751 solver.cpp:514] Iteration 45000, Testing net (#0)
I1206 11:58:45.612102  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:58:45.624682  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.661898 (* 1 = 0.661898 loss)
I1206 11:58:45.624709  2751 solver.cpp:580]     Test net output #1: prob = 0.812601
I1206 11:58:45.624716  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:58:45.730361  2751 solver.cpp:357] Iteration 45000 (7.13881 iter/s, 14.0079s/100 iters), loss = 0.0967506
I1206 11:58:45.730404  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0967504 (* 1 = 0.0967504 loss)
I1206 11:58:45.730414  2751 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I1206 11:58:56.481359  2751 solver.cpp:357] Iteration 45100 (9.3008 iter/s, 10.7518s/100 iters), loss = 0.0844831
I1206 11:58:56.481465  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0844829 (* 1 = 0.0844829 loss)
I1206 11:58:56.481477  2751 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I1206 11:59:07.235653  2751 solver.cpp:357] Iteration 45200 (9.29801 iter/s, 10.755s/100 iters), loss = 0.17072
I1206 11:59:07.235718  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.17072 (* 1 = 0.17072 loss)
I1206 11:59:07.235728  2751 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I1206 11:59:17.984277  2751 solver.cpp:357] Iteration 45300 (9.30288 iter/s, 10.7494s/100 iters), loss = 0.133815
I1206 11:59:17.984342  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.133814 (* 1 = 0.133814 loss)
I1206 11:59:17.984351  2751 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I1206 11:59:18.841259  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:59:28.716639  2751 solver.cpp:357] Iteration 45400 (9.31698 iter/s, 10.7331s/100 iters), loss = 0.134374
I1206 11:59:28.716785  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.134373 (* 1 = 0.134373 loss)
I1206 11:59:28.716795  2751 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I1206 11:59:39.350930  2751 solver.cpp:514] Iteration 45500, Testing net (#0)
I1206 11:59:42.577191  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 11:59:42.589376  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.558949 (* 1 = 0.558949 loss)
I1206 11:59:42.589404  2751 solver.cpp:580]     Test net output #1: prob = 0.836301
I1206 11:59:42.589411  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 11:59:42.695161  2751 solver.cpp:357] Iteration 45500 (7.15338 iter/s, 13.9794s/100 iters), loss = 0.0749832
I1206 11:59:42.695204  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.074983 (* 1 = 0.074983 loss)
I1206 11:59:42.695214  2751 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I1206 11:59:53.437934  2751 solver.cpp:357] Iteration 45600 (9.30795 iter/s, 10.7435s/100 iters), loss = 0.151303
I1206 11:59:53.438000  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.151302 (* 1 = 0.151302 loss)
I1206 11:59:53.438009  2751 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I1206 12:00:04.080879  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:00:04.183418  2751 solver.cpp:357] Iteration 45700 (9.30562 iter/s, 10.7462s/100 iters), loss = 0.0739504
I1206 12:00:04.183470  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0739502 (* 1 = 0.0739502 loss)
I1206 12:00:04.183480  2751 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I1206 12:00:14.933496  2751 solver.cpp:357] Iteration 45800 (9.30165 iter/s, 10.7508s/100 iters), loss = 0.115073
I1206 12:00:14.933557  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.115073 (* 1 = 0.115073 loss)
I1206 12:00:14.933568  2751 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I1206 12:00:25.665269  2751 solver.cpp:357] Iteration 45900 (9.31753 iter/s, 10.7325s/100 iters), loss = 0.12761
I1206 12:00:25.665333  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.12761 (* 1 = 0.12761 loss)
I1206 12:00:25.665343  2751 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I1206 12:00:36.303369  2751 solver.cpp:514] Iteration 46000, Testing net (#0)
I1206 12:00:39.508561  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:00:39.520823  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.452195 (* 1 = 0.452195 loss)
I1206 12:00:39.520850  2751 solver.cpp:580]     Test net output #1: prob = 0.855801
I1206 12:00:39.520857  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 12:00:39.626961  2751 solver.cpp:357] Iteration 46000 (7.16199 iter/s, 13.9626s/100 iters), loss = 0.11768
I1206 12:00:39.627004  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.11768 (* 1 = 0.11768 loss)
I1206 12:00:39.627017  2751 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I1206 12:00:49.204979  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:00:50.369560  2751 solver.cpp:357] Iteration 46100 (9.30814 iter/s, 10.7433s/100 iters), loss = 0.158713
I1206 12:00:50.369621  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.158713 (* 1 = 0.158713 loss)
I1206 12:00:50.369633  2751 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I1206 12:01:01.113368  2751 solver.cpp:357] Iteration 46200 (9.30711 iter/s, 10.7445s/100 iters), loss = 0.184207
I1206 12:01:01.113428  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.184207 (* 1 = 0.184207 loss)
I1206 12:01:01.113437  2751 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I1206 12:01:11.859828  2751 solver.cpp:357] Iteration 46300 (9.30481 iter/s, 10.7471s/100 iters), loss = 0.155464
I1206 12:01:11.859966  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.155464 (* 1 = 0.155464 loss)
I1206 12:01:11.859977  2751 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I1206 12:01:22.607194  2751 solver.cpp:357] Iteration 46400 (9.3041 iter/s, 10.7479s/100 iters), loss = 0.167761
I1206 12:01:22.607259  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.167761 (* 1 = 0.167761 loss)
I1206 12:01:22.607270  2751 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I1206 12:01:31.221984  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:01:33.265838  2751 solver.cpp:514] Iteration 46500, Testing net (#0)
I1206 12:01:36.446382  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:01:36.459547  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.630444 (* 1 = 0.630444 loss)
I1206 12:01:36.459573  2751 solver.cpp:580]     Test net output #1: prob = 0.828101
I1206 12:01:36.459579  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 12:01:36.569192  2751 solver.cpp:357] Iteration 46500 (7.16185 iter/s, 13.9629s/100 iters), loss = 0.109094
I1206 12:01:36.569236  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.109094 (* 1 = 0.109094 loss)
I1206 12:01:36.569249  2751 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I1206 12:01:47.313339  2751 solver.cpp:357] Iteration 46600 (9.30682 iter/s, 10.7448s/100 iters), loss = 0.167374
I1206 12:01:47.313544  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.167374 (* 1 = 0.167374 loss)
I1206 12:01:47.313555  2751 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I1206 12:01:58.074159  2751 solver.cpp:357] Iteration 46700 (9.29254 iter/s, 10.7613s/100 iters), loss = 0.1352
I1206 12:01:58.074223  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.135199 (* 1 = 0.135199 loss)
I1206 12:01:58.074232  2751 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I1206 12:02:08.816298  2751 solver.cpp:357] Iteration 46800 (9.30859 iter/s, 10.7428s/100 iters), loss = 0.0449013
I1206 12:02:08.816362  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0449011 (* 1 = 0.0449011 loss)
I1206 12:02:08.816373  2751 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I1206 12:02:16.358240  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:02:19.557960  2751 solver.cpp:357] Iteration 46900 (9.30901 iter/s, 10.7423s/100 iters), loss = 0.129585
I1206 12:02:19.558109  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.129585 (* 1 = 0.129585 loss)
I1206 12:02:19.558117  2751 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I1206 12:02:30.199481  2751 solver.cpp:514] Iteration 47000, Testing net (#0)
I1206 12:02:33.412994  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:02:33.424823  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.503054 (* 1 = 0.503054 loss)
I1206 12:02:33.424849  2751 solver.cpp:580]     Test net output #1: prob = 0.862202
I1206 12:02:33.424855  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 12:02:33.530139  2751 solver.cpp:357] Iteration 47000 (7.15669 iter/s, 13.9729s/100 iters), loss = 0.0997959
I1206 12:02:33.530182  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0997956 (* 1 = 0.0997956 loss)
I1206 12:02:33.530194  2751 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I1206 12:02:44.275166  2751 solver.cpp:357] Iteration 47100 (9.30608 iter/s, 10.7457s/100 iters), loss = 0.137779
I1206 12:02:44.275229  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.137779 (* 1 = 0.137779 loss)
I1206 12:02:44.275241  2751 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I1206 12:02:55.031900  2751 solver.cpp:357] Iteration 47200 (9.29598 iter/s, 10.7573s/100 iters), loss = 0.0968694
I1206 12:02:55.032045  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0968692 (* 1 = 0.0968692 loss)
I1206 12:02:55.032055  2751 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I1206 12:03:01.591208  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:03:05.785387  2751 solver.cpp:357] Iteration 47300 (9.29886 iter/s, 10.754s/100 iters), loss = 0.075723
I1206 12:03:05.785452  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0757228 (* 1 = 0.0757228 loss)
I1206 12:03:05.785462  2751 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I1206 12:03:16.529413  2751 solver.cpp:357] Iteration 47400 (9.30698 iter/s, 10.7446s/100 iters), loss = 0.121503
I1206 12:03:16.529479  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.121502 (* 1 = 0.121502 loss)
I1206 12:03:16.529490  2751 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I1206 12:03:27.177809  2751 solver.cpp:514] Iteration 47500, Testing net (#0)
I1206 12:03:30.365849  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:03:30.378304  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.419412 (* 1 = 0.419412 loss)
I1206 12:03:30.378330  2751 solver.cpp:580]     Test net output #1: prob = 0.876502
I1206 12:03:30.378337  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 12:03:30.483911  2751 solver.cpp:357] Iteration 47500 (7.16574 iter/s, 13.9553s/100 iters), loss = 0.104273
I1206 12:03:30.483952  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.104273 (* 1 = 0.104273 loss)
I1206 12:03:30.483963  2751 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I1206 12:03:41.231854  2751 solver.cpp:357] Iteration 47600 (9.30358 iter/s, 10.7486s/100 iters), loss = 0.118595
I1206 12:03:41.231920  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.118594 (* 1 = 0.118594 loss)
I1206 12:03:41.231931  2751 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I1206 12:03:46.815975  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:03:51.965242  2751 solver.cpp:357] Iteration 47700 (9.31622 iter/s, 10.734s/100 iters), loss = 0.0793931
I1206 12:03:51.965307  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0793929 (* 1 = 0.0793929 loss)
I1206 12:03:51.965317  2751 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I1206 12:04:02.710189  2751 solver.cpp:357] Iteration 47800 (9.3062 iter/s, 10.7455s/100 iters), loss = 0.133039
I1206 12:04:02.710369  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.133038 (* 1 = 0.133038 loss)
I1206 12:04:02.710379  2751 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I1206 12:04:13.458009  2751 solver.cpp:357] Iteration 47900 (9.30382 iter/s, 10.7483s/100 iters), loss = 0.140833
I1206 12:04:13.458073  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.140833 (* 1 = 0.140833 loss)
I1206 12:04:13.458082  2751 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I1206 12:04:24.099267  2751 solver.cpp:514] Iteration 48000, Testing net (#0)
I1206 12:04:27.312163  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:04:27.324205  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.430149 (* 1 = 0.430149 loss)
I1206 12:04:27.324247  2751 solver.cpp:580]     Test net output #1: prob = 0.868602
I1206 12:04:27.324255  2751 solver.cpp:593]     Max_acc: 0.877002  with iter: 32500
I1206 12:04:27.430456  2751 solver.cpp:357] Iteration 48000 (7.15655 iter/s, 13.9732s/100 iters), loss = 0.125966
I1206 12:04:27.430498  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.125966 (* 1 = 0.125966 loss)
I1206 12:04:27.430506  2751 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I1206 12:04:27.430512  2751 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I1206 12:04:31.948617  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:04:38.167062  2751 solver.cpp:357] Iteration 48100 (9.31343 iter/s, 10.7372s/100 iters), loss = 0.094691
I1206 12:04:38.167208  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0946908 (* 1 = 0.0946908 loss)
I1206 12:04:38.167218  2751 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I1206 12:04:48.906280  2751 solver.cpp:357] Iteration 48200 (9.31125 iter/s, 10.7397s/100 iters), loss = 0.0717097
I1206 12:04:48.906343  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0717095 (* 1 = 0.0717095 loss)
I1206 12:04:48.906355  2751 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I1206 12:04:59.641067  2751 solver.cpp:357] Iteration 48300 (9.31503 iter/s, 10.7353s/100 iters), loss = 0.0563034
I1206 12:04:59.641132  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0563032 (* 1 = 0.0563032 loss)
I1206 12:04:59.641144  2751 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I1206 12:05:10.378573  2751 solver.cpp:357] Iteration 48400 (9.31267 iter/s, 10.7381s/100 iters), loss = 0.0739305
I1206 12:05:10.378736  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0739303 (* 1 = 0.0739303 loss)
I1206 12:05:10.378746  2751 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I1206 12:05:13.931650  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:05:21.015453  2751 solver.cpp:514] Iteration 48500, Testing net (#0)
I1206 12:05:24.256889  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:05:24.268960  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.296966 (* 1 = 0.296966 loss)
I1206 12:05:24.268987  2751 solver.cpp:580]     Test net output #1: prob = 0.906303
I1206 12:05:24.269001  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_48500.caffemodel
I1206 12:05:24.276921  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_48500.solverstate
I1206 12:05:24.279320  2751 solver.cpp:593]     Max_acc: 0.906303  with iter: 48500
I1206 12:05:24.385679  2751 solver.cpp:357] Iteration 48500 (7.13891 iter/s, 14.0078s/100 iters), loss = 0.0868264
I1206 12:05:24.385725  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0868262 (* 1 = 0.0868262 loss)
I1206 12:05:24.385738  2751 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I1206 12:05:35.130167  2751 solver.cpp:357] Iteration 48600 (9.30661 iter/s, 10.745s/100 iters), loss = 0.0554478
I1206 12:05:35.130230  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0554476 (* 1 = 0.0554476 loss)
I1206 12:05:35.130242  2751 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I1206 12:05:45.868502  2751 solver.cpp:357] Iteration 48700 (9.31196 iter/s, 10.7389s/100 iters), loss = 0.0494061
I1206 12:05:45.868705  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0494059 (* 1 = 0.0494059 loss)
I1206 12:05:45.868715  2751 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I1206 12:05:56.605404  2751 solver.cpp:357] Iteration 48800 (9.31333 iter/s, 10.7373s/100 iters), loss = 0.0841914
I1206 12:05:56.605468  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0841912 (* 1 = 0.0841912 loss)
I1206 12:05:56.605478  2751 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I1206 12:05:59.188444  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:06:07.345923  2751 solver.cpp:357] Iteration 48900 (9.31008 iter/s, 10.7411s/100 iters), loss = 0.0926454
I1206 12:06:07.345989  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0926452 (* 1 = 0.0926452 loss)
I1206 12:06:07.345999  2751 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I1206 12:06:17.976924  2751 solver.cpp:514] Iteration 49000, Testing net (#0)
I1206 12:06:21.157835  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:06:21.170382  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.273246 (* 1 = 0.273246 loss)
I1206 12:06:21.170408  2751 solver.cpp:580]     Test net output #1: prob = 0.915502
I1206 12:06:21.170421  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_49000.caffemodel
I1206 12:06:21.178315  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_49000.solverstate
I1206 12:06:21.180718  2751 solver.cpp:593]     Max_acc: 0.915502  with iter: 49000
I1206 12:06:21.286836  2751 solver.cpp:357] Iteration 49000 (7.17276 iter/s, 13.9416s/100 iters), loss = 0.116138
I1206 12:06:21.286880  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.116138 (* 1 = 0.116138 loss)
I1206 12:06:21.286892  2751 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I1206 12:06:32.023412  2751 solver.cpp:357] Iteration 49100 (9.31348 iter/s, 10.7371s/100 iters), loss = 0.110535
I1206 12:06:32.023476  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.110534 (* 1 = 0.110534 loss)
I1206 12:06:32.023485  2751 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I1206 12:06:42.775326  2751 solver.cpp:357] Iteration 49200 (9.30022 iter/s, 10.7524s/100 iters), loss = 0.0541241
I1206 12:06:42.775391  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0541239 (* 1 = 0.0541239 loss)
I1206 12:06:42.775400  2751 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I1206 12:06:44.288328  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:06:53.526041  2751 solver.cpp:357] Iteration 49300 (9.30126 iter/s, 10.7512s/100 iters), loss = 0.0794395
I1206 12:06:53.526242  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0794393 (* 1 = 0.0794393 loss)
I1206 12:06:53.526252  2751 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I1206 12:07:04.263609  2751 solver.cpp:357] Iteration 49400 (9.31277 iter/s, 10.7379s/100 iters), loss = 0.0815761
I1206 12:07:04.263675  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0815759 (* 1 = 0.0815759 loss)
I1206 12:07:04.263685  2751 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I1206 12:07:14.906210  2751 solver.cpp:514] Iteration 49500, Testing net (#0)
I1206 12:07:18.110502  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:07:18.122634  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.26886 (* 1 = 0.26886 loss)
I1206 12:07:18.122661  2751 solver.cpp:580]     Test net output #1: prob = 0.918002
I1206 12:07:18.122674  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_49500.caffemodel
I1206 12:07:18.130573  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_49500.solverstate
I1206 12:07:18.192005  2751 solver.cpp:593]     Max_acc: 0.918002  with iter: 49500
I1206 12:07:18.297662  2751 solver.cpp:357] Iteration 49500 (7.12517 iter/s, 14.0347s/100 iters), loss = 0.0824721
I1206 12:07:18.297706  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0824719 (* 1 = 0.0824719 loss)
I1206 12:07:18.297719  2751 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I1206 12:07:29.050289  2751 solver.cpp:357] Iteration 49600 (9.2996 iter/s, 10.7532s/100 iters), loss = 0.0478109
I1206 12:07:29.050439  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0478107 (* 1 = 0.0478107 loss)
I1206 12:07:29.050449  2751 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I1206 12:07:29.592998  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:07:39.788936  2751 solver.cpp:357] Iteration 49700 (9.3118 iter/s, 10.7391s/100 iters), loss = 0.0736672
I1206 12:07:39.789002  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.073667 (* 1 = 0.073667 loss)
I1206 12:07:39.789013  2751 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I1206 12:07:50.530467  2751 solver.cpp:357] Iteration 49800 (9.30923 iter/s, 10.742s/100 iters), loss = 0.0589259
I1206 12:07:50.530529  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0589257 (* 1 = 0.0589257 loss)
I1206 12:07:50.530539  2751 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I1206 12:08:01.283599  2751 solver.cpp:357] Iteration 49900 (9.29918 iter/s, 10.7536s/100 iters), loss = 0.0297632
I1206 12:08:01.283684  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.029763 (* 1 = 0.029763 loss)
I1206 12:08:01.283694  2751 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I1206 12:08:11.503583  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:08:11.922502  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.caffemodel
I1206 12:08:11.930505  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.solverstate
I1206 12:08:11.933310  2751 solver.cpp:514] Iteration 50000, Testing net (#0)
I1206 12:08:15.160238  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:08:15.172389  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.259306 (* 1 = 0.259306 loss)
I1206 12:08:15.172415  2751 solver.cpp:580]     Test net output #1: prob = 0.921303
I1206 12:08:15.172433  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.caffemodel
I1206 12:08:15.177423  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.solverstate
I1206 12:08:15.179883  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:08:15.286257  2751 solver.cpp:357] Iteration 50000 (7.14117 iter/s, 14.0033s/100 iters), loss = 0.0360489
I1206 12:08:15.286303  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0360487 (* 1 = 0.0360487 loss)
I1206 12:08:15.286316  2751 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I1206 12:08:26.030751  2751 solver.cpp:357] Iteration 50100 (9.30665 iter/s, 10.745s/100 iters), loss = 0.0368051
I1206 12:08:26.030814  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0368049 (* 1 = 0.0368049 loss)
I1206 12:08:26.030824  2751 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I1206 12:08:36.775787  2751 solver.cpp:357] Iteration 50200 (9.3062 iter/s, 10.7455s/100 iters), loss = 0.0413832
I1206 12:08:36.776090  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.041383 (* 1 = 0.041383 loss)
I1206 12:08:36.776100  2751 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I1206 12:08:47.514384  2751 solver.cpp:357] Iteration 50300 (9.31199 iter/s, 10.7388s/100 iters), loss = 0.03692
I1206 12:08:47.514449  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0369198 (* 1 = 0.0369198 loss)
I1206 12:08:47.514461  2751 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I1206 12:08:56.762236  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:08:58.257639  2751 solver.cpp:357] Iteration 50400 (9.30774 iter/s, 10.7437s/100 iters), loss = 0.0639975
I1206 12:08:58.257704  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0639973 (* 1 = 0.0639973 loss)
I1206 12:08:58.257714  2751 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I1206 12:09:08.885078  2751 solver.cpp:514] Iteration 50500, Testing net (#0)
I1206 12:09:12.101213  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:09:12.113277  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.264858 (* 1 = 0.264858 loss)
I1206 12:09:12.113306  2751 solver.cpp:580]     Test net output #1: prob = 0.921102
I1206 12:09:12.113312  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:09:12.218897  2751 solver.cpp:357] Iteration 50500 (7.16234 iter/s, 13.9619s/100 iters), loss = 0.042073
I1206 12:09:12.218940  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0420728 (* 1 = 0.0420728 loss)
I1206 12:09:12.218950  2751 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I1206 12:09:22.972339  2751 solver.cpp:357] Iteration 50600 (9.29891 iter/s, 10.7539s/100 iters), loss = 0.0241487
I1206 12:09:22.972401  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0241485 (* 1 = 0.0241485 loss)
I1206 12:09:22.972411  2751 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I1206 12:09:33.714490  2751 solver.cpp:357] Iteration 50700 (9.30871 iter/s, 10.7426s/100 iters), loss = 0.0297891
I1206 12:09:33.714555  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0297889 (* 1 = 0.0297889 loss)
I1206 12:09:33.714565  2751 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I1206 12:09:42.008837  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:09:44.472033  2751 solver.cpp:357] Iteration 50800 (9.29539 iter/s, 10.758s/100 iters), loss = 0.0637641
I1206 12:09:44.472097  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0637638 (* 1 = 0.0637638 loss)
I1206 12:09:44.472106  2751 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I1206 12:09:55.219450  2751 solver.cpp:357] Iteration 50900 (9.30415 iter/s, 10.7479s/100 iters), loss = 0.0534536
I1206 12:09:55.219513  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0534534 (* 1 = 0.0534534 loss)
I1206 12:09:55.219523  2751 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I1206 12:10:05.855459  2751 solver.cpp:514] Iteration 51000, Testing net (#0)
I1206 12:10:09.109148  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:10:09.120713  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.267402 (* 1 = 0.267402 loss)
I1206 12:10:09.120740  2751 solver.cpp:580]     Test net output #1: prob = 0.920503
I1206 12:10:09.120748  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:10:09.226675  2751 solver.cpp:357] Iteration 51000 (7.13884 iter/s, 14.0079s/100 iters), loss = 0.038748
I1206 12:10:09.226716  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0387478 (* 1 = 0.0387478 loss)
I1206 12:10:09.226727  2751 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I1206 12:10:19.965559  2751 solver.cpp:357] Iteration 51100 (9.31153 iter/s, 10.7394s/100 iters), loss = 0.0290494
I1206 12:10:19.965761  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0290492 (* 1 = 0.0290492 loss)
I1206 12:10:19.965771  2751 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I1206 12:10:27.181237  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:10:30.729630  2751 solver.cpp:357] Iteration 51200 (9.28988 iter/s, 10.7644s/100 iters), loss = 0.0748822
I1206 12:10:30.729696  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.074882 (* 1 = 0.074882 loss)
I1206 12:10:30.729704  2751 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I1206 12:10:41.474202  2751 solver.cpp:357] Iteration 51300 (9.30662 iter/s, 10.745s/100 iters), loss = 0.0458888
I1206 12:10:41.474267  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0458886 (* 1 = 0.0458886 loss)
I1206 12:10:41.474277  2751 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I1206 12:10:52.197382  2751 solver.cpp:357] Iteration 51400 (9.32519 iter/s, 10.7236s/100 iters), loss = 0.0472362
I1206 12:10:52.197531  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.047236 (* 1 = 0.047236 loss)
I1206 12:10:52.197540  2751 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I1206 12:11:02.847012  2751 solver.cpp:514] Iteration 51500, Testing net (#0)
I1206 12:11:06.046977  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:11:06.059119  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.261038 (* 1 = 0.261038 loss)
I1206 12:11:06.059146  2751 solver.cpp:580]     Test net output #1: prob = 0.920802
I1206 12:11:06.059154  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:11:06.165171  2751 solver.cpp:357] Iteration 51500 (7.15905 iter/s, 13.9683s/100 iters), loss = 0.0367186
I1206 12:11:06.165216  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0367184 (* 1 = 0.0367184 loss)
I1206 12:11:06.165227  2751 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I1206 12:11:12.406201  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:11:16.908407  2751 solver.cpp:357] Iteration 51600 (9.30777 iter/s, 10.7437s/100 iters), loss = 0.0425615
I1206 12:11:16.908474  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0425613 (* 1 = 0.0425613 loss)
I1206 12:11:16.908483  2751 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I1206 12:11:27.658663  2751 solver.cpp:357] Iteration 51700 (9.30171 iter/s, 10.7507s/100 iters), loss = 0.0570075
I1206 12:11:27.658805  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0570073 (* 1 = 0.0570073 loss)
I1206 12:11:27.658815  2751 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I1206 12:11:38.405107  2751 solver.cpp:357] Iteration 51800 (9.30508 iter/s, 10.7468s/100 iters), loss = 0.0336486
I1206 12:11:38.405169  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0336484 (* 1 = 0.0336484 loss)
I1206 12:11:38.405179  2751 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I1206 12:11:49.140413  2751 solver.cpp:357] Iteration 51900 (9.31466 iter/s, 10.7358s/100 iters), loss = 0.0327338
I1206 12:11:49.140476  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0327336 (* 1 = 0.0327336 loss)
I1206 12:11:49.140486  2751 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I1206 12:11:54.401043  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:11:59.774127  2751 solver.cpp:514] Iteration 52000, Testing net (#0)
I1206 12:12:03.011234  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:12:03.023352  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.265642 (* 1 = 0.265642 loss)
I1206 12:12:03.023380  2751 solver.cpp:580]     Test net output #1: prob = 0.920502
I1206 12:12:03.023386  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:12:03.130007  2751 solver.cpp:357] Iteration 52000 (7.14785 iter/s, 13.9902s/100 iters), loss = 0.0279443
I1206 12:12:03.130050  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0279441 (* 1 = 0.0279441 loss)
I1206 12:12:03.130065  2751 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I1206 12:12:13.879530  2751 solver.cpp:357] Iteration 52100 (9.30233 iter/s, 10.75s/100 iters), loss = 0.0211747
I1206 12:12:13.879593  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0211745 (* 1 = 0.0211745 loss)
I1206 12:12:13.879602  2751 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I1206 12:12:24.619648  2751 solver.cpp:357] Iteration 52200 (9.31049 iter/s, 10.7406s/100 iters), loss = 0.0369673
I1206 12:12:24.619712  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0369671 (* 1 = 0.0369671 loss)
I1206 12:12:24.619722  2751 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I1206 12:12:35.361408  2751 solver.cpp:357] Iteration 52300 (9.30908 iter/s, 10.7422s/100 iters), loss = 0.0348232
I1206 12:12:35.361608  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.034823 (* 1 = 0.034823 loss)
I1206 12:12:35.361618  2751 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I1206 12:12:39.559198  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:12:46.107142  2751 solver.cpp:357] Iteration 52400 (9.30575 iter/s, 10.746s/100 iters), loss = 0.0420135
I1206 12:12:46.107208  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0420133 (* 1 = 0.0420133 loss)
I1206 12:12:46.107218  2751 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I1206 12:12:56.749063  2751 solver.cpp:514] Iteration 52500, Testing net (#0)
I1206 12:12:59.949036  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:12:59.961119  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.271541 (* 1 = 0.271541 loss)
I1206 12:12:59.961148  2751 solver.cpp:580]     Test net output #1: prob = 0.921103
I1206 12:12:59.961154  2751 solver.cpp:593]     Max_acc: 0.921303  with iter: 50000
I1206 12:13:00.067098  2751 solver.cpp:357] Iteration 52500 (7.16304 iter/s, 13.9606s/100 iters), loss = 0.0687642
I1206 12:13:00.067142  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.068764 (* 1 = 0.068764 loss)
I1206 12:13:00.067153  2751 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I1206 12:13:10.809290  2751 solver.cpp:357] Iteration 52600 (9.30869 iter/s, 10.7427s/100 iters), loss = 0.0474163
I1206 12:13:10.809438  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0474161 (* 1 = 0.0474161 loss)
I1206 12:13:10.809450  2751 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I1206 12:13:21.543421  2751 solver.cpp:357] Iteration 52700 (9.31577 iter/s, 10.7345s/100 iters), loss = 0.0275641
I1206 12:13:21.543484  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0275639 (* 1 = 0.0275639 loss)
I1206 12:13:21.543496  2751 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I1206 12:13:24.778116  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:13:32.291687  2751 solver.cpp:357] Iteration 52800 (9.30345 iter/s, 10.7487s/100 iters), loss = 0.0601575
I1206 12:13:32.291749  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0601573 (* 1 = 0.0601573 loss)
I1206 12:13:32.291759  2751 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I1206 12:13:43.042371  2751 solver.cpp:357] Iteration 52900 (9.30135 iter/s, 10.7511s/100 iters), loss = 0.0651427
I1206 12:13:43.042518  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0651425 (* 1 = 0.0651425 loss)
I1206 12:13:43.042528  2751 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I1206 12:13:53.677857  2751 solver.cpp:514] Iteration 53000, Testing net (#0)
I1206 12:13:56.909885  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:13:56.921391  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.266061 (* 1 = 0.266061 loss)
I1206 12:13:56.921417  2751 solver.cpp:580]     Test net output #1: prob = 0.922203
I1206 12:13:56.921430  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_53000.caffemodel
I1206 12:13:56.929366  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_53000.solverstate
I1206 12:13:56.931772  2751 solver.cpp:593]     Max_acc: 0.922203  with iter: 53000
I1206 12:13:57.037802  2751 solver.cpp:357] Iteration 53000 (7.14493 iter/s, 13.9959s/100 iters), loss = 0.0413467
I1206 12:13:57.037848  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0413465 (* 1 = 0.0413465 loss)
I1206 12:13:57.037863  2751 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I1206 12:14:07.783363  2751 solver.cpp:357] Iteration 53100 (9.30578 iter/s, 10.746s/100 iters), loss = 0.0454516
I1206 12:14:07.783430  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0454514 (* 1 = 0.0454514 loss)
I1206 12:14:07.783440  2751 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I1206 12:14:09.948635  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:14:18.528040  2751 solver.cpp:357] Iteration 53200 (9.30656 iter/s, 10.7451s/100 iters), loss = 0.0334692
I1206 12:14:18.528239  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.033469 (* 1 = 0.033469 loss)
I1206 12:14:18.528250  2751 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I1206 12:14:29.276568  2751 solver.cpp:357] Iteration 53300 (9.30334 iter/s, 10.7488s/100 iters), loss = 0.0253155
I1206 12:14:29.276633  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0253153 (* 1 = 0.0253153 loss)
I1206 12:14:29.276641  2751 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I1206 12:14:40.019902  2751 solver.cpp:357] Iteration 53400 (9.30772 iter/s, 10.7438s/100 iters), loss = 0.0233727
I1206 12:14:40.019969  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0233725 (* 1 = 0.0233725 loss)
I1206 12:14:40.019979  2751 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I1206 12:14:50.645952  2751 solver.cpp:514] Iteration 53500, Testing net (#0)
I1206 12:14:53.834544  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:14:53.846650  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.263297 (* 1 = 0.263297 loss)
I1206 12:14:53.846678  2751 solver.cpp:580]     Test net output #1: prob = 0.923903
I1206 12:14:53.846690  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_53500.caffemodel
I1206 12:14:53.878012  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_53500.solverstate
I1206 12:14:53.880409  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:14:53.986881  2751 solver.cpp:357] Iteration 53500 (7.15945 iter/s, 13.9676s/100 iters), loss = 0.0521449
I1206 12:14:53.986927  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0521447 (* 1 = 0.0521447 loss)
I1206 12:14:53.986939  2751 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I1206 12:14:55.175487  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:15:04.737466  2751 solver.cpp:357] Iteration 53600 (9.30143 iter/s, 10.751s/100 iters), loss = 0.0561446
I1206 12:15:04.737530  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0561444 (* 1 = 0.0561444 loss)
I1206 12:15:04.737540  2751 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I1206 12:15:15.479758  2751 solver.cpp:357] Iteration 53700 (9.30863 iter/s, 10.7427s/100 iters), loss = 0.0269654
I1206 12:15:15.479822  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0269652 (* 1 = 0.0269652 loss)
I1206 12:15:15.479831  2751 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I1206 12:15:26.217639  2751 solver.cpp:357] Iteration 53800 (9.31246 iter/s, 10.7383s/100 iters), loss = 0.0231245
I1206 12:15:26.217890  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0231243 (* 1 = 0.0231243 loss)
I1206 12:15:26.217900  2751 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I1206 12:15:36.951750  2751 solver.cpp:357] Iteration 53900 (9.31589 iter/s, 10.7343s/100 iters), loss = 0.0508476
I1206 12:15:36.951815  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0508474 (* 1 = 0.0508474 loss)
I1206 12:15:36.951828  2751 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I1206 12:15:37.173612  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:15:47.589184  2751 solver.cpp:514] Iteration 54000, Testing net (#0)
I1206 12:15:50.822000  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:15:50.834611  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.277932 (* 1 = 0.277932 loss)
I1206 12:15:50.834638  2751 solver.cpp:580]     Test net output #1: prob = 0.922102
I1206 12:15:50.834645  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:15:50.940191  2751 solver.cpp:357] Iteration 54000 (7.14846 iter/s, 13.989s/100 iters), loss = 0.0271421
I1206 12:15:50.940237  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0271419 (* 1 = 0.0271419 loss)
I1206 12:15:50.940248  2751 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I1206 12:16:01.681272  2751 solver.cpp:357] Iteration 54100 (9.30967 iter/s, 10.7415s/100 iters), loss = 0.0390304
I1206 12:16:01.681440  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0390302 (* 1 = 0.0390302 loss)
I1206 12:16:01.681454  2751 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I1206 12:16:12.432094  2751 solver.cpp:357] Iteration 54200 (9.30134 iter/s, 10.7511s/100 iters), loss = 0.041108
I1206 12:16:12.432158  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0411078 (* 1 = 0.0411078 loss)
I1206 12:16:12.432169  2751 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I1206 12:16:22.324905  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:16:23.178460  2751 solver.cpp:357] Iteration 54300 (9.30511 iter/s, 10.7468s/100 iters), loss = 0.0737645
I1206 12:16:23.178525  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0737643 (* 1 = 0.0737643 loss)
I1206 12:16:23.178534  2751 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I1206 12:16:33.914168  2751 solver.cpp:357] Iteration 54400 (9.31435 iter/s, 10.7361s/100 iters), loss = 0.0261601
I1206 12:16:33.914269  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0261599 (* 1 = 0.0261599 loss)
I1206 12:16:33.914281  2751 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I1206 12:16:44.562278  2751 solver.cpp:514] Iteration 54500, Testing net (#0)
I1206 12:16:47.756532  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:16:47.768630  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.27595 (* 1 = 0.27595 loss)
I1206 12:16:47.768656  2751 solver.cpp:580]     Test net output #1: prob = 0.921202
I1206 12:16:47.768663  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:16:47.874840  2751 solver.cpp:357] Iteration 54500 (7.1627 iter/s, 13.9612s/100 iters), loss = 0.0387467
I1206 12:16:47.874883  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0387465 (* 1 = 0.0387465 loss)
I1206 12:16:47.874894  2751 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I1206 12:16:58.595726  2751 solver.cpp:357] Iteration 54600 (9.32721 iter/s, 10.7213s/100 iters), loss = 0.0354193
I1206 12:16:58.595791  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0354191 (* 1 = 0.0354191 loss)
I1206 12:16:58.595801  2751 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I1206 12:17:07.520417  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:17:09.344563  2751 solver.cpp:357] Iteration 54700 (9.30297 iter/s, 10.7493s/100 iters), loss = 0.038043
I1206 12:17:09.344624  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0380428 (* 1 = 0.0380428 loss)
I1206 12:17:09.344633  2751 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I1206 12:17:20.094686  2751 solver.cpp:357] Iteration 54800 (9.30186 iter/s, 10.7505s/100 iters), loss = 0.0131547
I1206 12:17:20.094748  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0131545 (* 1 = 0.0131545 loss)
I1206 12:17:20.094759  2751 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I1206 12:17:30.835693  2751 solver.cpp:357] Iteration 54900 (9.30976 iter/s, 10.7414s/100 iters), loss = 0.0426136
I1206 12:17:30.835758  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0426133 (* 1 = 0.0426133 loss)
I1206 12:17:30.835770  2751 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I1206 12:17:41.478169  2751 solver.cpp:514] Iteration 55000, Testing net (#0)
I1206 12:17:44.709327  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:17:44.721451  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.270116 (* 1 = 0.270116 loss)
I1206 12:17:44.721479  2751 solver.cpp:580]     Test net output #1: prob = 0.920503
I1206 12:17:44.721487  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:17:44.828009  2751 solver.cpp:357] Iteration 55000 (7.14649 iter/s, 13.9929s/100 iters), loss = 0.0344317
I1206 12:17:44.828052  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0344314 (* 1 = 0.0344314 loss)
I1206 12:17:44.828061  2751 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I1206 12:17:52.775755  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:17:55.567764  2751 solver.cpp:357] Iteration 55100 (9.31083 iter/s, 10.7402s/100 iters), loss = 0.0329075
I1206 12:17:55.567828  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0329073 (* 1 = 0.0329073 loss)
I1206 12:17:55.567840  2751 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I1206 12:18:06.303891  2751 solver.cpp:357] Iteration 55200 (9.31399 iter/s, 10.7365s/100 iters), loss = 0.029404
I1206 12:18:06.303956  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0294038 (* 1 = 0.0294038 loss)
I1206 12:18:06.303966  2751 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I1206 12:18:17.046535  2751 solver.cpp:357] Iteration 55300 (9.30834 iter/s, 10.7431s/100 iters), loss = 0.0385515
I1206 12:18:17.046679  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0385513 (* 1 = 0.0385513 loss)
I1206 12:18:17.046690  2751 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I1206 12:18:27.793277  2751 solver.cpp:357] Iteration 55400 (9.30486 iter/s, 10.7471s/100 iters), loss = 0.0230182
I1206 12:18:27.793344  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.023018 (* 1 = 0.023018 loss)
I1206 12:18:27.793354  2751 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I1206 12:18:34.681696  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:18:38.427402  2751 solver.cpp:514] Iteration 55500, Testing net (#0)
I1206 12:18:41.637630  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:18:41.649093  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.270022 (* 1 = 0.270022 loss)
I1206 12:18:41.649121  2751 solver.cpp:580]     Test net output #1: prob = 0.921302
I1206 12:18:41.649127  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:18:41.753515  2751 solver.cpp:357] Iteration 55500 (7.16292 iter/s, 13.9608s/100 iters), loss = 0.0624924
I1206 12:18:41.753558  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0624922 (* 1 = 0.0624922 loss)
I1206 12:18:41.753571  2751 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I1206 12:18:52.498445  2751 solver.cpp:357] Iteration 55600 (9.30634 iter/s, 10.7454s/100 iters), loss = 0.0495831
I1206 12:18:52.498590  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0495829 (* 1 = 0.0495829 loss)
I1206 12:18:52.498601  2751 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I1206 12:19:03.252125  2751 solver.cpp:357] Iteration 55700 (9.29886 iter/s, 10.754s/100 iters), loss = 0.0597166
I1206 12:19:03.252188  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0597164 (* 1 = 0.0597164 loss)
I1206 12:19:03.252198  2751 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I1206 12:19:13.989814  2751 solver.cpp:357] Iteration 55800 (9.31264 iter/s, 10.7381s/100 iters), loss = 0.0264237
I1206 12:19:13.989878  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0264235 (* 1 = 0.0264235 loss)
I1206 12:19:13.989889  2751 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I1206 12:19:19.892719  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:19:24.719099  2751 solver.cpp:357] Iteration 55900 (9.31993 iter/s, 10.7297s/100 iters), loss = 0.07511
I1206 12:19:24.719302  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0751098 (* 1 = 0.0751098 loss)
I1206 12:19:24.719313  2751 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I1206 12:19:35.354528  2751 solver.cpp:514] Iteration 56000, Testing net (#0)
I1206 12:19:38.580935  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:19:38.593694  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.272067 (* 1 = 0.272067 loss)
I1206 12:19:38.593721  2751 solver.cpp:580]     Test net output #1: prob = 0.921402
I1206 12:19:38.593727  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:19:38.700501  2751 solver.cpp:357] Iteration 56000 (7.15214 iter/s, 13.9818s/100 iters), loss = 0.044321
I1206 12:19:38.700546  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0443208 (* 1 = 0.0443208 loss)
I1206 12:19:38.700558  2751 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I1206 12:19:49.442363  2751 solver.cpp:357] Iteration 56100 (9.30901 iter/s, 10.7423s/100 iters), loss = 0.0278793
I1206 12:19:49.442427  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0278792 (* 1 = 0.0278792 loss)
I1206 12:19:49.442437  2751 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I1206 12:20:00.183496  2751 solver.cpp:357] Iteration 56200 (9.30966 iter/s, 10.7415s/100 iters), loss = 0.0363412
I1206 12:20:00.183655  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.036341 (* 1 = 0.036341 loss)
I1206 12:20:00.183665  2751 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I1206 12:20:05.031268  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:20:10.925782  2751 solver.cpp:357] Iteration 56300 (9.30874 iter/s, 10.7426s/100 iters), loss = 0.0157554
I1206 12:20:10.925846  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0157552 (* 1 = 0.0157552 loss)
I1206 12:20:10.925856  2751 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I1206 12:20:21.658809  2751 solver.cpp:357] Iteration 56400 (9.31669 iter/s, 10.7334s/100 iters), loss = 0.0481716
I1206 12:20:21.658872  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0481714 (* 1 = 0.0481714 loss)
I1206 12:20:21.658881  2751 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I1206 12:20:32.303011  2751 solver.cpp:514] Iteration 56500, Testing net (#0)
I1206 12:20:35.530081  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:20:35.542430  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.273777 (* 1 = 0.273777 loss)
I1206 12:20:35.542457  2751 solver.cpp:580]     Test net output #1: prob = 0.921302
I1206 12:20:35.542464  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:20:35.648952  2751 solver.cpp:357] Iteration 56500 (7.14761 iter/s, 13.9907s/100 iters), loss = 0.0458894
I1206 12:20:35.648995  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0458892 (* 1 = 0.0458892 loss)
I1206 12:20:35.649008  2751 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I1206 12:20:46.403069  2751 solver.cpp:357] Iteration 56600 (9.2984 iter/s, 10.7545s/100 iters), loss = 0.0350772
I1206 12:20:46.403131  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.035077 (* 1 = 0.035077 loss)
I1206 12:20:46.403142  2751 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I1206 12:20:50.284651  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:20:57.155150  2751 solver.cpp:357] Iteration 56700 (9.30018 iter/s, 10.7525s/100 iters), loss = 0.0257759
I1206 12:20:57.155220  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0257757 (* 1 = 0.0257757 loss)
I1206 12:20:57.155230  2751 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I1206 12:21:07.889093  2751 solver.cpp:357] Iteration 56800 (9.3159 iter/s, 10.7343s/100 iters), loss = 0.0207873
I1206 12:21:07.889240  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0207872 (* 1 = 0.0207872 loss)
I1206 12:21:07.889250  2751 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I1206 12:21:18.633849  2751 solver.cpp:357] Iteration 56900 (9.30692 iter/s, 10.7447s/100 iters), loss = 0.0251388
I1206 12:21:18.633913  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0251386 (* 1 = 0.0251386 loss)
I1206 12:21:18.633924  2751 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I1206 12:21:29.261415  2751 solver.cpp:514] Iteration 57000, Testing net (#0)
I1206 12:21:32.469112  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:21:32.481941  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.275358 (* 1 = 0.275358 loss)
I1206 12:21:32.481968  2751 solver.cpp:580]     Test net output #1: prob = 0.920702
I1206 12:21:32.481976  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:21:32.587524  2751 solver.cpp:357] Iteration 57000 (7.1679 iter/s, 13.9511s/100 iters), loss = 0.0133634
I1206 12:21:32.587566  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133632 (* 1 = 0.0133632 loss)
I1206 12:21:32.587579  2751 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I1206 12:21:35.491443  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:21:43.344995  2751 solver.cpp:357] Iteration 57100 (9.29755 iter/s, 10.7555s/100 iters), loss = 0.0389489
I1206 12:21:43.345191  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0389488 (* 1 = 0.0389488 loss)
I1206 12:21:43.345201  2751 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I1206 12:21:54.095770  2751 solver.cpp:357] Iteration 57200 (9.30343 iter/s, 10.7487s/100 iters), loss = 0.01814
I1206 12:21:54.095834  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0181398 (* 1 = 0.0181398 loss)
I1206 12:21:54.095844  2751 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I1206 12:22:04.839048  2751 solver.cpp:357] Iteration 57300 (9.30977 iter/s, 10.7414s/100 iters), loss = 0.0486871
I1206 12:22:04.839112  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0486869 (* 1 = 0.0486869 loss)
I1206 12:22:04.839121  2751 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I1206 12:22:15.572911  2751 solver.cpp:357] Iteration 57400 (9.3179 iter/s, 10.732s/100 iters), loss = 0.0346392
I1206 12:22:15.573060  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0346391 (* 1 = 0.0346391 loss)
I1206 12:22:15.573071  2751 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I1206 12:22:17.414515  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:22:26.212522  2751 solver.cpp:514] Iteration 57500, Testing net (#0)
I1206 12:22:29.461735  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:22:29.473790  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.279041 (* 1 = 0.279041 loss)
I1206 12:22:29.473819  2751 solver.cpp:580]     Test net output #1: prob = 0.921502
I1206 12:22:29.473824  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:22:29.580327  2751 solver.cpp:357] Iteration 57500 (7.14029 iter/s, 14.005s/100 iters), loss = 0.0216687
I1206 12:22:29.580368  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0216685 (* 1 = 0.0216685 loss)
I1206 12:22:29.580379  2751 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I1206 12:22:40.327177  2751 solver.cpp:357] Iteration 57600 (9.30655 iter/s, 10.7451s/100 iters), loss = 0.019988
I1206 12:22:40.327242  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0199878 (* 1 = 0.0199878 loss)
I1206 12:22:40.327251  2751 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I1206 12:22:51.077797  2751 solver.cpp:357] Iteration 57700 (9.30327 iter/s, 10.7489s/100 iters), loss = 0.0518489
I1206 12:22:51.077935  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0518488 (* 1 = 0.0518488 loss)
I1206 12:22:51.077945  2751 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I1206 12:23:01.833932  2751 solver.cpp:357] Iteration 57800 (9.29853 iter/s, 10.7544s/100 iters), loss = 0.0397536
I1206 12:23:01.833995  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0397534 (* 1 = 0.0397534 loss)
I1206 12:23:01.834007  2751 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I1206 12:23:02.695884  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:23:12.575979  2751 solver.cpp:357] Iteration 57900 (9.31063 iter/s, 10.7404s/100 iters), loss = 0.0441046
I1206 12:23:12.576045  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0441044 (* 1 = 0.0441044 loss)
I1206 12:23:12.576054  2751 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I1206 12:23:23.211181  2751 solver.cpp:514] Iteration 58000, Testing net (#0)
I1206 12:23:26.455490  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:23:26.467967  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.29104 (* 1 = 0.29104 loss)
I1206 12:23:26.467994  2751 solver.cpp:580]     Test net output #1: prob = 0.919803
I1206 12:23:26.468001  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:23:26.573609  2751 solver.cpp:357] Iteration 58000 (7.14511 iter/s, 13.9956s/100 iters), loss = 0.011459
I1206 12:23:26.573652  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0114589 (* 1 = 0.0114589 loss)
I1206 12:23:26.573665  2751 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I1206 12:23:37.329687  2751 solver.cpp:357] Iteration 58100 (9.29839 iter/s, 10.7545s/100 iters), loss = 0.0495589
I1206 12:23:37.329751  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0495587 (* 1 = 0.0495587 loss)
I1206 12:23:37.329761  2751 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I1206 12:23:47.987073  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:23:48.090364  2751 solver.cpp:357] Iteration 58200 (9.2944 iter/s, 10.7592s/100 iters), loss = 0.0242734
I1206 12:23:48.090417  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0242732 (* 1 = 0.0242732 loss)
I1206 12:23:48.090426  2751 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I1206 12:23:58.835276  2751 solver.cpp:357] Iteration 58300 (9.30801 iter/s, 10.7434s/100 iters), loss = 0.0454525
I1206 12:23:58.835427  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0454524 (* 1 = 0.0454524 loss)
I1206 12:23:58.835438  2751 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I1206 12:24:09.597004  2751 solver.cpp:357] Iteration 58400 (9.29352 iter/s, 10.7602s/100 iters), loss = 0.0151519
I1206 12:24:09.597069  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0151518 (* 1 = 0.0151518 loss)
I1206 12:24:09.597079  2751 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I1206 12:24:20.213084  2751 solver.cpp:514] Iteration 58500, Testing net (#0)
I1206 12:24:23.437378  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:24:23.449410  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.282065 (* 1 = 0.282065 loss)
I1206 12:24:23.449439  2751 solver.cpp:580]     Test net output #1: prob = 0.919903
I1206 12:24:23.449445  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:24:23.555719  2751 solver.cpp:357] Iteration 58500 (7.16491 iter/s, 13.9569s/100 iters), loss = 0.0711098
I1206 12:24:23.555763  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0711096 (* 1 = 0.0711096 loss)
I1206 12:24:23.555776  2751 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I1206 12:24:33.141319  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:24:34.315145  2751 solver.cpp:357] Iteration 58600 (9.29535 iter/s, 10.7581s/100 iters), loss = 0.0354814
I1206 12:24:34.315210  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0354813 (* 1 = 0.0354813 loss)
I1206 12:24:34.315219  2751 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I1206 12:24:45.053289  2751 solver.cpp:357] Iteration 58700 (9.31376 iter/s, 10.7368s/100 iters), loss = 0.0610508
I1206 12:24:45.053349  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0610507 (* 1 = 0.0610507 loss)
I1206 12:24:45.053360  2751 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I1206 12:24:55.802129  2751 solver.cpp:357] Iteration 58800 (9.30447 iter/s, 10.7475s/100 iters), loss = 0.0483978
I1206 12:24:55.802196  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0483977 (* 1 = 0.0483977 loss)
I1206 12:24:55.802206  2751 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I1206 12:25:06.569643  2751 solver.cpp:357] Iteration 58900 (9.28831 iter/s, 10.7662s/100 iters), loss = 0.0415495
I1206 12:25:06.569969  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0415493 (* 1 = 0.0415493 loss)
I1206 12:25:06.569979  2751 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I1206 12:25:15.173547  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:25:17.209462  2751 solver.cpp:514] Iteration 59000, Testing net (#0)
I1206 12:25:20.457052  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:25:20.469126  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.270311 (* 1 = 0.270311 loss)
I1206 12:25:20.469153  2751 solver.cpp:580]     Test net output #1: prob = 0.922703
I1206 12:25:20.469159  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:25:20.575129  2751 solver.cpp:357] Iteration 59000 (7.14101 iter/s, 14.0036s/100 iters), loss = 0.0155587
I1206 12:25:20.575172  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0155586 (* 1 = 0.0155586 loss)
I1206 12:25:20.575184  2751 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I1206 12:25:31.320744  2751 solver.cpp:357] Iteration 59100 (9.30716 iter/s, 10.7444s/100 iters), loss = 0.0370879
I1206 12:25:31.320806  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0370877 (* 1 = 0.0370877 loss)
I1206 12:25:31.320817  2751 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I1206 12:25:42.057045  2751 solver.cpp:357] Iteration 59200 (9.31523 iter/s, 10.7351s/100 iters), loss = 0.0182698
I1206 12:25:42.057147  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0182696 (* 1 = 0.0182696 loss)
I1206 12:25:42.057162  2751 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I1206 12:25:52.797266  2751 solver.cpp:357] Iteration 59300 (9.31184 iter/s, 10.739s/100 iters), loss = 0.0162099
I1206 12:25:52.797333  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0162098 (* 1 = 0.0162098 loss)
I1206 12:25:52.797341  2751 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I1206 12:26:00.317775  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:26:03.533612  2751 solver.cpp:357] Iteration 59400 (9.31515 iter/s, 10.7352s/100 iters), loss = 0.0393834
I1206 12:26:03.533674  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0393833 (* 1 = 0.0393833 loss)
I1206 12:26:03.533684  2751 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I1206 12:26:14.190073  2751 solver.cpp:514] Iteration 59500, Testing net (#0)
I1206 12:26:17.398339  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:26:17.410603  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.278036 (* 1 = 0.278036 loss)
I1206 12:26:17.410630  2751 solver.cpp:580]     Test net output #1: prob = 0.922703
I1206 12:26:17.410637  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:26:17.516597  2751 solver.cpp:357] Iteration 59500 (7.15227 iter/s, 13.9816s/100 iters), loss = 0.0286819
I1206 12:26:17.516638  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0286818 (* 1 = 0.0286818 loss)
I1206 12:26:17.516649  2751 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I1206 12:26:28.265529  2751 solver.cpp:357] Iteration 59600 (9.30417 iter/s, 10.7479s/100 iters), loss = 0.0653157
I1206 12:26:28.265594  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0653155 (* 1 = 0.0653155 loss)
I1206 12:26:28.265604  2751 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I1206 12:26:39.016340  2751 solver.cpp:357] Iteration 59700 (9.30254 iter/s, 10.7498s/100 iters), loss = 0.0202612
I1206 12:26:39.016407  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0202611 (* 1 = 0.0202611 loss)
I1206 12:26:39.016417  2751 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I1206 12:26:45.575487  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:26:49.754004  2751 solver.cpp:357] Iteration 59800 (9.31391 iter/s, 10.7366s/100 iters), loss = 0.0399022
I1206 12:26:49.754067  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0399021 (* 1 = 0.0399021 loss)
I1206 12:26:49.754077  2751 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I1206 12:27:00.480974  2751 solver.cpp:357] Iteration 59900 (9.32317 iter/s, 10.726s/100 iters), loss = 0.0240406
I1206 12:27:00.481035  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0240404 (* 1 = 0.0240404 loss)
I1206 12:27:00.481046  2751 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I1206 12:27:11.108481  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.caffemodel
I1206 12:27:11.116484  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.solverstate
I1206 12:27:11.119261  2751 solver.cpp:514] Iteration 60000, Testing net (#0)
I1206 12:27:14.344894  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:27:14.356849  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.283019 (* 1 = 0.283019 loss)
I1206 12:27:14.356876  2751 solver.cpp:580]     Test net output #1: prob = 0.921302
I1206 12:27:14.356883  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:27:14.462221  2751 solver.cpp:357] Iteration 60000 (7.15308 iter/s, 13.98s/100 iters), loss = 0.048202
I1206 12:27:14.462265  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0482019 (* 1 = 0.0482019 loss)
I1206 12:27:14.462275  2751 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I1206 12:27:25.227452  2751 solver.cpp:357] Iteration 60100 (9.28998 iter/s, 10.7643s/100 iters), loss = 0.0169736
I1206 12:27:25.227696  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0169734 (* 1 = 0.0169734 loss)
I1206 12:27:25.227710  2751 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I1206 12:27:30.814605  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:27:35.963022  2751 solver.cpp:357] Iteration 60200 (9.31579 iter/s, 10.7345s/100 iters), loss = 0.0186879
I1206 12:27:35.963085  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0186877 (* 1 = 0.0186877 loss)
I1206 12:27:35.963099  2751 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I1206 12:27:46.706938  2751 solver.cpp:357] Iteration 60300 (9.30839 iter/s, 10.743s/100 iters), loss = 0.033197
I1206 12:27:46.707002  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0331969 (* 1 = 0.0331969 loss)
I1206 12:27:46.707012  2751 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I1206 12:27:57.450839  2751 solver.cpp:357] Iteration 60400 (9.30838 iter/s, 10.743s/100 iters), loss = 0.0417684
I1206 12:27:57.450995  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0417682 (* 1 = 0.0417682 loss)
I1206 12:27:57.451005  2751 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I1206 12:28:08.063845  2751 solver.cpp:514] Iteration 60500, Testing net (#0)
I1206 12:28:11.273664  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:28:11.286411  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.274426 (* 1 = 0.274426 loss)
I1206 12:28:11.286438  2751 solver.cpp:580]     Test net output #1: prob = 0.922103
I1206 12:28:11.286444  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:28:11.392740  2751 solver.cpp:357] Iteration 60500 (7.17324 iter/s, 13.9407s/100 iters), loss = 0.032323
I1206 12:28:11.392782  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0323229 (* 1 = 0.0323229 loss)
I1206 12:28:11.392796  2751 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I1206 12:28:15.918180  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:28:22.139580  2751 solver.cpp:357] Iteration 60600 (9.30578 iter/s, 10.746s/100 iters), loss = 0.0189627
I1206 12:28:22.139643  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0189625 (* 1 = 0.0189625 loss)
I1206 12:28:22.139654  2751 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I1206 12:28:32.862749  2751 solver.cpp:357] Iteration 60700 (9.32632 iter/s, 10.7223s/100 iters), loss = 0.0291335
I1206 12:28:32.862900  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0291333 (* 1 = 0.0291333 loss)
I1206 12:28:32.862910  2751 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I1206 12:28:43.608352  2751 solver.cpp:357] Iteration 60800 (9.3069 iter/s, 10.7447s/100 iters), loss = 0.014542
I1206 12:28:43.608415  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0145418 (* 1 = 0.0145418 loss)
I1206 12:28:43.608428  2751 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I1206 12:28:54.337697  2751 solver.cpp:357] Iteration 60900 (9.32092 iter/s, 10.7286s/100 iters), loss = 0.0100257
I1206 12:28:54.337760  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0100255 (* 1 = 0.0100255 loss)
I1206 12:28:54.337771  2751 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I1206 12:28:57.887040  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:29:04.968045  2751 solver.cpp:514] Iteration 61000, Testing net (#0)
I1206 12:29:08.199064  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:29:08.211201  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.277047 (* 1 = 0.277047 loss)
I1206 12:29:08.211228  2751 solver.cpp:580]     Test net output #1: prob = 0.922903
I1206 12:29:08.211236  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:29:08.317536  2751 solver.cpp:357] Iteration 61000 (7.15365 iter/s, 13.9789s/100 iters), loss = 0.0227322
I1206 12:29:08.317579  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0227321 (* 1 = 0.0227321 loss)
I1206 12:29:08.317592  2751 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I1206 12:29:19.058849  2751 solver.cpp:357] Iteration 61100 (9.31048 iter/s, 10.7406s/100 iters), loss = 0.0262178
I1206 12:29:19.058913  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0262176 (* 1 = 0.0262176 loss)
I1206 12:29:19.058923  2751 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I1206 12:29:29.807185  2751 solver.cpp:357] Iteration 61200 (9.3044 iter/s, 10.7476s/100 iters), loss = 0.0237681
I1206 12:29:29.807250  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0237679 (* 1 = 0.0237679 loss)
I1206 12:29:29.807260  2751 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I1206 12:29:40.551806  2751 solver.cpp:357] Iteration 61300 (9.3076 iter/s, 10.7439s/100 iters), loss = 0.0209665
I1206 12:29:40.551956  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0209663 (* 1 = 0.0209663 loss)
I1206 12:29:40.551968  2751 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I1206 12:29:43.142436  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:29:51.299612  2751 solver.cpp:357] Iteration 61400 (9.3049 iter/s, 10.747s/100 iters), loss = 0.0267124
I1206 12:29:51.299675  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0267122 (* 1 = 0.0267122 loss)
I1206 12:29:51.299685  2751 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I1206 12:30:01.930326  2751 solver.cpp:514] Iteration 61500, Testing net (#0)
I1206 12:30:05.109238  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:30:05.121366  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.28763 (* 1 = 0.28763 loss)
I1206 12:30:05.121393  2751 solver.cpp:580]     Test net output #1: prob = 0.920703
I1206 12:30:05.121399  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:30:05.227274  2751 solver.cpp:357] Iteration 61500 (7.18039 iter/s, 13.9268s/100 iters), loss = 0.0583888
I1206 12:30:05.227316  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0583886 (* 1 = 0.0583886 loss)
I1206 12:30:05.227327  2751 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I1206 12:30:15.969295  2751 solver.cpp:357] Iteration 61600 (9.30979 iter/s, 10.7414s/100 iters), loss = 0.0234326
I1206 12:30:15.969436  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0234324 (* 1 = 0.0234324 loss)
I1206 12:30:15.969446  2751 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I1206 12:30:26.717694  2751 solver.cpp:357] Iteration 61700 (9.30433 iter/s, 10.7477s/100 iters), loss = 0.0410367
I1206 12:30:26.717757  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0410366 (* 1 = 0.0410366 loss)
I1206 12:30:26.717768  2751 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I1206 12:30:28.232187  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:30:37.452605  2751 solver.cpp:357] Iteration 61800 (9.31594 iter/s, 10.7343s/100 iters), loss = 0.0218248
I1206 12:30:37.452670  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0218246 (* 1 = 0.0218246 loss)
I1206 12:30:37.452682  2751 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I1206 12:30:48.207365  2751 solver.cpp:357] Iteration 61900 (9.29874 iter/s, 10.7541s/100 iters), loss = 0.0320516
I1206 12:30:48.207597  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0320514 (* 1 = 0.0320514 loss)
I1206 12:30:48.207607  2751 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I1206 12:30:58.857681  2751 solver.cpp:514] Iteration 62000, Testing net (#0)
I1206 12:31:02.102357  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:31:02.114439  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.276246 (* 1 = 0.276246 loss)
I1206 12:31:02.114466  2751 solver.cpp:580]     Test net output #1: prob = 0.923102
I1206 12:31:02.114472  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:31:02.220618  2751 solver.cpp:357] Iteration 62000 (7.13657 iter/s, 14.0123s/100 iters), loss = 0.0244945
I1206 12:31:02.220659  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244944 (* 1 = 0.0244944 loss)
I1206 12:31:02.220669  2751 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I1206 12:31:12.959560  2751 solver.cpp:357] Iteration 62100 (9.31239 iter/s, 10.7384s/100 iters), loss = 0.0244502
I1206 12:31:12.959623  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244501 (* 1 = 0.0244501 loss)
I1206 12:31:12.959635  2751 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I1206 12:31:13.504513  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:31:23.688983  2751 solver.cpp:357] Iteration 62200 (9.32065 iter/s, 10.7289s/100 iters), loss = 0.0248498
I1206 12:31:23.689241  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0248496 (* 1 = 0.0248496 loss)
I1206 12:31:23.689251  2751 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I1206 12:31:34.433687  2751 solver.cpp:357] Iteration 62300 (9.30755 iter/s, 10.744s/100 iters), loss = 0.0264049
I1206 12:31:34.433751  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0264047 (* 1 = 0.0264047 loss)
I1206 12:31:34.433763  2751 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I1206 12:31:45.184023  2751 solver.cpp:357] Iteration 62400 (9.3025 iter/s, 10.7498s/100 iters), loss = 0.0229256
I1206 12:31:45.184088  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0229254 (* 1 = 0.0229254 loss)
I1206 12:31:45.184098  2751 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I1206 12:31:55.384665  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:31:55.804872  2751 solver.cpp:514] Iteration 62500, Testing net (#0)
I1206 12:31:59.005939  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:31:59.017793  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.276533 (* 1 = 0.276533 loss)
I1206 12:31:59.017820  2751 solver.cpp:580]     Test net output #1: prob = 0.923203
I1206 12:31:59.017827  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:31:59.124224  2751 solver.cpp:357] Iteration 62500 (7.17383 iter/s, 13.9396s/100 iters), loss = 0.0247954
I1206 12:31:59.124270  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0247953 (* 1 = 0.0247953 loss)
I1206 12:31:59.124282  2751 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I1206 12:32:09.870589  2751 solver.cpp:357] Iteration 62600 (9.30589 iter/s, 10.7459s/100 iters), loss = 0.0438095
I1206 12:32:09.870653  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0438094 (* 1 = 0.0438094 loss)
I1206 12:32:09.870666  2751 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I1206 12:32:20.619940  2751 solver.cpp:357] Iteration 62700 (9.30331 iter/s, 10.7489s/100 iters), loss = 0.0265801
I1206 12:32:20.620004  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.02658 (* 1 = 0.02658 loss)
I1206 12:32:20.620015  2751 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I1206 12:32:31.354769  2751 solver.cpp:357] Iteration 62800 (9.31589 iter/s, 10.7343s/100 iters), loss = 0.0408481
I1206 12:32:31.354969  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.040848 (* 1 = 0.040848 loss)
I1206 12:32:31.354979  2751 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I1206 12:32:40.607235  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:32:42.108678  2751 solver.cpp:357] Iteration 62900 (9.29947 iter/s, 10.7533s/100 iters), loss = 0.0180656
I1206 12:32:42.108743  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0180655 (* 1 = 0.0180655 loss)
I1206 12:32:42.108752  2751 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I1206 12:32:52.748070  2751 solver.cpp:514] Iteration 63000, Testing net (#0)
I1206 12:32:55.962131  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:32:55.974571  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.284171 (* 1 = 0.284171 loss)
I1206 12:32:55.974599  2751 solver.cpp:580]     Test net output #1: prob = 0.920603
I1206 12:32:55.974606  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:32:56.070294  2751 solver.cpp:357] Iteration 63000 (7.16278 iter/s, 13.9611s/100 iters), loss = 0.0234591
I1206 12:32:56.070338  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.023459 (* 1 = 0.023459 loss)
I1206 12:32:56.070350  2751 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I1206 12:33:06.815279  2751 solver.cpp:357] Iteration 63100 (9.30703 iter/s, 10.7446s/100 iters), loss = 0.0256991
I1206 12:33:06.815399  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.025699 (* 1 = 0.025699 loss)
I1206 12:33:06.815409  2751 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I1206 12:33:17.546545  2751 solver.cpp:357] Iteration 63200 (9.31899 iter/s, 10.7308s/100 iters), loss = 0.0274873
I1206 12:33:17.546608  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0274872 (* 1 = 0.0274872 loss)
I1206 12:33:17.546618  2751 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I1206 12:33:25.815079  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:33:28.279021  2751 solver.cpp:357] Iteration 63300 (9.31788 iter/s, 10.7321s/100 iters), loss = 0.0303828
I1206 12:33:28.279085  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0303827 (* 1 = 0.0303827 loss)
I1206 12:33:28.279094  2751 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I1206 12:33:39.025283  2751 solver.cpp:357] Iteration 63400 (9.30592 iter/s, 10.7459s/100 iters), loss = 0.0280652
I1206 12:33:39.025430  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0280651 (* 1 = 0.0280651 loss)
I1206 12:33:39.025440  2751 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I1206 12:33:49.679576  2751 solver.cpp:514] Iteration 63500, Testing net (#0)
I1206 12:33:52.906301  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:33:52.926090  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.287905 (* 1 = 0.287905 loss)
I1206 12:33:52.926117  2751 solver.cpp:580]     Test net output #1: prob = 0.920902
I1206 12:33:52.926123  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:33:53.031570  2751 solver.cpp:357] Iteration 63500 (7.13994 iter/s, 14.0057s/100 iters), loss = 0.0174556
I1206 12:33:53.031613  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0174554 (* 1 = 0.0174554 loss)
I1206 12:33:53.031630  2751 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I1206 12:34:03.784319  2751 solver.cpp:357] Iteration 63600 (9.30026 iter/s, 10.7524s/100 iters), loss = 0.0236134
I1206 12:34:03.784386  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0236132 (* 1 = 0.0236132 loss)
I1206 12:34:03.784395  2751 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I1206 12:34:10.994730  2757 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:34:14.542340  2751 solver.cpp:357] Iteration 63700 (9.29572 iter/s, 10.7576s/100 iters), loss = 0.0258421
I1206 12:34:14.542404  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.025842 (* 1 = 0.025842 loss)
I1206 12:34:14.542413  2751 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I1206 12:34:25.287937  2751 solver.cpp:357] Iteration 63800 (9.30645 iter/s, 10.7452s/100 iters), loss = 0.0150691
I1206 12:34:25.288003  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.015069 (* 1 = 0.015069 loss)
I1206 12:34:25.288012  2751 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I1206 12:34:36.030288  2751 solver.cpp:357] Iteration 63900 (9.30926 iter/s, 10.742s/100 iters), loss = 0.0166634
I1206 12:34:36.030354  2751 solver.cpp:376]     Train net output #0: Softmax1 = 0.0166633 (* 1 = 0.0166633 loss)
I1206 12:34:36.030364  2751 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I1206 12:34:46.659291  2751 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.caffemodel
I1206 12:34:46.700362  2751 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.solverstate
I1206 12:34:46.730201  2751 solver.cpp:472] Iteration 64000, loss = 0.0330285
I1206 12:34:46.730242  2751 solver.cpp:514] Iteration 64000, Testing net (#0)
I1206 12:34:49.932843  2758 data_layer.cpp:73] Restarting data prefetching from start.
I1206 12:34:49.945021  2751 solver.cpp:580]     Test net output #0: Softmax1 = 0.279746 (* 1 = 0.279746 loss)
I1206 12:34:49.945049  2751 solver.cpp:580]     Test net output #1: prob = 0.921102
I1206 12:34:49.945055  2751 solver.cpp:593]     Max_acc: 0.923903  with iter: 53500
I1206 12:34:49.945065  2751 solver.cpp:479] Optimization Done.
I1206 12:34:49.945070  2751 caffe.cpp:326] Optimization Done.
